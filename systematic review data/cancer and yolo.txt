PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Lalinia, M; Sahafi, A				Lalinia, Mehrshad; Sahafi, Ali			Colorectal polyp detection in colonoscopy images using YOLO-V8 network	SIGNAL IMAGE AND VIDEO PROCESSING			English	Article						Polyp detection; YOLO-V8; Colonoscopy images; Gastrointestinal disorders; Colorectal cancer; Artificial intelligence	TASK-FORCE; CANCER	Gastrointestinal tract disorders, including colorectal cancer (CRC), impose a significant health burden in Europe, with rising incidence rates among both young and elderly populations. Timely detection and removal of polyps, the precursors to CRC, are vital for prevention. Conventional colonoscopy, though effective, is prone to human errors. To address this, we propose an artificial intelligence-based polyp detection system using the YOLO-V8 network. We constructed a diverse dataset from multiple publicly available sources and conducted extensive evaluations. YOLO-V8 m demonstrated impressive performance, achieving 95.6% precision, 91.7% recall, and 92.4% F1-score. It outperformed other state-of-the-art models in terms of mean average precision. YOLO-V8 s offered a balance between accuracy and computational efficiency. Our research provides valuable insights into enhancing polyp detection and contributes to the advancement of computer-aided diagnosis for colorectal cancer.	[Lalinia, Mehrshad; Sahafi, Ali] Univ Southern Denmark, Dept Mech & Elect Engn, Elect Engn Sect, DK-5230 Odense, Denmark	University of Southern Denmark	Lalinia, M (corresponding author), Univ Southern Denmark, Dept Mech & Elect Engn, Elect Engn Sect, DK-5230 Odense, Denmark.	melal@sdu.dk; alisa@sdu.dk	Sahafi, Ali/AFR-3829-2022	Sahafi, Ali/0000-0001-9360-9103	University of Southern Denmark	University of Southern Denmark	No Statement Available	Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197; Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897; [Anonymous], 2023, HEALTHLINE; [Anonymous], 2013, Ultralytics; Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165; Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007; Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989; Bochkovskiy A., 2020, COMPUTER VISION PATT, DOI DOI 10.48550/ARXIV.2004.10934; Cao CT, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250632; Carrinho P., 2022, HIGHLY ACCURATE FAST; Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26; Durak S, 2021, MED BIOL ENG COMPUT, V59, P1563, DOI 10.1007/s11517-021-02398-8; Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3490, DOI 10.1109/ICCV48922.2021.00349; Galdran Adrian, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P293, DOI 10.1007/978-3-030-68763-2_22; Ge Z, 2021, YOLOX EXCEEDING YOLO, DOI [DOI 10.48550/ARXIV.2107.08430, 10.48550/ARXIV.2107.08430]; Guo Z, 2020, I S BIOMED IMAGING, P1655, DOI [10.1109/ISBI45749.2020.9098500, 10.1109/isbi45749.2020.9098500]; Jha D., 2022, IEEE T NEUR NET LEAR, V6, P66; Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672; Karaman A, 2023, APPL INTELL, V53, P15603, DOI 10.1007/s10489-022-04299-1; Karaman A, 2023, EXPERT SYST APPL, V221, DOI 10.1016/j.eswa.2023.119741; Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340; Lee JN, 2022, J ELECTR ENG TECHNOL, V17, P3057, DOI 10.1007/s42835-022-01191-3; Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1; Lewis J, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28530-2; Li Q, 2017, IEEE INT CONF COMM, P29, DOI 10.1109/ICCW.2017.7962629; Li X., 2020, P ANN C NEUR INF PRO, P21002, DOI DOI 10.48550/ARXIV.2006.04388; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052; Matsuda T, 2015, JPN J CLIN ONCOL, V45, P900, DOI 10.1093/jjco/hyv117; Megía PJ, 2021, CATAL TODAY, V367, P145, DOI 10.1016/j.cattod.2020.04.069; Ng S, 2020, DIGEST DIS SCI, V65, P2229, DOI 10.1007/s10620-020-06049-0; Nogueira-Rodríguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4; Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031; Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519; Pozdeev AA, 2019, IEEE NW RUSS YOUNG, P1216, DOI [10.1109/eiconrus.2019.8657018, 10.1109/EIConRus.2019.8657018]; Qian ZQ, 2022, IEEE SENS J, V22, P10841, DOI 10.1109/JSEN.2022.3170034; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003; Ro Y.M., 2020, MULTIMEDIA MODELING, V11962; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sahafi A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17502-7; Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3; Song PF, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105476; Stoffel EM, 2020, GASTROENTEROLOGY, V158, P341, DOI 10.1053/j.gastro.2019.07.055; Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997; Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821; Tan M., 2020, P IEEE CVF C COMP VI, P10778, DOI DOI 10.48550/ARXIV.1911.09070; Tashk Ashkan, 2019, WSEAS Transactions on Systems and Control, V14, P384; Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23; Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037; Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190; Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094; Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503; Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004; Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370; Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133; Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2; Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337; Zheng ZH, 2022, IEEE T CYBERNETICS, V52, P8574, DOI 10.1109/TCYB.2021.3095305; Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993	62	7	7	44	66	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	1863-1703	1863-1711		SIGNAL IMAGE VIDEO P	Signal Image Video Process.	APR	2024	18	3					2047	2058		10.1007/s11760-023-02835-1	http://dx.doi.org/10.1007/s11760-023-02835-1		DEC 2023	12	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Imaging Science & Photographic Technology	LL3R7		hybrid			2024-09-18	WOS:001129351400003
J	Coskun, D; Karaboga, D; Bastürk, A; Akay, B; Nalbantoglu, OU; Dogan, S; Paçal, I; Karagöz, MA				Coskun, Damla; Karaboga, Dervis; Basturk, Alper; Akay, Bahriye; Nalbantoglu, oezkan Ufuk; Dogan, Serap; Pacal, Ishak; Karagoz, Meryem Altin			A comparative study of YOLO models and a transformer-based YOLOv5 model for mass detection in mammograms	TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES			English	Article						Breast cancer; deep learning; YOLO; computer-aided detection; transformer-based YOLO; data augmentation	COMPUTER-AIDED DIAGNOSIS; DIGITAL MAMMOGRAMS; CANCER; CLASSIFICATION; SYSTEM; FULL	Breast cancer is a prevalent form of cancer across the globe, and if it is not diagnosed at an early stage it can be life-threatening. In order to aid in its diagnosis, detection, and classification, computer-aided detection (CAD) systems are employed. You Only Look Once (YOLO)-based CAD algorithms have become very popular owing to their highly accurate results for object detection tasks in recent years. Therefore, the most popular YOLO models are implemented to compare the performance in mass detection with various experiments on the INbreast dataset. In addition, a YOLO model with an integrated Swin Transformer in its backbone is proposed for mass detection in mammography images within the study. The performance of YOLOv5 models and a transformer-based YOLO model is compared to that of each other and YOLOv3 and YOLOv4 models using images with different sizes on the INbreast dataset. The best results are obtained by the transformer-based YOLO model of YOLOv5 for 832 x 832 image size. In another experiment, we compared the default anchors against the anchors provided by the YOLOv5 autoanchor function before training and saw that the anchors generated by the YOLOv5 autoanchor increased the success rates. Furthermore, various experiments were conducted to observe how data augmentation affects performance. Although a small amount of data was used in the study, high performance was obtained by YOLO algorithms, which are promising tools for cancer detection.	[Coskun, Damla; Karaboga, Dervis; Basturk, Alper; Akay, Bahriye; Nalbantoglu, oezkan Ufuk; Karagoz, Meryem Altin] Erciyes Univ, Fac Engn, Dept Comp Engn, Kayseri, Turkiye; [Coskun, Damla; Karaboga, Dervis; Basturk, Alper; Akay, Bahriye; Nalbantoglu, oezkan Ufuk; Pacal, Ishak; Karagoz, Meryem Altin] Erciyes Univ, Artificial Intelligence & Big Data Applicat & Res, Kayseri, Turkiye; [Dogan, Serap] Erciyes Univ Med Fac, Dept Radiol, Kayseri, Turkiye; [Pacal, Ishak] Igdir Univ, Engn Fac, Comp Engn Dept, Igdir, Turkiye; [Karagoz, Meryem Altin] Sivas Cumhuriyet Univ, Dept Comp Engn, Sivas, Turkiye	Erciyes University; Erciyes University; Erciyes University; Igdir University; Cumhuriyet University	Coskun, D (corresponding author), Erciyes Univ, Fac Engn, Dept Comp Engn, Kayseri, Turkiye.; Coskun, D (corresponding author), Erciyes Univ, Artificial Intelligence & Big Data Applicat & Res, Kayseri, Turkiye.	damlacoskun@erciyes.edu.tr	Karagöz, Meryem Altın/AAS-9054-2021; Karaboga, Dervis/AAY-8495-2020; Basturk, Alper/A-8953-2012; Basturk Akay, Bahriye/A-8934-2012; Pacal, Ishak/HJJ-1662-2023	Karagoz, Meryem Altin/0000-0002-8275-5356; Basturk Akay, Bahriye/0000-0001-6575-4725; Pacal, Ishak/0000-0001-6670-2169	Council of Higher Education [100/2000]; Big Data Application and Research Center	Council of Higher Education; Big Data Application and Research Center	This study is supported by the Council of Higher Education 100/2000 doctoral program. Experimental calcu- lations were conducted on the computer at Erciyes University Artificial Intelligence and Big Data Application and Research Center.	Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4; Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584; Al-antari MA, 2020, ADV EXP MED BIOL, V1213, P59, DOI 10.1007/978-3-030-33128-3_4; Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003; Al-masni MA, 2017, IEEE ENG MED BIO, P1230, DOI 10.1109/EMBC.2017.8037053; Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017; Aly GH, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105823; Arnold M, 2022, BREAST, V66, P15, DOI 10.1016/j.breast.2022.08.010; Baccouche A, 2021, Computers, Materials & Continua, V69; Baccouche A, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106884; Betancourt Tarifa Amparo S., 2023, Journal of Ambient Intelligence and Humanized Computing, P2723, DOI 10.1007/s12652-023-04517-9; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Chen PY, 2019, IEEE IMAGE PROC, P2956, DOI [10.1109/ICIP.2019.8803719, 10.1109/icip.2019.8803719]; Chen XX, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071549; Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009; Djebbar K, 2019, IEEE 2019 6 INT C IM, P1; Dluznevskij D, 2021, BALT J MOD COMPUT, V9, P333, DOI 10.22364/bjmc.2021.9.3.07; Domingues I, 2020, ARTIF INTELL REV, V53, P4093, DOI 10.1007/s10462-019-09788-3; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Gotzsche PC, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001877.pub5; Hamed G, 2021, IEEE ACCESS, V9, P116898, DOI 10.1109/ACCESS.2021.3105924; Hassan NM, 2022, LECT NOTES COMPUT SC, V13375, P544, DOI 10.1007/978-3-031-10522-7_37; Hassan NM, 2022, MULTIMED TOOLS APPL, V81, P20043, DOI 10.1007/s11042-022-12332-1; Kamran SA, 2022, Arxiv, DOI arXiv:2211.08717; Kolchev A, 2022, J IMAGING, V8, DOI 10.3390/jimaging8040088; Kozegar E, 2020, ARTIF INTELL REV, V53, P1919, DOI 10.1007/s10462-019-09722-7; Li F, 2023, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR52729.2023.00297; Li Y, 2016, J. Health Med. Inform., V4, P1, DOI 10.4172/2157-7420.1000238; Liberman L, 2002, RADIOL CLIN N AM, V40, P409, DOI 10.1016/S0033-8389(01)00017-3; Liu HY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155817; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu Z, 2022, PROC CVPR IEEE, P11999, DOI 10.1109/CVPR52688.2022.01170; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Lu SL, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14225853; Moghbel M, 2013, ARTIF INTELL REV, V39, P305, DOI 10.1007/s10462-011-9274-2; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Parsa Parisa, 2006, Asian Pac J Cancer Prev, V7, P509; Peng JC, 2020, MED BIOL ENG COMPUT, V58, P1405, DOI 10.1007/s11517-020-02170-4; Redmon J., 2018, arXiv; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Shah SM, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105221; Siegel RL, 2023, CA-CANCER J CLIN, V73, P17, DOI 10.3322/caac.21763; Su YY, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106903; Thuan D., 2021, Evolution of Yolo Algorithm and Yolov5: The State-of-the-Art Object Detention Algorithm; Vasanthi P, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15773-4; Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852; Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203; Wei Yixuan, 2022, arXiv; Xue ZY, 2022, FORESTS, V13, DOI 10.3390/f13081332; Yang W, 2023, IEEE IJCNN, DOI 10.1109/IJCNN54540.2023.10191866; Yasir N, 2022, Pakistan Journal of Engineering and Technology, V5, P1; Zhang LL, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116273; Zhao JH, 2022, MULTIMED TOOLS APPL, V81, P19257, DOI 10.1007/s11042-021-10505-y	55	5	5	5	16	Tubitak Scientific & Technological Research Council Turkey	ANKARA	ATATURK BULVARI NO 221, KAVAKLIDERE, TR-06100 ANKARA, TURKIYE	1300-0632	1303-6203		TURK J ELECTR ENG CO	Turk. J. Electr. Eng. Comput. Sci.		2023	31	7					1294	1313		10.55730/1300-0632.4048	http://dx.doi.org/10.55730/1300-0632.4048			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Z9DP8		Bronze			2024-09-18	WOS:001115009000007
J	Yao, ZD; Jin, T; Mao, BE; Lu, B; Zhang, YF; Li, SS; Chen, WC				Yao, Zhendong; Jin, Tao; Mao, Boneng; Lu, Bo; Zhang, Yefei; Li, Sisi; Chen, Weichang			Construction and Multicenter Diagnostic Verification of Intelligent Recognition System for Endoscopic Images From Early Gastric Cancer Based on YOLO-V3 Algorithm	FRONTIERS IN ONCOLOGY			English	Article						Early gastric cancer; YOLO; endoscopy; Convolutional neural network; artificial intelligence	CONVOLUTIONAL NEURAL-NETWORK	IntroductionEndoscopy is an important tool for the diagnosis of early gastric cancer. Therefore, a combination of artificial intelligence and endoscopy has the ability to increase the speed and efficiency of early gastric cancer diagnosis. YOU ONLY LOOK ONCE (YOLO) is an advanced object detection depth neural network algorithm that has not been widely used in gastrointestinal image recognition. ObjectiveWe developed an artificial intelligence system herein referred to as "EGC-YOLO" for the rapid and accurate diagnosis of endoscopic images from early gastric cancer. MethodsMore than 40000 gastroscopic images from 1653 patients in Yixing people's Hospital were used as the training set for the system, while endoscopic images from the other two hospitals were used as external validation test sets. The sensitivity, specificity, positive predictive value, Youden index and ROC curve were analyzed to evaluate detection efficiencies for EGC-YOLO. ResultsEGC-YOLO was able to diagnose early gastric cancer in the two test sets with a high superiority and efficiency. The accuracy, sensitivity, specificity and positive predictive value for Test Sets 1 and 2 were 85.15% and 86.02%, 85.36% and 83.02%, 84.41% and 92.21%, and 95.22% and 95.65%, respectively. In Test Sets 1 and 2, the corresponding Threshold-values were 0.02, 0.16 and 0.17 at the maximum of the Youden index. An increase in Threshold-values was associated with a downward trend in sensitivity and accuracy, while specificity remained relatively stable at more than 80%. ConclusionsThe EGC-YOLO system is superior for the efficient, accurate and rapid detection of early gastric cancer lesions. For different data sets, it is important to select the appropriate threshold-value in advance to achieve the best performance of the EGC-YOLO system.	[Yao, Zhendong; Chen, Weichang] Soochow Univ, Dept Gastroenterol, Affiliated Hosp 1, Suzhou, Peoples R China; [Yao, Zhendong; Jin, Tao; Mao, Boneng] Yixing Peoples Hosp, Dept Gastroenterol, Yixing, Peoples R China; [Lu, Bo] Microsoft Ltd Co, Microsoft Teams Calling Meeting Device Sharepoint, Suzhou, Peoples R China; [Zhang, Yefei] Soochow Univ, Dept Gastroenterol, Affiliated Hosp 2, Suzhou, Peoples R China; [Li, Sisi] Civil Avit Hosp Shanghai, Dept Gastroenterol, Shanghai, Peoples R China	Soochow University - China; Soochow University - China	Chen, WC (corresponding author), Soochow Univ, Dept Gastroenterol, Affiliated Hosp 1, Suzhou, Peoples R China.	weichangchen@126.com	Chen, Chao/JHS-6563-2023; Zhang, Yefei/AAE-2285-2019; Chen, Wei/X-6211-2019					Al-Antary MT, 2021, IEEE ACCESS, V9, P54190, DOI 10.1109/ACCESS.2021.3070685; Dohi O, 2017, GASTRIC CANCER, V20, P297, DOI 10.1007/s10120-016-0620-6; Esposito G, 2019, ENDOSCOPY, V51, P515, DOI 10.1055/a-0808-3186; Fukunaga S, 2017, GASTROINTEST ENDOSC, V85, P143, DOI 10.1016/j.gie.2016.06.049; Gupta S, 2020, GASTROENTEROLOGY, V158, P693, DOI 10.1053/j.gastro.2019.12.003; Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2; Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9; Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830; Jaiswal AK, 2021, IEEE ACCESS, V9, P70606, DOI 10.1109/ACCESS.2021.3078241; Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20107, 10.3322/caac.21492, 10.3322/caac.20115]; Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029; Lee S, 2020, J EUR ACAD DERMATOL, V34, P1842, DOI 10.1111/jdv.16185; Nagahama T, 2018, ENDOSCOPY, V50, P566, DOI 10.1055/s-0044-100790; Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771; Pimentel-Nunes P, 2019, ENDOSCOPY, V51, P365, DOI 10.1055/a-0859-1883; Rawla P, 2019, GASTROENTEROL REV, V14, P26, DOI 10.5114/pg.2018.80001; Rugge M, 2019, GUT, V68, P11, DOI 10.1136/gutjnl-2017-314600; Rugge M, 2017, CLIN GASTROENTEROL H, V15, P1833, DOI 10.1016/j.cgh.2017.05.023; Sakamoto T, 2020, TRANSL LUNG CANCER R, V9, P2255, DOI 10.21037/tlcr-20-591; Serag A, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00185; Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z; Sumiyama K, 2017, GASTRIC CANCER, V20, pS20, DOI 10.1007/s10120-016-0659-4; Suzuki H, 2019, DIGEST ENDOSC, V31, P30, DOI 10.1111/den.13246; Tanabe S, 2017, GASTRIC CANCER, V20, pS45, DOI 10.1007/s10120-016-0664-7; Tang DH, 2020, EBIOMEDICINE, V62, DOI 10.1016/j.ebiom.2020.103146; Tayal A, 2022, MULTIMEDIA SYST, V28, P1417, DOI 10.1007/s00530-021-00769-7; Tizhoosh Hamid Reza, 2018, J Pathol Inform, V9, P38, DOI 10.4103/jpi.jpi_53_18; Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190; Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037; Wang SQ, 2020, CHINESE MED J-PEKING, V133, P2027, DOI 10.1097/CM9.0000000000001023; Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031; Yoon HJ, 2020, CLIN ENDOSC, V53, P127, DOI 10.5946/ce.2020.046; Zhang XY, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0631-9; Zhang YB, 2018, IEEE T MED IMAGING, V37, P1370, DOI 10.1109/TMI.2018.2823083	34	9	10	3	43	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2234-943X			FRONT ONCOL	Front. Oncol.	JAN 25	2022	12								815951	10.3389/fonc.2022.815951	http://dx.doi.org/10.3389/fonc.2022.815951			10	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	YV3WV	35145918	Green Published, gold			2024-09-18	WOS:000752662400001
J	Nersisson, R; Iyer, TJ; Raj, ANJ; Rajangam, V				Nersisson, Ruban; Iyer, Tharun J.; Joseph Raj, Alex Noel; Rajangam, Vijayarajan			A Dermoscopic Skin Lesion Classification Technique Using YOLO-CNN and Traditional Feature Model	ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING			English	Article						Dermoscopic skin lesions; Convolutional neural network; YOLO; Feature fusion; Transfer learning	CANCER; FUSION; LBP	Skin cancer is one of the most deadly diseases around the world, wherein one of the three cancers is skin cancer. Early detection of skin cancer is paramount for better treatment planning. This paper investigates a Convolutional Neural Network (CNN), specifically, You Only Look Once (YOLO), to extract features from the skin lesions. The features, obtained from the CNN, are concatenated with traditional features like texture and colour features extracted from the lesion region of the input images. Later, the concatenated features are fed to a Fully Connected Network, which is trained with the specific ground truths to achieve higher classification accuracy. The proposed method improves the detection and classification of skin lesions when compared with other models and YOLO without traditional features. The performance measures of the fusion network are able to achieve the accuracy of 94%, precision of 0.85, recall of 0.88, and area under the curve of 0.95.	[Nersisson, Ruban; Iyer, Tharun J.] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India; [Joseph Raj, Alex Noel] Shantou Univ, Key Lab Digital Signal & Image Proc Guangdong Pro, Dept Elect Engn, Coll Engn, Shantou 515063, Peoples R China; [Rajangam, Vijayarajan] Vellore Inst Technol, Ctr Healthcare Adv Innovat & Res, Chennai, Tamil Nadu, India	Vellore Institute of Technology (VIT); VIT Vellore; Shantou University; Vellore Institute of Technology (VIT); VIT Chennai	Raj, ANJ (corresponding author), Shantou Univ, Key Lab Digital Signal & Image Proc Guangdong Pro, Dept Elect Engn, Coll Engn, Shantou 515063, Peoples R China.	jalexnoel@stu.edu.cn	R, VIJAYARAJAN/G-8581-2015; noel, alex/V-6663-2019; Nersisson, Ruban/D-3764-2019	VIJAYARAJAN, R/0000-0003-0562-4472; Joseph Raj, Alex Noel/0000-0003-1505-3159; Iyer, Tharun/0000-0002-0647-988X	Scientific Research Grant of Shantou University, China [NTF17016]	Scientific Research Grant of Shantou University, China	This research was financially supported by the Scientific Research Grant of Shantou University, China, Grant No: NTF17016.	Abuzaghleh O, 2015, IEEE J TRANSL ENG HE, V3, DOI 10.1109/JTEHM.2015.2419612; Alquran, 2017, MELANOMA SKIN CANC D, P1; [Anonymous], 2018, ARXIV180705979; Ashour AS, 2018, SIGNAL IMAGE VIDEO P, V12, P1311, DOI 10.1007/s11760-018-1284-y; Baldwin L, 2013, ASIAN PAC J CANCER P, V14, P2155, DOI 10.7314/APJCP.2013.14.4.2155; Barata C, 2019, IEEE J BIOMED HEALTH, V23, P1096, DOI 10.1109/JBHI.2018.2845939; Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540; Benco M, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58692; Chao Zhu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3065, DOI 10.1109/ICPR.2010.751; Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547; Craythorne E., 2017, Medicine, V45, P431, DOI DOI 10.1016/J.MPMED.2017.04.003; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DeVries T., 2017, ARXIV170301402; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Jain S, 2015, PROCEDIA COMPUT SCI, V48, P735, DOI 10.1016/j.procs.2015.04.209; Jerant AF, 2000, AM FAM PHYSICIAN, V62, P357; Kavitha JC, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16); Li J, 2016, NEUROCOMPUTING, V182, P111, DOI 10.1016/j.neucom.2015.12.005; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Massone C, 2005, CURR OPIN ONCOL, V17, P147, DOI 10.1097/01.cco.0000152627.36243.26; Mhaske, 2013, MELANOMA SKIN CANC D, P1; Milanova M., 2019, AM J ADV RES, V1, P3; Nezhadian FK, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P1, DOI 10.1109/AISP.2017.8324108; Peng X., 2016, ASIAN C COMPUTER VIS, P256; Pfeifer GP, 2012, PHOTOCH PHOTOBIO SCI, V11, P90, DOI 10.1039/c1pp05144j; Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3; Sáez A, 2016, IEEE T MED IMAGING, V35, P1036, DOI 10.1109/TMI.2015.2506270; Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423; Singh G, 2018, J INF TECHNOL RES, V11, P91, DOI 10.4018/JITR.2018010106; Situ N, 2008, IEEE ENG MED BIO, P3110, DOI 10.1109/IEMBS.2008.4649862; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sotoodeh M, 2019, EXPERT SYST APPL, V127, P342, DOI 10.1016/j.eswa.2019.03.020; Sreelatha T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1334-1; Tracey EH, 2019, DERMATOL CLIN, V37, P73, DOI 10.1016/j.det.2018.08.003; Pham TC, 2018, LECT NOTES ARTIF INT, V10752, P573, DOI 10.1007/978-3-319-75420-8_54; Wolner ZJ, 2017, DERMATOL CLIN, V35, P417, DOI 10.1016/j.det.2017.06.003; INT C MATH COMP; 2018 52 ANN C INF SC	40	11	12	2	32	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2193-567X	2191-4281		ARAB J SCI ENG	Arab. J. Sci. Eng.	OCT	2021	46	10					9797	9808		10.1007/s13369-021-05571-1	http://dx.doi.org/10.1007/s13369-021-05571-1		APR 2021	12	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	UX1NJ					2024-09-18	WOS:000637689800005
J	Manoj, SO; Abirami, KR; Victor, A; Arya, M				Manoj, S. Oswalt; Abirami, K. Rama; Victor, Akila; Arya, Monika			AUTOMATIC DETECTION AND CATEGORIZATION OF SKIN LESIONS FOR EARLY DIAGNOSIS OF SKIN CANCER USING YOLO-V3-DCNN ARCHITECTURE	IMAGE ANALYSIS & STEREOLOGY			English	Article						skin cancer; Deep Convolutional Neural Network (DCNN); deep learning; you only look once (YOLO-v3)	NEURAL-NETWORK; MELANOMA; CLASSIFICATION; FEATURES; IMAGES	Malignant melanoma is a type of benign skin cancer that is the most lethal due to its rapid development and affects a large number of people worldwide. Also, it is one of the deadliest diseases in the world. Moreover, existing research has stated that risk factors may be significantly decreased by making it nearly curable if diagnosed early on. This prompt identification and categorization necessitate using an automated system, even though the existing method is rather difficult. Hence our research employs the YOLO v3 -DCNN architecture to discover and categorize the deadliest kinds of skin cancer. Initially, YOLO v3 generates the feature map; simultaneously, colour features are extracted using colour moments with QuadHistogram, whereas Grey Level Co-occurrence Matrix (GLCM) with Redundant Contourlet Transform(RCT) gener-ated texture features, and both (colour and texture) features get fused. Then, fused features are fed into the Deep Convolutional Neural Network (DCNN), which classifies the different types of skin cancer. Finally, our proposed approach is compared with the current works. Consequently, our proposed YOLO-v3 -DCNN has greater accuracy when contrasted with the baseline techniques.	[Manoj, S. Oswalt] Sri Krishna Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamilnadu, India; [Abirami, K. Rama] Dayananda Sagar Acad Technol & Management, Dept Informat Sci & Engn, Bengaluru, India; [Victor, Akila] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India; [Arya, Monika] Bhilai Inst Technol, Dept Comp Sci & Engn, Durg CG, Chhattisgarh 491001, India	Sri Krishna College of Engineering & Technology; Vellore Institute of Technology (VIT); VIT Vellore; Bhilai Institute of Technology	Victor, A (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.	oswaltmanojibm@gmail.com; ramaabirami1988@gmail.com; a.akilavictor@gmail.com; arya.akshara@gmail.com	ARYA, MONIKA/R-9976-2018; Victor, Akila/HKE-4747-2023; K, Dr.RAMA ABIRAMI/ADC-6905-2022; Manoj S, Dr. Oswalt/E-4608-2018	Manoj S, Dr. Oswalt/0000-0001-8251-2920				Adegun AA, 2020, IEEE ACCESS, V8, P150377, DOI 10.1109/ACCESS.2020.3016651; Akram T, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00216-y; Albahli S, 2020, IEEE ACCESS, V8, P198403, DOI 10.1109/ACCESS.2020.3035345; [Anonymous], 2019, HEART FAIL; [Anonymous], 2017, RES J PHARM TECHNOL; [Anonymous], 2018, SOMATIC GENETICS HUM; [Anonymous], 2014, ARCH OR ON 0625; Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473; Bisla D, 2019, IEEE COMPUT SOC CONF, P2720, DOI 10.1109/CVPRW.2019.00330; Byrd AL, 2018, NAT REV MICROBIOL, V16, P143, DOI 10.1038/nrmicro.2017.157; cancer, Key statistics for melanoma skin cancer; CASCINELLI N, 1987, J AM ACAD DERMATOL, V16, P361, DOI 10.1016/S0190-9622(87)70050-4; Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003; Cohen VML, 2018, MIDDLE EAST AFR J OP, V25, P91, DOI 10.4103/meajo.MEAJO_96_18; Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1; Elgamal M, 2013, INT J ADV COMPUT SC, V4, P287; ERCAL F, 1994, IEEE T BIO-MED ENG, V41, P837, DOI 10.1109/10.312091; Farag A, 2017, IEEE T IMAGE PROCESS, V26, P386, DOI 10.1109/TIP.2016.2624198; Hu K, 2019, BIOMED SIGNAL PROCES, V51, P200, DOI 10.1016/j.bspc.2019.02.018; Jain S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21238142; Khan MA, 2020, NEURAL COMPUT APPL, V32, P15929, DOI 10.1007/s00521-019-04514-0; Khan MA, 2021, PATTERN RECOGN LETT, V143, P58, DOI 10.1016/j.patrec.2020.12.015; Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034; Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837; Khodaei H, 2018, APPL THERM ENG, V137, P395, DOI 10.1016/j.applthermaleng.2018.04.008; Kumar NVR, 2022, INT J PERVASIVE COMP, V18, P407, DOI 10.1108/IJPCC-08-2020-0107; Maglogiannis I, 2015, COMPUT METH PROG BIO, V118, P124, DOI 10.1016/j.cmpb.2014.12.001; Mukherjee Soumen, 2019, Recent Trends in Signal and Image Processing. Proceedings of ISSIP 2018. Advances in Intelligent Systems and Computing (AISC 922), P31, DOI 10.1007/978-981-13-6783-0_4; Narasimhan K, 2016, INT J BIOMED ENG TEC, V20, P243, DOI 10.1504/IJBET.2016.075427; Nersisson R, 2021, ARAB J SCI ENG, V46, P9797, DOI 10.1007/s13369-021-05571-1; Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005; O'Sullivan DE, 2019, CANCER EPIDEMIOL, V59, P1, DOI 10.1016/j.canep.2019.01.004; Parameshachari BD, 2020, IOP C SER MAT SCI, V925; Rashid H, 2019, IEEE ENG MED BIO, P916, DOI [10.1109/EMBC.2019.8857905, 10.1109/embc.2019.8857905]; Razmjooy N, 2012, COMPUT MATH APPL, V63, P268, DOI 10.1016/j.camwa.2011.11.019; Rokhana Rika, 2020, 2020 International Electronics Symposium (IES), P481, DOI 10.1109/IES50839.2020.9231676; Saeed J., 2021, Journal of Applied Science and Technology Trends, V2, P41, DOI [DOI 10.38094/JASTT20189, 10.38094/jastt20189]; Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161; Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072; Wighton P, 2011, IEEE T INF TECHNOL B, V15, P622, DOI 10.1109/TITB.2011.2150758; Sikkandar MY, 2021, J AMB INTEL HUM COMP, V12, P3245, DOI 10.1007/s12652-020-02537-3; Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166; Zhang N, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101756	43	1	1	0	6	INT SOC STEREOLOGY	LJUBJANA	INST ANATOMY, MEDICAL FACULTY, KORYTKOVA 2, LJUBJANA, SL-1000, SLOVENIA	1580-3139			IMAGE ANAL STEREOL	Image Anal. Stereol.		2023	42	2					101	117		10.105566/ias.2773	http://dx.doi.org/10.105566/ias.2773			17	Materials Science, Multidisciplinary; Mathematics, Applied; Mechanics; Imaging Science & Photographic Technology	Science Citation Index Expanded (SCI-EXPANDED)	Materials Science; Mathematics; Mechanics; Imaging Science & Photographic Technology	M4XE3					2024-09-18	WOS:001030249200005
J	Yeh, JY; Chan, SW				Yeh, Jinn-Yi; Chan, Siwa			Deep Learning YOLO-based CAD for Breast Cancer Detection in Digital Breast Tomosynthesis	BASIC & CLINICAL PHARMACOLOGY & TOXICOLOGY			English	Meeting Abstract									[Yeh, Jinn-Yi] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan; [Chan, Siwa] Taichung Tzu Chi Hosp, Dept Med Imaging, Taichung, Taiwan	National Chiayi University; Buddhist Tzu Chi General Hospital; Taichung Tzu Chi Hospital			, Novice/GPS-8420-2022		Ministry of Science and Technology [MOST 107-2221-E-415-011]	Ministry of Science and Technology(Spanish Government)	We are grateful to the Ministry of Science and Technology for the research grant (MOST 107-2221-E-415-011).		0	0	0	0	13	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1742-7835	1742-7843		BASIC CLIN PHARMACOL	Basic Clin. Pharmacol. Toxicol.	FEB	2020	126			1	SI	055	40	41						2	Pharmacology & Pharmacy; Toxicology	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Toxicology	KF8MY					2024-09-18	WOS:000509492400056
J	Wang, SF; Xie, J; Cui, YR; Chen, ZJ				Wang, Shaofang; Xie, Jun; Cui, Yanrong; Chen, Zhongju			Colorectal Polyp Detection Model by Using Super-Resolution Reconstruction and YOLO	ELECTRONICS			English	Article						polyp detection; colonoscopy; medical image processing; deep learning; SRGAN; YOLO; ACmix; Res2net	CANCER DIAGNOSIS; CLASSIFICATION; ACCURATE	Colorectal cancer (CRC) is the second leading cause of cancer-related deaths worldwide. Colonoscopy is the primary method to prevent CRC. However, traditional polyp detection methods face problems such as low image resolution and the possibility of missing polyps. In recent years, deep learning techniques have been extensively employed in the detection of colorectal polyps. However, these algorithms have not yet addressed the issue of detection in low-resolution images. In this study, we propose a novel YOLO-SRPD model by integrating SRGAN and YOLO to address the issue of low-resolution colonoscopy images. Firstly, the SRGAN with integrated ACmix is used to convert low-resolution images to high-resolution images. The generated high-resolution images are then used as the training set for polyp detection. Then, the C3_Res2Net is integrated into the YOLOv5 backbone to enhance multiscale feature extraction. Finally, CBAM modules are added before the prediction head to enhance attention to polyp information. The experimental results indicate that YOLO-SRPD achieves a mean average precision (mAP) of 94.2% and a precision of 95.2%. Compared to the original model (YOLOv5), the average accuracy increased by 1.8% and the recall rate increased by 5.6%. These experimental results confirm that YOLO-SRPD can address the low-resolution problem during colorectal polyp detection and exhibit exceptional robustness.	[Wang, Shaofang; Xie, Jun; Cui, Yanrong; Chen, Zhongju] Yangtze Univ, Sch Comp Sci, Jingzhou 434023, Peoples R China	Yangtze University	Wang, SF (corresponding author), Yangtze Univ, Sch Comp Sci, Jingzhou 434023, Peoples R China.	wangshaofang2022@yangtzeu.edu.cn; 2022710617@yangtzeu.edu.cn; cyanr@yangtzeu.edu.cn; chenzj@yangtzeu.edu.cn			National Natural Science Foundation of China General Program [62077018]; Hubei Provincial Education Department	National Natural Science Foundation of China General Program(National Natural Science Foundation of China (NSFC)); Hubei Provincial Education Department	This research was funded by the National Natural Science Foundation of China General Program under Grant 62077018 and the Hubei Provincial Education Department.	Abadir AP, 2020, CLIN ENDOSC, V53, P132; Ali S., 2019, arXiv; Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007; Bishop CM, 2006, Springer google schola, V2, P1122; Carrinho P, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120834; Chen BL, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103019; Chou YC, 2023, MULTIMED TOOLS APPL, V82, P16817, DOI 10.1007/s11042-022-13995-6; ELKarazle K, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031225; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Ghose P, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17138-3; Glover B, 2020, CLIN TRANSL GASTROEN, V11, DOI 10.14309/ctg.0000000000000130; Hegazy MAA, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104313; Jass JR, 2004, CLIN GASTROENTEROL H, V2, P1, DOI 10.1016/S1542-3565(03)00284-2; Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37; Jie Luyang, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P2169, DOI 10.1109/EMBC48229.2022.9871952; Kavitha MS, 2022, CANCERS, V14, DOI 10.3390/cancers14153707; Kim BS, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-62494-1; Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004; Laddha M., 2019, P 2019 4 INT C BIOME, P55; le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Mahmood T, 2024, EXPERT SYST APPL, V249, DOI 10.1016/j.eswa.2024.123747; Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7; Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659; Pavlou E, 2024, EXP DERMATOL, V33, DOI 10.1111/exd.15019; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Sánchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923; Shi JS, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2021.106578; Shi Y., 2013, Ph.D. Thesis; Siegel RL, 2023, CA-CANCER J CLIN, V73, P17, DOI 10.3322/caac.21763; Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3; Soberanis-Mukul R.D., 2020, arXiv; Su YZ, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104699; Su YZ, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103903; Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003; Tan L, 2024, TSINGHUA SCI TECHNOL, V29, P1524, DOI 10.26599/TST.2023.9010126; Tan M., 2020, P IEEE CVF C COMP VI, P10778, DOI DOI 10.48550/ARXIV.1911.09070; Tang CP, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020170; Tang CP, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040968; Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019; Wang CY, 2024, Arxiv, DOI arXiv:2402.13616; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Yang K, 2022, ALEX ENG J, V61, P917, DOI 10.1016/j.aej.2021.04.072; Yasmin F, 2023, IEEE ACCESS, V11, P97605, DOI 10.1109/ACCESS.2023.3312729; Yoshimura T, 2021, INT J RADIAT ONCOL, V111, pE121, DOI 10.1016/j.ijrobp.2021.07.541; Yu T, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104953; Zeng YF, 2020, THERANOSTICS, V10, P2587, DOI 10.7150/thno.40099; Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026; Zhang SC, 2024, COMPUT METH PROG BIO, V250, DOI 10.1016/j.cmpb.2024.108178; Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133; Zhu PC, 2024, FRONT COMPUT NEUROSC, V18, DOI 10.3389/fncom.2024.1356447	52	0	0	11	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2024	13	12							2298	10.3390/electronics13122298	http://dx.doi.org/10.3390/electronics13122298			17	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	WP4P0		gold			2024-09-18	WOS:001256067500001
J	Liu, KH				Liu, Kehong			STBi-YOLO: A Real-Time Object Detection Method for Lung Nodule Recognition	IEEE ACCESS			English	Article						Lung nodules; object detection; YOLO-v5; bidirectional feature pyramid; stochastic-pooling	FALSE-POSITIVE REDUCTION; PULMONARY NODULES; NEURAL-NETWORKS; CT IMAGES; SYSTEM	Lung cancer is the most prevalent and deadly oncological disease in the world, but a timely detection of lung nodules can greatly improve the survival rate of this disease. However, due to the tiny size of lung nodules and inconspicuous edges, lung nodules are not easily distinguished by naked eyes thus medical image diagnosticians are prone to misdiagnosis simply based on their own experiences and subjective judgements. In recent years, the machine-learning-based image processing techniques find their wide applications in the field of medical diagnosis, and have been proved to be an efficient way to aid diagnosticians to accurately identify subtle lesions in images. To accurately recognize lung nodules in CT images, in this paper, we propose an approach, called STBi-YOLO. This approach stems from YOLO-v5, but makes significant improvements from three dimensions-we first use the spatial pyramid pooling network that is based on stochastic-pooling method to modify the basic network structure of YOLO-v5; then apply a bidirectional feature pyramid network to perform multi-scale feature fusion; finally improve the loss function of the YOLO-v5 and adopt the EIoU function to optimize the training model. To evaluate our approach, we compare STBi-YOLO with YOLO-v3, YOLO-v4, YOLO-v5, and multiple leading object detection models, such as Faster R-CNN and SSD. The experiments show that STBi-YOLO achieves an accuracy of 96.1% and a recall rate of 93.3% for the detection of lung nodules, while producing a 4 x smaller model size in memory consumption than YOLO-v5 and exhibiting comparable results in terms of mAP and time cost against Faster R-CNN and SSD.	[Liu, Kehong] Xian Univ Sci & Technol, Coll Comp Sci & Technol, Xian 710054, Shaanxi, Peoples R China	Xi'an University of Science & Technology	Liu, KH (corresponding author), Xian Univ Sci & Technol, Coll Comp Sci & Technol, Xian 710054, Shaanxi, Peoples R China.	1292692089@qq.com		Liu, Kehong/0000-0003-4252-6935	Science and Technology Plan Project of Shaanxi [2017JM6105]; Seclover Corporation; Ministry of Education Collaborative Education Project; HUAWEI Corporation	Science and Technology Plan Project of Shaanxi; Seclover Corporation; Ministry of Education Collaborative Education Project; HUAWEI Corporation(Huawei Technologies)	This work was supported in part by the Science and Technology Plan Project of Shaanxi under Grant 2017JM6105, in part by the Ministry of Education Collaborative Education Project with Seclover Corporation, and in part by the Ministry of Education Collaborative Education Project with HUAWEI Corporation.	Bingzhen Li, 2021, Proceedings of the 2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA), P137, DOI 10.1109/ICPECA51329.2021.9362714; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Bulò SR, 2017, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR.2017.749; Chaitanya B. K., 2020, 2020 15th International Conference on Protection and Automation of Power Systems (IPAPS), P149, DOI 10.1109/IPAPS52181.2020.9375620; Chen XL, 2017, Arxiv, DOI arXiv:1702.02138; Dai JF, 2016, ADV NEUR IN, V29; Dashdorj Z, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2808-3; de Carvalho AO, 2017, MED BIOL ENG COMPUT, V55, P1199, DOI 10.1007/s11517-016-1582-x; Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502; Ebner L, 2017, MED PHYS, V44, P3483, DOI 10.1002/mp.12277; Ghafoorian M, 2017, NEUROIMAGE-CLIN, V14, P391, DOI 10.1016/j.nicl.2017.01.033; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hamidian S, 2017, PROC SPIE, V10134, DOI 10.1117/12.2255795; He K., 2017, IEEE I CONF COMP VIS, P2961, DOI DOI 10.1109/ICCV.2017.322; He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824; Hooda R, 2019, BIOMED ENG LETT, V9, P109, DOI [10.1007/s13534-018-0086-z, 10.1007/s13534-018-0086-z(0123456789().,-volV)(0123456789,-().volV)]; Huang QH, 2020, IEEE T KNOWL DATA EN, V32, P728, DOI 10.1109/TKDE.2019.2891622; Javaid M, 2016, COMPUT METH PROG BIO, V135, P125, DOI 10.1016/j.cmpb.2016.07.031; Khordehchi EA, 2017, IMAGE ANAL STEREOL, V36, P65, DOI 10.5566/ias.1679; Lanfredi RB, 2019, LECT NOTES COMPUT SC, V11769, P685, DOI 10.1007/978-3-030-32226-7_76; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Liu JK, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0669-0; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Nithila EE, 2017, ENG SCI TECHNOL, V20, P1192, DOI 10.1016/j.jestch.2016.12.006; Painsky A, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23060773; Pang YW, 2018, IEEE T NEUR NET LEAR, V29, P1587, DOI 10.1109/TNNLS.2017.2676130; Qilong Li, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P762, DOI 10.1109/ICIS.2018.8466432; Redmon J., 2018, arXiv; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001; Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809; Singh B, 2018, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2018.00119; Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660; Syaharuddin A. Z., 2021, 2021 INT C ARTIFICIA, P1, DOI [10.1109/AIMS52415.2021.9466014, DOI 10.1109/AIMS52415.2021.9466014]; Teramoto A, 2018, INTEL SYST REF LIBR, V140, P87, DOI 10.1007/978-3-319-68843-5_4; Wang Y, 2020, J X-RAY SCI TECHNOL, V28, P1, DOI 10.3233/XST-190581; Wang ZQ, 2018, COMPUT METH PROG BIO, V162, P197, DOI 10.1016/j.cmpb.2018.05.028; Yan FX, 2021, 2021 4TH INTERNATIONAL CONFERENCE ON ROBOTICS, CONTROL AND AUTOMATION ENGINEERING (RCAE 2021), P21, DOI 10.1109/RCAE53607.2021.9638930; Zhang Y, 2021, ARXIV; Zhao TY, 2018, I S BIOMED IMAGING, P505, DOI 10.1109/ISBI.2018.8363626	45	18	18	44	229	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2022	10						75385	75394		10.1109/ACCESS.2022.3192034	http://dx.doi.org/10.1109/ACCESS.2022.3192034			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	3D3DC		gold			2024-09-18	WOS:000829185600001
C	Al-masni, MA; Al-antari, MA; Park, JM; Gi, G; Kim, TY; Rivera, P; Valarezo, E; Han, SM; Kim, TS			IEEE	Al-masni, M. A.; Al-antari, M. A.; Park, J. M.; Gi, G.; Kim, T. Y.; Rivera, P.; Valarezo, E.; Han, S. -M.; Kim, T. -S.			Detection and Classification of the Breast Abnormalities in Digital Mammograms via Regional Convolutional Neural Network	2017 39TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY (EMBC)	IEEE Engineering in Medicine and Biology Society Conference Proceedings		English	Proceedings Paper	39th Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society (EMBC)	JUL 11-15, 2017	SOUTH KOREA	IEEE Engn Med & Biol Soc, PubMed, MEDLINE, Korean Soc Med & Biol Engn		Breast Cancer; Mass Detection and Classification; Computer Aided Diagnosis; Deep Learning; YOLO		Automatic detection and classification of the masses in mammograms are still a big challenge and play a crucial role to assist radiologists for accurate diagnosis. In this paper, we propose a novel computer-aided diagnose (CAD) system based on one of the regional deep learning techniques: a ROI-based Convolutional Neural Network (CNN) which is called You Only Look Once (YOLO). Our proposed YOLO-based CAD system contains four main stages: mammograms preprocessing, feature extraction utilizing multi convolutional deep layers, mass detection with confidence model, and finally mass classification using fully connected neural network (FC-NN). A set of training mammograms with the information of ROI masses and their types are used to train YOLO. The trained YOLO-based CAD system detects the masses and classifies their types into benign or malignant. Our results show that the proposed YOLO-based CAD system detects the mass location with an overall accuracy of 96.33%. The system also distinguishes between benign and malignant lesions with an overall accuracy of 85.52%. Our proposed system seems to be feasible as a CAD system capable of detection and classification at the same time. It also overcomes some challenging breast cancer cases such as the mass existing in the pectoral muscles or dense regions.	[Al-masni, M. A.; Al-antari, M. A.; Park, J. M.; Gi, G.; Kim, T. Y.; Rivera, P.; Valarezo, E.; Han, S. -M.; Kim, T. -S.] Kyung Hee Univ, Dept Biomed Engn, Yongin, Gyeonggi, South Korea; [Valarezo, E.] Escuela Super Politecn Litoral, ESPOL, FIEC, Campus Gustavo Galindo Via Perimetral, Guayaquil, Ecuador	Kyung Hee University; Escuela Superior Politecnica del Litoral	Kim, TS (corresponding author), Kyung Hee Univ, Dept Biomed Engn, Yongin, Gyeonggi, South Korea.	tskim@khu.ac.kr	Al-masni, Mohammed/AFR-0105-2022; Han, Seungmoo/KIC-1598-2024; Añazco, Edwin/AAH-1458-2021; Al-antari, Prof. Mugahed A./M-5602-2018	AL-MASNI, MOHAMMED/0000-0002-1548-965X; Valarezo Anazco, Edwin/0000-0003-0077-8528; Rivera, Patricio/0000-0001-6440-5478; Al-antari, Prof. Mugahed A./0000-0002-4457-4407	Center for Integrated Smart Sensors - Ministry of Science, ICT & Future Planning as Global Frontier Project [CISS-2011-0031863]; National Research Foundation of Korea (NRF) grant - Korea government (MEST) [2014R1A2A2A09052449]; International Collaborative Research and Development Program - Ministry of Trade, industry, and Energy (MOTIE, Korea) [N0002252]	Center for Integrated Smart Sensors - Ministry of Science, ICT & Future Planning as Global Frontier Project(Ministry of Science, ICT & Future Planning, Republic of Korea); National Research Foundation of Korea (NRF) grant - Korea government (MEST)(National Research Foundation of KoreaMinistry of Education, Science & Technology (MEST), Republic of Korea); International Collaborative Research and Development Program - Ministry of Trade, industry, and Energy (MOTIE, Korea)(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea)	This work was supported by the Center for Integrated Smart Sensors funded by the Ministry of Science, ICT & Future Planning as Global Frontier Project (CISS-2011-0031863). This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MEST) (2014R1A2A2A09052449). This work was also supported by International Collaborative Research and Development Program (funded by the Ministry of Trade, industry, and Energy (MOTIE, Korea) (N0002252)	Akselrod-Ballin A., 2016, REGION BASED CONVOLU, P197; Al-antari MA, 2016, GLOB C ENG APPL SCI, P1306; Al-antari MA., 2017, J SCI ENG, V04, P114; [Anonymous], P 4 WORLD C APPL SCI; Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014; Bilanovic D., 2010, US Patent, Patent No. 7; Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160; Guo Q, 2016, NEUROCOMPUTING, V184, P78, DOI 10.1016/j.neucom.2015.07.135; Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212; Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060; Kallenberg M., 2010, COMPARISON TILT CORR; Kooi T, 2016, LECT NOTES COMPUT SC, V9699, P51, DOI 10.1007/978-3-319-41546-8_7; Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8; Redmon J., 2016, Darknet: Open Source Neural Networks in C; Redmon J., 2016, P IEEE C COMP VIS PA, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/cvpr.2016.91, 10.1109/CVPR.2016.91]; Siegel RL., CA Cancer J Clin, V72, P7	16	65	70	0	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1557-170X	1558-4615	978-1-5090-2809-2	IEEE ENG MED BIO			2017							1230	1233						4	Biophysics; Engineering, Biomedical	Conference Proceedings Citation Index - Science (CPCI-S)	Biophysics; Engineering	BJ7CZ	29060098				2024-09-18	WOS:000427085301170
J	Mohammed, AD; Ekmekci, D				Mohammed, Ahmed Dhahi; Ekmekci, Dursun			Breast Cancer Diagnosis Using YOLO-Based Multiscale Parallel CNN and Flattened Threshold Swish	APPLIED SCIENCES-BASEL			English	Article						breast cancer detection; breast cancer classification; mammogram screening; Contrast Limited Adaptive Histogram Equalization (CLAHE); You Only Look Once (YOLO); DenseNet; InceptionNet; Flatten Threshold Swish (FTS); INbreast; CBIS-DDSM	CLASSIFICATION	In the field of biomedical imaging, the use of Convolutional Neural Networks (CNNs) has achieved impressive success. Additionally, the detection and pathological classification of breast masses creates significant challenges. Traditional mammogram screening, conducted by healthcare professionals, is often exhausting, costly, and prone to errors. To address these issues, this research proposes an end-to-end Computer-Aided Diagnosis (CAD) system utilizing the 'You Only Look Once' (YOLO) architecture. The proposed framework begins by enhancing digital mammograms using the Contrast Limited Adaptive Histogram Equalization (CLAHE) technique. Then, features are extracted using the proposed CNN, leveraging multiscale parallel feature extraction capabilities while incorporating DenseNet and InceptionNet architectures. To combat the 'dead neuron' problem, the CNN architecture utilizes the 'Flatten Threshold Swish' (FTS) activation function. Additionally, the YOLO loss function has been enhanced to effectively handle lesion scale variation in mammograms. The proposed framework was thoroughly tested on two publicly available benchmarks: INbreast and CBIS-DDSM. It achieved an accuracy of 98.72% for breast cancer classification on the INbreast dataset and a mean Average Precision (mAP) of 91.15% for breast cancer detection on the CBIS-DDSM. The proposed CNN architecture utilized only 11.33 million parameters for training. These results highlight the proposed framework's ability to revolutionize vision-based breast cancer diagnosis.	[Mohammed, Ahmed Dhahi; Ekmekci, Dursun] Karabuk Univ, Fac Comp & Informat, Dept Comp Engn, TR-78050 Karabuk, Turkiye	Karabuk University	Mohammed, AD; Ekmekci, D (corresponding author), Karabuk Univ, Fac Comp & Informat, Dept Comp Engn, TR-78050 Karabuk, Turkiye.	ahmed.dhahi89@gmail.com; dekmekci@karabuk.edu.tr	EKMEKCI, Dursun/AAI-7264-2021	EKMEKCI, Dursun/0000-0002-9830-7793				Abduljabbar M., 2023, Int. J. Image Graph. Signal Process, V5, P17, DOI [10.5815/ijigsp.2023.05.02, DOI 10.5815/IJIGSP.2023.05.02]; Alghamdi H, 2023, AGRICULTURE-BASEL, V13, DOI 10.3390/agriculture13051072; Anand V, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119230; Ashraf MH, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101657; Baccouche A, 2021, CMC-COMPUT MATER CON, V69, P1407, DOI 10.32604/cmc.2021.018461; Chakravarthy SRS, 2022, IRBM, V43, P49, DOI 10.1016/j.irbm.2020.12.004; Do QV, 2024, EXPERT SYST APPL, V241, DOI 10.1016/j.eswa.2023.122742; Elkorany AS, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29875-4; Escorcia-Gutierrez J, 2022, CMC-COMPUT MATER CON, V71, P4221, DOI 10.32604/cmc.2022.022322; Hasan AM, 2024, EXPERT SYST APPL, V236, DOI 10.1016/j.eswa.2023.121371; Ibrokhimov B, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094616; Jeon W, 2021, ADV COMPUT, V122, P167, DOI 10.1016/bs.adcom.2020.11.003; Jessica T., 2023, J. Med. Imaging Radiat. Sci, V54, pS35, DOI [10.1016/j.jmir.2023.06.129, DOI 10.1016/J.JMIR.2023.06.129]; Kang D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03516-0; Khan AI, 2023, MEASUREMENT, V218, DOI 10.1016/j.measurement.2023.113230; Koh J, 2022, CLIN BREAST CANCER, V22, P26, DOI 10.1016/j.clbc.2021.04.015; Kratkiewicz K, 2022, J CLIN MED, V11, DOI 10.3390/jcm11051165; Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177; Lemons K, 2023, INT J UNDERGRADUATE, V12, P10, DOI [10.7710/2168-0620.0287, DOI 10.7710/2168-0620.0287]; Loizidou K, 2023, COMPUT BIOL MED, V153, DOI 10.1016/j.compbiomed.2023.106554; Malebary SJ, 2021, IEEE ACCESS, V9, P55312, DOI 10.1109/ACCESS.2021.3071297; Meng MZ, 2022, FUTURE ONCOL, V18, P4361, DOI 10.2217/fon-2022-0593; Moloney BM, 2022, ACAD RADIOL, V29, pS211, DOI 10.1016/j.acra.2021.06.012; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/iwssip48289.2020.9145130, 10.1109/IWSSIP48289.2020.9145130]; Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204; Salama WM, 2021, ALEX ENG J, V60, P4701, DOI 10.1016/j.aej.2021.03.048; Sechopoulos I, 2021, SEMIN CANCER BIOL, V72, P214, DOI 10.1016/j.semcancer.2020.06.002; Selvi A, 2023, INTELL AUTOM SOFT CO, V36, P1257, DOI 10.32604/iasc.2023.029850; Soulami KB, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103696; Su YY, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106903; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003; Ul Haq I, 2022, J KING SAUD UNIV-COM, V34, P3310, DOI 10.1016/j.jksuci.2022.03.023; Vijayan Devi, 2023, Procedia Computer Science, P393, DOI 10.1016/j.procs.2023.01.022; Wen X, 2024, BIOCYBERN BIOMED ENG, V44, P119, DOI 10.1016/j.bbe.2024.01.002; Xie LZ, 2020, KNOWL-BASED SYST, V208, DOI 10.1016/j.knosys.2020.106465; Zhang LL, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116273; Zhao JH, 2022, MULTIMED TOOLS APPL, V81, P19257, DOI 10.1007/s11042-021-10505-y	39	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	7							2680	10.3390/app14072680	http://dx.doi.org/10.3390/app14072680			16	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	NN4B7		gold			2024-09-18	WOS:001201106200001
J	Wu, NK; Jia, DY; Zhang, CW; Li, ZQ				Wu, Nengkai; Jia, Dongyao; Zhang, Chuanwang; Li, Ziqi			Cervical cell extraction network based on optimized yolo	MATHEMATICAL BIOSCIENCES AND ENGINEERING			English	Article						cervical cells; yolo; overlapping cell; deep learning; object detection	UNSUPERVISED SEGMENTATION	Early screening for cervical cancer is a common form of cancer prevention. In the microscopic images of cervical cells, the number of abnormal cells is small, and some abnormal cells are heavily stacked. How to solve the segmentation of highly overlapping cells and realize the identification of single cells from overlapping cells is still a heavy task. Therefore, this paper proposes an object detection algorithm of Cell_yolo to effectively and accurately segment overlapping cells. Cell_yolo adopts a simplified network structure and improves the maximum pooling operation, so that the information of the image is preserved to the greatest extent during the model pooling process. Aiming at the characteristics of many overlapping cells in cervical cell images, a non-maximum suppression method of center distance is proposed to prevent the overlapping cell detection frame from being deleted by mistake. At the same time, the loss function is improved and the focus loss function is added to alleviate the imbalance of positive and negative samples in the training process. Experiments are conducted on a private dataset (BJTUCELL). Experiments have verified that the Cell_yolo model has the advantages of low computational complexity and high detection accuracy, and it is superior to common network models such as YOLOv4 and Faster_RCNN.	[Wu, Nengkai; Jia, Dongyao; Zhang, Chuanwang; Li, Ziqi] Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun, Beijing 100044, Peoples R China	Beijing Jiaotong University	Jia, DY (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun, Beijing 100044, Peoples R China.	dongyaojia1974@163.com	li, ziqi/JDC-9141-2023		Beijing Jiaotong University;  [2022YJS020];  [W21ZZ200030];  [W19L00130]	Beijing Jiaotong University; ; ; 	Acknowledgments We acknowledge that this research is supported by the Beijing Jiaotong University (grant 2022YJS020, W21ZZ200030 and W19L00130) .	Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bin Dong, 2019, 2019 IEEE International Conferences on Ubiquitous Computing & Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS), P190, DOI 10.1109/IUCC/DSCI/SmartCNS.2019.00060; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Chankong T, 2014, COMPUT METH PROG BIO, V113, P539, DOI 10.1016/j.cmpb.2013.12.012; Davies-Oliveira JC, 2021, CLIN ONCOL-UK, V33, P550, DOI 10.1016/j.clon.2021.06.013; Diniz DN, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094091; Dong Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P507, DOI 10.1007/978-3-319-66179-7_58; Elakkiya R, 2022, MULTIMED TOOLS APPL, V81, P191, DOI 10.1007/s11042-021-10627-3; Gençtav A, 2012, PATTERN RECOGN, V45, P4151, DOI 10.1016/j.patcog.2012.05.006; Giacomello E, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207220; Harandi NM, 2010, J MED SYST, V34, P1043, DOI 10.1007/s10916-009-9323-4; Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201; Jung C, 2010, IEEE T BIO-MED ENG, V57, P2825, DOI 10.1109/TBME.2010.2060486; Kale Asli, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2399, DOI 10.1109/ICPR.2010.587; Krithiga R, 2021, ARCH COMPUT METHOD E, V28, P2607, DOI 10.1007/s11831-020-09470-w; Lee H, 2016, IEEE COMPUT SOC CONF, P1367, DOI 10.1109/CVPRW.2016.172; Li YX, 2018, IEEE ACCESS, V6, P14048, DOI 10.1109/ACCESS.2018.2808938; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Nambu Y, 2022, CANCER MED-US, V11, P520, DOI 10.1002/cam4.4460; Plissiti M E., 2013, Biomedical imaging and computational modeling in biomechanics, P1, DOI DOI 10.1007/978-94-007-4270-3_1; Plissiti ME, 2012, IEEE T IMAGE PROCESS, V21, P4568, DOI 10.1109/TIP.2012.2206041; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Xing ZQ, 2022, IET COMPUT VIS, V16, P418, DOI 10.1049/cvi2.12097	24	1	1	11	54	AMER INST MATHEMATICAL SCIENCES-AIMS	SPRINGFIELD	PO BOX 2604, SPRINGFIELD, MO 65801-2604, UNITED STATES	1547-1063	1551-0018		MATH BIOSCI ENG	Math. Biosci. Eng.		2023	20	2					2364	2381		10.3934/mbe.2023111	http://dx.doi.org/10.3934/mbe.2023111			18	Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology	9Q0ID	36899538	gold			2024-09-18	WOS:000944657100024
J	Wang, LF; Zhang, CH; Zhang, Y; Li, J				Wang, Lingfei; Zhang, Chenghao; Zhang, Yu; Li, Jin			An Automated Diagnosis Method for Lung Cancer Target Detection and Subtype Classification-Based CT Scans	BIOENGINEERING-BASEL			English	Article						lung cancer subtypes classification; lung cancer detection; YOLO V8; attention mechanism		When dealing with small targets in lung cancer detection, the YOLO V8 algorithm may encounter false positives and misses. To address this issue, this study proposes an enhanced YOLO V8 detection model. The model integrates a large separable kernel attention mechanism into the C2f module to expand the information retrieval range, strengthens the extraction of lung cancer features in the Backbone section, and achieves effective interaction between multi-scale features in the Neck section, thereby enhancing feature representation and robustness. Additionally, depth-wise convolution and Coordinate Attention mechanisms are embedded in the Fast Spatial Pyramid Pooling module to reduce feature loss and improve detection accuracy. This study introduces a Minimum Point Distance-based IOU loss to enhance correlation between predicted and ground truth bounding boxes, improving adaptability and accuracy in small target detection. Experimental validation demonstrates that the improved network outperforms other mainstream detection networks in terms of average precision values and surpasses other classification networks in terms of accuracy. These findings validate the outstanding performance of the enhanced model in the localization and recognition aspects of lung cancer auxiliary diagnosis.	[Wang, Lingfei; Zhang, Chenghao; Zhang, Yu; Li, Jin] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China	Harbin Engineering University	Li, J (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.	wanglingfei@hrbeu.edu.cn; 910381219@hrbeu.edu.cn; zhangyu04@hrbeu.edu.cn; lijin@hrbeu.edu.cn						Barbouchi K, 2023, INT J IMAG SYST TECH, V33, P1383, DOI 10.1002/ima.22858; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; del Ciello A, 2017, DIAGN INTERV RADIOL, V23, P118, DOI 10.5152/dir.2016.16187; Firdaus Q., 2020, P 2020 INT EL S IES, P643; Gao Y, 2021, J DIGIT IMAGING, V34, P605, DOI 10.1007/s10278-021-00455-0; Gupta A, 2015, IEEE INT SYMP SIGNAL, P375, DOI 10.1109/ISSPIT.2015.7394363; Han Y, 2021, EUR J NUCL MED MOL I, V48, P350, DOI 10.1007/s00259-020-04771-5; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hendrix W, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00388-5; Jacob C, 2022, INT J IMAG SYST TECH, V32, P1681, DOI 10.1002/ima.22684; Ji ZL, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11102344; Jin M., 2021, Acta Med. Sin, V34, P34; Johora F.T., 2018, GUB J. Sci. Eng. (GUBJSE), V5, P14, DOI [10.3329/gubjse.v5i1.47897, DOI 10.3329/GUBJSE.V5I1.47897]; Joseph RK, 2016, CRIT POL ECON S ASIA, P1; Khordehchi EA, 2017, IMAGE ANAL STEREOL, V36, P65, DOI 10.5566/ias.1679; Kosaraju S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-23166-0; Lian L, 2024, INT J ARTIF INTELL T, V33, DOI 10.1142/S0218213023500483; Lin Q, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac944d; Liu J, 2019, MED PHYS, V46, P3091, DOI 10.1002/mp.13551; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Loraksa C, 2022, IEEE ACCESS, V10, P65496, DOI 10.1109/ACCESS.2022.3183604; Mammeri S, 2024, MULTIMED TOOLS APPL, V83, P30965, DOI 10.1007/s11042-023-16864-y; Marentakis P, 2021, MED BIOL ENG COMPUT, V59, P215, DOI 10.1007/s11517-020-02302-w; Messay T, 2010, MED IMAGE ANAL, V14, P390, DOI 10.1016/j.media.2010.02.004; Nguyen CC, 2021, IEEE ACCESS, V9, P154740, DOI 10.1109/ACCESS.2021.3128942; Paing MP, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P302, DOI 10.1109/ECTICon.2017.8096233; Pang SC, 2020, IEEE ACCESS, V8, P4799, DOI 10.1109/ACCESS.2019.2962862; Popper H, 2024, CURR OPIN ONCOL, V36, P57, DOI 10.1097/CCO.0000000000001011; Rahal HR, 2024, INT J INF SECUR, V23, P15, DOI 10.1007/s10207-023-00733-8; Redmon J., 2018, arXiv; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rezaie AA, 2017, INT J INTERACT MULTI, V4, P15, DOI 10.9781/ijimai.2017.452; Saad M, 2017, COMPUT BIOL MED, V91, P222, DOI 10.1016/j.compbiomed.2017.10.029; Sairam P., 2014, Int. J. Ind. Electron. Control, V6, P121; Soni A., 2019, Int. J. Eng. Adv. Technol, V8, P2772; Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866; Wang SD, 2020, OPEN MED-WARSAW, V15, P190, DOI 10.1515/med-2020-0028; Xu J, 2023, COMPUT BIOL MED, V153, DOI 10.1016/j.compbiomed.2022.106470; Zhou JM, 2024, BMC CANCER, V24, DOI 10.1186/s12885-024-12052-9	40	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2306-5354		BIOENGINEERING-BASEL	Bioengineering-Basel	AUG	2024	11	8							767	10.3390/bioengineering11080767	http://dx.doi.org/10.3390/bioengineering11080767			20	Biotechnology & Applied Microbiology; Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology; Engineering	E8O5K	39199725	gold			2024-09-18	WOS:001305539300001
J	Sahafi, A; Koulaouzidis, A; Lalinia, M				Sahafi, Ali; Koulaouzidis, Anastasios; Lalinia, Mehrshad			Polypoid Lesion Segmentation Using YOLO-V8 Network in Wireless Video Capsule Endoscopy Images	DIAGNOSTICS			English	Article						polypoid lesion identification; polypoid lesion segmentation; YOLO-V8; WCE images; gastrointestinal disorders; colorectal cancer; artificial intelligence	CANCER	Gastrointestinal (GI) tract disorders are a significant public health issue. They are becoming more common and can cause serious health problems and high healthcare costs. Small bowel tumours (SBTs) and colorectal cancer (CRC) are both becoming more prevalent, especially among younger adults. Early detection and removal of polyps (precursors of malignancy) is essential for prevention. Wireless Capsule Endoscopy (WCE) is a procedure that utilises swallowable camera devices that capture images of the GI tract. Because WCE generates a large number of images, automated polyp segmentation is crucial. This paper reviews computer-aided approaches to polyp detection using WCE imagery and evaluates them using a dataset of labelled anomalies and findings. The study focuses on YOLO-V8, an improved deep learning model, for polyp segmentation and finds that it performs better than existing methods, achieving high precision and recall. The present study underscores the potential of automated detection systems in improving GI polyp identification.	[Sahafi, Ali; Lalinia, Mehrshad] Univ Southern Denmark, Dept Mech & Elect Engn, Digital & High Frequency Elect Sect, DK-5230 Odense, Denmark; [Koulaouzidis, Anastasios] Odense Univ Hosp, Surg Res Unit, DK-5000 Svendborg, Denmark; [Koulaouzidis, Anastasios] Univ Southern Denmark, Dept Clin Res, DK-5230 Odense, Denmark; [Koulaouzidis, Anastasios] OUH Svendborg Sygehus, Dept Med, DK-5700 Svendborg, Denmark; [Koulaouzidis, Anastasios] Pomeranian Med Univ, Dept Social Med & Publ Hlth, PL-70204 Szczecin, Poland	University of Southern Denmark; University of Southern Denmark; Odense University Hospital; University of Southern Denmark; University of Southern Denmark; Odense University Hospital; Pomeranian Medical University	Sahafi, A (corresponding author), Univ Southern Denmark, Dept Mech & Elect Engn, Digital & High Frequency Elect Sect, DK-5230 Odense, Denmark.	alisa@sdu.dk; anastasios.koulaouzidis@rsyd.dk; melal@sdu.dk	Koulaouzidis, Anastasios/G-9060-2014; Sahafi, Ali/AFR-3829-2022	Koulaouzidis, Anastasios/0000-0002-2248-489X; Sahafi, Ali/0000-0001-9360-9103				Amiri Z, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7863113; [Anonymous], 2004, ISO/IEC 15948:2004; [Anonymous], 2022, ISO/IEC 14496-12:2022; [Anonymous], 2013, Ultralytics; Cao CT, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250632; Data M., Kid-Medical Data and Signal Processing Laboratory; Delagah B., 2023, J. Healthc. Eng, V2023, P6076514, DOI [10.1155/2023/6076514, DOI 10.1155/2023/6076514]; Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26; Dray X, 2021, ENDOSC INT OPEN, V09, pE1754, DOI 10.1055/a-1521-4882; Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3490, DOI 10.1109/ICCV48922.2021.00349; freepik, Image Designed by Freepik; Freitas Fred., 2009, Reciis, V3, P7, DOI [10.3395/reciis.v3i1.239en, DOI 10.3395/RECIIS.V3I1.239EN]; Galdran Adrian, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P293, DOI 10.1007/978-3-030-68763-2_22; Ge Z, 2021, Arxiv, DOI arXiv:2107.08430; Goel N, 2022, SOFT COMPUT, V26, P1231, DOI 10.1007/s00500-021-06546-y; Guo Z, 2020, I S BIOMED IMAGING, P1655, DOI [10.1109/ISBI45749.2020.9098500, 10.1109/isbi45749.2020.9098500]; Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300; Hoang MC, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101878; Iakovidis DK, 2014, SCI WORLD J, DOI 10.1155/2014/286856; Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13; Jha D, 2021, COMP MED SY, P37, DOI 10.1109/CBMS52027.2021.00014; Karaman A, 2023, APPL INTELL, V53, P15603, DOI 10.1007/s10489-022-04299-1; Karaman A, 2023, EXPERT SYST APPL, V221, DOI 10.1016/j.eswa.2023.119741; Korman LY, 2005, ENDOSCOPY, V37, P951, DOI 10.1055/s-2005-870329; Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488; Lalinia M, 2024, SIGNAL IMAGE VIDEO P, V18, P2047, DOI 10.1007/s11760-023-02835-1; Lee JN, 2022, J ELECTR ENG TECHNOL, V17, P3057, DOI 10.1007/s42835-022-01191-3; Lewis J, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28530-2; Li X., 2020, P ANN C NEUR INF PRO, P21002, DOI DOI 10.48550/ARXIV.2006.04388; Li Z., 2014, Handbook of Capsule Endoscopy, DOI [10.1007/978-94-017-9229-5.pdf, DOI 10.1007/978-94-017-9229-5.PDF]; Nogueira-Rodríguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4; Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031; Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519; Pan SY, 2011, WORLD J GASTRO ONCOL, V3, P33, DOI 10.4251/wjgo.v3.i3.33; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Sahafi A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17502-7; Song PF, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105476; Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404; Souaidi M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12082030; Tomar NK, 2023, IEEE T NEUR NET LEAR, V34, P9375, DOI 10.1109/TNNLS.2022.3159394; Vlachou E, 2023, BEST PRACT RES CL GA, V64, DOI 10.1016/j.bpg.2023.101860; Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3; Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011; Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12; Zheng ZH, 2022, IEEE T CYBERNETICS, V52, P8574, DOI 10.1109/TCYB.2021.3095305; Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993	48	3	3	19	19	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4418		DIAGNOSTICS	Diagnostics	MAR	2024	14	5							474	10.3390/diagnostics14050474	http://dx.doi.org/10.3390/diagnostics14050474			16	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	KV3C0	38472946	gold, Green Published			2024-09-18	WOS:001182688800001
J	Ji, ZL; Zhao, JY; Liu, JY; Zeng, XY; Zhang, HY; Zhang, XJ; Ganchev, I				Ji, Zhanlin; Zhao, Jianyong; Liu, Jinyun; Zeng, Xinyi; Zhang, Haiyang; Zhang, Xueji; Ganchev, Ivan			ELCT-YOLO: An Efficient One-Stage Model for Automatic Lung Tumor Detection Based on CT Images	MATHEMATICS			English	Article						lung cancer; tumor; CT image; one-stage detector; YOLO; multi-scale; receptive field		Research on lung cancer automatic detection using deep learning algorithms has achieved good results but, due to the complexity of tumor edge features and possible changes in tumor positions, it is still a great challenge to diagnose patients with lung tumors based on computed tomography (CT) images. In order to solve the problem of scales and meet the requirements of real-time detection, an efficient one-stage model for automatic lung tumor detection in CT Images, called ELCT-YOLO, is presented in this paper. Instead of deepening the backbone or relying on a complex feature fusion network, ELCT-YOLO uses a specially designed neck structure, which is suitable to enhance the multi-scale representation ability of the entire feature layer. At the same time, in order to solve the problem of lacking a receptive field after decoupling, the proposed model uses a novel Cascaded Refinement Scheme (CRS), composed of two different types of receptive field enhancement modules (RFEMs), which enables expanding the effective receptive field and aggregate multi-scale context information, thus improving the tumor detection performance of the model. The experimental results show that the proposed ELCT-YOLO model has strong ability in expressing multi-scale information and good robustness in detecting lung tumors of various sizes.	[Ji, Zhanlin; Zhao, Jianyong; Liu, Jinyun; Zeng, Xinyi] North China Univ Sci & Technol, Coll Artificial Intelligence, Hebei Key Lab Ind Intelligent Percept, Tangshan 063210, Peoples R China; [Ji, Zhanlin; Ganchev, Ivan] Univ Limerick, Telecommun Res Ctr TRC, Limerick V94 T9PX, Ireland; [Zhang, Haiyang] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou 215000, Peoples R China; [Zhang, Xueji] Shenzhen Univ, Sch Biomed Engn, Hlth Sci Ctr, Shenzhen 518060, Peoples R China; [Ganchev, Ivan] Univ Plovdiv Paisii Hilendarski, Dept Comp Syst, Plovdiv 4000, Bulgaria; [Ganchev, Ivan] Bulgarian Acad Sci, Inst Math & Informat, Sofia 1040, Bulgaria	North China University of Science & Technology; University of Limerick; Xi'an Jiaotong-Liverpool University; Shenzhen University; Plovdiv University; Bulgarian Academy of Sciences	Ganchev, I (corresponding author), Univ Limerick, Telecommun Res Ctr TRC, Limerick V94 T9PX, Ireland.; Zhang, XJ (corresponding author), Shenzhen Univ, Sch Biomed Engn, Hlth Sci Ctr, Shenzhen 518060, Peoples R China.; Ganchev, I (corresponding author), Univ Plovdiv Paisii Hilendarski, Dept Comp Syst, Plovdiv 4000, Bulgaria.; Ganchev, I (corresponding author), Bulgarian Acad Sci, Inst Math & Informat, Sofia 1040, Bulgaria.	zhaojianyong@stu.ncst.edu.cn; zhangxueji@szu.edu.cn; ivan.ganchev@ul.ie	Zhang, Xi/HJH-1211-2023; Zeng, Xinyi/IWE-0807-2023; Zhang, Jiahua/KFS-4615-2024; zhang, wen/JXN-0191-2024; Zhang, Xueji/JUU-6678-2023; zhang, xueji/ABE-6497-2020; Ganchev, Ivan/D-4973-2012	zhang, xueji/0000-0002-0035-3821; Ganchev, Ivan/0000-0003-0535-7087; Zhang, Haiyang/0000-0002-3025-9609	S&T Major Project of the Science and Technology Ministry of China [2017YFE0135700]; Bulgarian National Science Fund (BNSF) [K?-06-??-K?TA?/1 (KP-06-IP-CHINA/1)]	S&T Major Project of the Science and Technology Ministry of China; Bulgarian National Science Fund (BNSF)(National Science Fund of Bulgaria)	This publication has emanated from joint research conducted with the financial support of the S&T Major Project of the Science and Technology Ministry of China under the Grant No. 2017YFE0135700 and the Bulgarian National Science Fund (BNSF) under the Grant No. K?-06-??-K?TA?/1 (KP-06-IP-CHINA/1).	Ahmed I, 2023, IEEE ACM T COMPUT BI, V20, P2445, DOI 10.1109/TCBB.2022.3192139; Alamro W, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010036; Alsaedi D, 2022, IEEE T MICROW THEORY, V70, P3566, DOI 10.1109/TMTT.2022.3168312; Bhattacharjee A, 2023, IEEE T RADIAT PLASMA, V7, P394, DOI 10.1109/TRPMS.2023.3236719; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Causey J, 2022, IEEE ACM T COMPUT BI, V19, P1165, DOI 10.1109/TCBB.2020.3027744; Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261; Chen LC, 2017, Arxiv, DOI arXiv:1706.05587; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Ezhilraja K., 2022, 2022 International Conference on Automation, Computing and Renewable Systems (ICACRS), P1009, DOI 10.1109/ICACRS55517.2022.10029217; Fang HH, 2022, IEEE T MED IMAGING, V41, P2828, DOI 10.1109/TMI.2022.3172773; Gevorgyan Z, 2022, Arxiv, DOI [arXiv:2205.12740, DOI 10.48550/ARXIV.2205.12740]; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Gong J, 2020, EUR RADIOL, V30, P1847, DOI 10.1007/s00330-019-06533-w; Guo ZT, 2022, IEEE J BIOMED HEALTH, V26, P2547, DOI 10.1109/JBHI.2021.3131671; Halder A, 2020, J DIGIT IMAGING, V33, P655, DOI 10.1007/s10278-020-00320-6; Huang SG, 2023, SEMIN CANCER BIOL, V89, P30, DOI 10.1016/j.semcancer.2023.01.006; Jocher Glenn, 2022, Tech. Rep; Joseph RK, 2016, CRIT POL ECON S ASIA, P1; Lee JH, 2022, RADIOLOGY, V305, P209, DOI 10.1148/radiol.212877; Li CY, 2022, Arxiv, DOI arXiv:2209.02976; Li Ping, 2020, TCIA; Lin J, 2023, J DIGIT IMAGING, V36, P1029, DOI 10.1007/s10278-023-00792-2; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu JH, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020427; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu Y, 2023, IEEE T CIRC SYST VID, V33, P4934, DOI 10.1109/TCSVT.2023.3245883; Mei J, 2022, IEEE T PATTERN ANAL, V44, P4374, DOI 10.1109/TPAMI.2021.3065086; Mei SH, 2023, CRIT REV FOOD SCI, V63, P3046, DOI 10.1080/10408398.2021.1983767; Mousavi Z, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.108312; Mousavi Z, 2022, SLAS TECHNOL, V27, P63, DOI 10.1016/j.slast.2021.10.011; Mustafa B., 2021, arXiv; Ning Guo, 2021, 2021 International Conference on Computer Communication and Artificial Intelligence (CCAI), P15, DOI 10.1109/CCAI50917.2021.9447531; Nishino M, 2023, RADIOLOGY, V306, DOI 10.1148/radiol.222536; Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008; Redmon J., 2018, arXiv; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Slatore Christopher, 2022, Am J Respir Crit Care Med, V205, pP17, DOI 10.1164/rccm.2059P17; Su A., 2023, Electronics, V12, DOI 10.3390/electronics12010014; Sugawara H, 2023, LUNG CANCER, V176, P31, DOI 10.1016/j.lungcan.2022.12.007; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Wang CS, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12102555; Wang D., 2022, IEEE T IND INFORM, P1, DOI [10.1109/TII.2022.3208364, DOI 10.1109/TII.2022.3208364]; Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163; Wang WCV, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133661; Wu HS, 2023, IEEE T CYBERNETICS, V53, P2610, DOI 10.1109/TCYB.2022.3162873; Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085; Xiang W, 2019, IEEE WINT CONF APPL, P1789, DOI 10.1109/WACV.2019.00195; Xu L, 2021, NEUROCOMPUTING, V421, P115; Xu R, 2024, IEEE ACM T COMPUT BI, V21, P1093, DOI 10.1109/TCBB.2023.3253713; Yan C-M., 2022, J COMPUT, V33, P113, DOI [10.53106/199115992022063303009, DOI 10.53106/199115992022063303009]; Zhang TG, 2023, PHYS MED BIOL, V68, DOI 10.1088/1361-6560/acabff; Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993; Zhong GJ, 2023, IEEE T EM TOP COMP I, V7, P1113, DOI 10.1109/TETCI.2023.3243920	55	7	7	13	43	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	MAY 17	2023	11	10							2344	10.3390/math11102344	http://dx.doi.org/10.3390/math11102344			22	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	H6PS3		gold, Green Published			2024-09-18	WOS:000997165700001
J	Mammeri, S; Amroune, M; Haouam, MY; Bendib, I; Silva, AC				Mammeri, Selma; Amroune, Mohamed; Haouam, Mohamed-Yassine; Bendib, Issam; Silva, Aristofanes Correa			Early detection and diagnosis of lung cancer using YOLO v7, and transfer learning	MULTIMEDIA TOOLS AND APPLICATIONS			English	Article						Lung cancer; Computer vision; Deep learning; YOLO; Object detection; Lung nodules classification	CT IMAGES; ALGORITHM	Lung cancer is a very dangerous disease and one of the leading causes of cancer-related deaths worldwide. It often goes undetected until it reaches an advanced stage. Early detection of lung nodules, especially those ranging between 3mm-30mm, can aid radiologists in diagnosing the disease, as it poses a significant challenge for them. In this study, we propose a method for the detection and classification of these nodules using the LIDR-IDRI dataset. Our method consists of two parts. The first part focuses on introducing object detection algorithms using one of the recent version of YOLO (YOLO v7) to detect lung nodules. These algorithms enable the drawing of bounding boxes around the lung nodules without losing any vital information, thus assisting radiologists in identifying and tracking the nodules in adjacent computed tomography slices. We also evaluated the impact of different input images on nodule detection, including whole images (images without preprocessing and segmentation), lung segmented images (the lung area is extracted from the whole images), and preprocessed images (applying some filtering methods on the whole images). Our findings revealed that using whole images resulted in the best performance, achieving a detection mAP (mean average precision) of 81.28%. In the second part, we present a multi-class classification using transfer learning with the VGG16 model. This classification process demonstrated good performance in classifying the nodules detected in the first step by the YOLO object detector into three classes: benign, suspect, and malignant. The classification is based on the degree of malignancy given by each radiologist, which varies from (1 to 5) depending on the nodule malignancy. This approach has the potential to enhance the accuracy of nodule classification and improve the overall diagnostic process for lung cancer.	[Mammeri, Selma; Amroune, Mohamed; Haouam, Mohamed-Yassine; Bendib, Issam] Echahid Cheikh Larbi Tebessi Univ, Lab Math Informat & Syst LAMIS, Tebessa 12002, Algeria; [Silva, Aristofanes Correa] Univ Fed Maranhao, Dept Elect Engn, BR-65080805 Sao Luis, Maranhao, Brazil	Echahid Cheikh Larbi Tebessi University; Universidade Federal do Maranhao	Mammeri, S (corresponding author), Echahid Cheikh Larbi Tebessi Univ, Lab Math Informat & Syst LAMIS, Tebessa 12002, Algeria.	selma.mammeri@univ-tebessa.dz; mohamed.amroune@univ-tebessa.dz; mohamed-yassine.haouam@univ-tebessa.dz; issam.bendib@univ-tebessa.dz; aricsilva@gmail.com	HAOUAM, Mohamed Yassine/KFT-1015-2024; Amroune, Pr.Mohamed/HGC-7134-2022; SILVA, ARISTOFANES/D-7957-2013	Haouam, Mohamed Yassine/0000-0001-8989-6656				[Anonymous], 2021, CANC IMAGING ARCH; [Anonymous], 2022, SIZES LUNG NODULES; [Anonymous], 2021, ERODING DILATING; Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013; de Carvalho AS, 2017, J DIGIT IMAGING, V30, P812, DOI 10.1007/s10278-017-9973-6; Ewaidat HA, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2301.02166; Haider A, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P198, DOI 10.1109/ASPCON49795.2020.9276715; Jin X., 2010, K-Means Clustering, P563, DOI 10.1007/978-0-387-30164-8_425; Kaviarasu K, 2016, S ASIAN J ENG TECHNO, V2; Kejia Xu, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P233, DOI 10.1145/3404555.3404609; Lung Image Database Consortium (LIDC), 2020, NOD SIZ REP; Luo SQ, 2001, P ANN INT IEEE EMBS, V23, P2727, DOI 10.1109/IEMBS.2001.1017347; Mohamed A, 2021, 2021 INT C NETW ADV, P1, DOI [10.1109/ICNAS53565.2021.9628946, DOI 10.1109/ICNAS53565.2021.9628946]; Noviana R, 2017, AIP CONF PROC, V1867, DOI 10.1063/1.4994425; Pydicom, 2021, US; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sawant A, 1999, P SOC PHOTO-OPT INS, V3661, P1263, DOI 10.1117/12.348522; Soltani H, 2021, 2021 INT C RECENT AD, P1; Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866; Suji RJ, 2021, INDIAN J COMPUT SCI, V12, DOI [10.21817/indjcse/2021/v12i4/211204270, DOI 10.21817/INDJCSE/2021/V12I4/211204270]; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031; Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510; Yan C-M., 2022, J COMPUT, V33, P113, DOI [10.53106/199115992022063303009, DOI 10.53106/199115992022063303009]	25	4	4	12	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1380-7501	1573-7721		MULTIMED TOOLS APPL	Multimed. Tools Appl.	MAR	2024	83	10					30965	30980		10.1007/s11042-023-16864-y	http://dx.doi.org/10.1007/s11042-023-16864-y		SEP 2023	16	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KU8C7					2024-09-18	WOS:001066762000014
C	Nie, YL; Sommella, P; O'Nils, M; Liguori, C; Lundgren, J			IEEE	Nie, Yali; Sommella, Paolo; O'Nils, Mattias; Liguori, Consolatina; Lundgren, Jan			Automatic Detection of Melanoma with Yolo Deep Convolutional Neural Networks	2019 E-HEALTH AND BIOENGINEERING CONFERENCE (EHB)	E-Health and Bioengineering Conference		English	Proceedings Paper	7th E-Health and Bioengineering Conference (EHB)	NOV 21-23, 2019	Grigore T Popa Univ Med & Pharmacy, Iasi, ROMANIA	Grigore T Popa Univ Med & Pharmacy , Fac Med Bioengineering, IEEE, Romanian Soc Med Bioengineering, Romanian Acad, Inst Comp Sci, Iasi Branch, IEEE Romania Sect, IEEE EMB Romania Chapter, IEEE EMC Romania Chapter, IEEE Signal Proc Romania Chapter, IEEE SMC Romania Chapter	Grigore T Popa Univ Med & Pharmacy	Image processing; Melanoma; Yolo; Object Detection		In the past three years, deep convolutional neural networks (DCNNs) have achieved promising results in detecting skin cancer. However, improving the accuracy and efficiency of the automatic detection of melanoma is still urgent due to the visual similarity of benign and malignant dermoscopic images. There is also a need for fast and computationally effective systems for mobile applications targeting caregivers and homes. This paper presents the You Only Look Once (Yolo) algorithms, which are based on DCNNs applied to the detection of melanoma. The Yolo algorithms comprise YoloV1, YoloV2, and YoloV3, whose methodology first resets the input image size and then divides the image into several cells. According to the position of the detected object in the cell, the network will try to predict the bounding box of the object and the class confidence score. Our test results indicate that the mean average precision (mAP) of Yolo can exceed 0.82 with a training set of only 200 images, proving that this method has great advantages for detecting melanoma in lightweight system applications.	[Nie, Yali; O'Nils, Mattias; Lundgren, Jan] Mid Sweden Univ, Dept Elect Engn, Sundsvall, Sweden; [Sommella, Paolo; Liguori, Consolatina] Univ Salerno, Dept Ind Engineer, Salerno, Italy	Mid-Sweden University; University of Salerno	Nie, YL (corresponding author), Mid Sweden Univ, Dept Elect Engn, Sundsvall, Sweden.	yali.nie@miun.se; psommella@unisa.it; mattias.onils@miun.se; tliguori@unisa.it; Jan.Lundgren@miun.se	O'Nils, Mattias/ABD-3235-2020; Nie, Yali/HJG-5670-2022	Nie, Yali/0000-0003-1840-791X				Adrian R., 2016, INTERSECTION UNION I; AlAsadi A.H., 2016, EARLY DETECTION CLAS; Azfar RS, 2011, J TELEMED TELECARE, V17, P338, DOI 10.1258/jtt.2011.110115; Ballerini L, 2013, Color Medical Image Analysis, P63; Chen E.Z., 2018, bioRxiv, P381855; Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547; Di Leo G, 2015, IEEE IMTC P, P1646, DOI 10.1109/I2MTC.2015.7151526; Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473; Garnavi R, 2012, IEEE T INF TECHNOL B, V16, P1239, DOI 10.1109/TITB.2012.2212282; Girshick R., 2014, P IEEE C COMPUTER VI, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He K., 2016, PROC IEEE C COMPUTER, DOI [DOI 10.1109/CVPR.2016.90, 10.1109/CVPR.2016.90]; Joseph R., 2018, YOLOV3 INCREMENTAL I, DOI DOI 10.48550/ARXIV.1804.02767; Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117, DOI [DOI 10.1109/CVPR.2017.106, 10.1109/CVPR.2017.106]; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Mark E., 2011, TECH REP; Menzies SW, 1996, ARCH DERMATOL, V132, P1178, DOI 10.1001/archderm.132.10.1178; Redmon J., 2016, P IEEE C COMP VIS PA, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/cvpr.2016.91, 10.1109/CVPR.2016.91]; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rothe R, 2015, LECT NOTES COMPUT SC, V9003, P290, DOI 10.1007/978-3-319-16865-4_19; Seth D, 2017, CURR DERMATOL REP, V6, P204, DOI 10.1007/s13671-017-0192-7; STOLZ W, 1994, EUR J DERMATOL, V4, P521; Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551; Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839; Yuan XJ, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P3301; Zhong-Qiu Z., 2019, IEEE T NEURAL NETWOR	27	53	57	1	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2575-5137	2575-5145	978-1-7281-2603-6	E-HEALTH BIOENG CONF			2019										10.1109/ehb47216.2019.8970033	http://dx.doi.org/10.1109/ehb47216.2019.8970033			4	Health Care Sciences & Services; Engineering, Biomedical; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Health Care Sciences & Services; Engineering; Medical Informatics	BP5YO		Green Published			2024-09-18	WOS:000558648300163
C	Wang, JG; Gou, C; Shen, TY; Wang, FY			IEEE	Wang, Jiangong; Gou, Chao; Shen, Tianyu; Wang, Fei-Yue			Global segmentation-aided local masses detection in X-ray breast images	2018 CHINESE AUTOMATION CONGRESS (CAC)	Chinese Automation Congress		English	Proceedings Paper	Chinese Automation Congress (CAC)	NOV 30-DEC 02, 2018	Xian, PEOPLES R CHINA	CAA, IEEE, IEEE Syst Man & Cybernet Soc		mammogram; mass detection; YOLO; U-net	DIGITAL MAMMOGRAMS	Breast cancer, as one of the most leading cancers for women, has attached more and more attention. Early image-based detection of masses for mammogram screening plays a crucial role for radiological diagnosis. In this paper, we propose to incorporate global and local information for accurate masses detection. Specifically, we improve a local ROI-based CNN framework which is named as YOLO for coarse mass localization, followed by an improved LT-net structure to incorporate global information for fine mass detection. Experimental results on benchmark dataset of INbreast show that our proposed method can achieve preferable results.	[Wang, Jiangong; Gou, Chao; Shen, Tianyu; Wang, Fei-Yue] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China; [Wang, Jiangong; Shen, Tianyu] Univ Chinese Acad Sci, Sch Artifical Intelligence, Beijing, Peoples R China; [Gou, Chao; Wang, Fei-Yue] Qingdao Acad Intelligent Ind, Qingdao, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Wang, JG (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.; Wang, JG (corresponding author), Univ Chinese Acad Sci, Sch Artifical Intelligence, Beijing, Peoples R China.	wangjiangong2018@ia.ac.cn; chao.gou@ia.ac.cn; shentianyu2016@ia.ac.cn; feiyue.wang@ia.ac.cn	Wang, Jiangong/AAA-9386-2021; Shen, Tianyu/JIE-9808-2023	Gou, Chao/0000-0002-4128-886X; Wang, Jiangong/0000-0002-0259-0118	National Natural Science Foundation of China [61806198, 61533019]; Project of Youth Foundation of the State Key Laboratory for Management and Control of Complex Systems [Y6S9011F4N]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Project of Youth Foundation of the State Key Laboratory for Management and Control of Complex Systems	This work was supported in part by the National Natural Science Foundation of China under Grant 61806198, 61533019 and Project of Youth Foundation of the State Key Laboratory for Management and Control of Complex Systems under Grant Y6S9011F4N.	Al-antari MA, 2018, J MED BIOL ENG, V38, P443, DOI 10.1007/s40846-017-0321-6; [Anonymous], AUTOMATED SOFT TISSU; [Anonymous], INT WORK DIG MAMM; [Anonymous], 2001, The digital database for screening mammography; Campanini R, 2004, PHYS MED BIOL, V49, P961, DOI 10.1088/0031-9155/49/6/007; Liu S, 2001, IEEE T IMAGE PROCESS, V10, P874, DOI 10.1109/83.923284; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Siegel R, 2014, CA-CANCER J CLIN, V64, P9, DOI 10.3322/caac.21208	12	3	3	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2688-092X	2688-0938	978-1-7281-1312-8	CHIN AUTOM CONGR			2018							3655	3660						6	Automation & Control Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems	BM0WI					2024-09-18	WOS:000459239503132
J	Rong, RC; Sheng, HDY; Jin, KW; Wu, FJ; Luo, DN; Wen, ZY; Tang, C; Yang, DM; Jia, LW; Amgad, M; Cooper, LAD; Xie, Y; Zhan, XW; Wang, SD; Xiao, GH				Rong, Ruichen; Sheng, Hudanyun; Jin, Kevin W.; Wu, Fangjiang; Luo, Danni; Wen, Zhuoyu; Tang, Chen; Yang, Donghan M.; Jia, Liwei; Amgad, Mohamed; Cooper, Lee A. D.; Xie, Yang; Zhan, Xiaowei; Wang, Shidan; Xiao, Guanghua			A Deep Learning Approach for Histology-Based Nucleus Segmentation and Tumor Microenvironment Characterization	MODERN PATHOLOGY			English	Article						digital pathology; nucleus segmentation; whole-slide imaging; Yolo	VARIABLE SELECTION	Microscopic examination of pathology slides is essential to disease diagnosis and biomedical research. However, traditional manual examination of tissue slides is laborious and subjective. Tumor whole-slide image (WSI) scanning is becoming part of routine clinical procedures and produces massive data that capture tumor histologic details at high resolution. Furthermore, the rapid development of deep learning algorithms has significantly increased the efficiency and accuracy of pathology image analysis. In light of this progress, digital pathology is fast becoming a powerful tool to assist pathologists. Studying tumor tissue and its surrounding microenvironment provides critical insight into tumor initiation, progression, metastasis, and potential therapeutic targets. Nucleus segmentation and classification are critical to pathology image analysis, especially in characterizing and quantifying the tumor microenvironment (TME). Computational algorithms have been developed for nucleus segmentation and TME quantification within image patches. However, existing algorithms are computationally intensive and time consuming for WSI analysis. This study presents Histology-based Detection using Yolo (HD-Yolo), a new method that significantly accelerates nucleus segmentation and TME quantification. We demonstrate that HD-Yolo outperforms existing WSI analysis methods in nucleus detection, classification accuracy, and computation time. We validated the advantages of the system on 3 different tissue types: lung cancer, liver cancer, and breast cancer. For breast cancer, nucleus features by HD-Yolo were more prognostically significant than both the estrogen receptor status by immunohistochemistry and the progesterone receptor status by immunohistochemistry. The WSI analysis pipeline and a real-time nucleus segmentation viewer are available at https://github.com/impromptuRong/hd_wsi.& COPY; 2023 THE AUTHORS. Published by Elsevier Inc. on behalf of the United States & Canadian Academy of Pathology. This is an open access article under the CC BY-NC-ND license (http://creativecommons. org/licenses/by-nc-nd/4.0/).	[Rong, Ruichen; Sheng, Hudanyun; Jin, Kevin W.; Wu, Fangjiang; Luo, Danni; Wen, Zhuoyu; Tang, Chen; Yang, Donghan M.; Xie, Yang; Zhan, Xiaowei; Wang, Shidan; Xiao, Guanghua] UT Southwestern Med Ctr, Quantitat Biomed Res Ctr, Peter O Donnell Jr Sch Publ Hlth, Dallas, TX 75390 USA; [Jia, Liwei] UT Southwestern Med Ctr, Dept Pathol, Dallas, TX USA; [Amgad, Mohamed] Northwestern Univ, Dept Pathol, Feinberg Sch Med, Chicago, IL USA; [Xie, Yang; Zhan, Xiaowei; Xiao, Guanghua] UT Southwestern Med Ctr, Dept Bioinformat, Dallas, TX 75390 USA; [Xie, Yang; Xiao, Guanghua] UT Southwestern Med Ctr, Simmons Comprehens Canc Ctr, Dallas, TX 75390 USA; [Zhan, Xiaowei] UT Southwestern Med Ctr, Ctr Genet Host Def, Dallas, TX 75390 USA	University of Texas System; University of Texas Southwestern Medical Center Dallas; University of Texas System; University of Texas Southwestern Medical Center Dallas; Northwestern University; Feinberg School of Medicine; University of Texas System; University of Texas Southwestern Medical Center Dallas; University of Texas System; University of Texas Southwestern Medical Center Dallas; University of Texas System; University of Texas Southwestern Medical Center Dallas	Zhan, XW; Wang, SD; Xiao, GH (corresponding author), UT Southwestern Med Ctr, Quantitat Biomed Res Ctr, Peter O Donnell Jr Sch Publ Hlth, Dallas, TX 75390 USA.; Zhan, XW; Xiao, GH (corresponding author), UT Southwestern Med Ctr, Dept Bioinformat, Dallas, TX 75390 USA.; Xiao, GH (corresponding author), UT Southwestern Med Ctr, Simmons Comprehens Canc Ctr, Dallas, TX 75390 USA.; Zhan, XW (corresponding author), UT Southwestern Med Ctr, Ctr Genet Host Def, Dallas, TX 75390 USA.	Xiaowei.Zhan@utsouthwestern.edu; Shidan.wang@utsouthwestern.edu; Guanghua.Xiao@utsouthwestern.edu	Wang, Shidan/ABC-2163-2020; zhan, xiaowei/AAA-1775-2020; Wen, Zhuoyu/HLG-8170-2023; Amgad, Mohamed/I-7440-2019; Zhan, Xiaowei/L-5711-2013	Zhan, Xiaowei/0000-0002-6249-7193	National Institutes of Health [R01GM140012, R01GM141519, R01DE030656, U01CA249245, R35GM136375, P50CA070907, 2P30CA142543]; Cancer Prevention and Research Institute of Texas [RP190107, RP180805];  [RP230330]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Cancer Prevention and Research Institute of Texas(Cancer Prevention & Research Institute of Texas); 	& nbsp;This work was supported by the National Institutes of Health (R01GM140012, R01GM141519, R01DE030656, U01CA249245, R35GM136375, P50CA070907, and 2P30CA142543) and the Cancer Prevention and Research Institute of Texas (CPRIT RP180805, RP230330 and RP190107). The funding bodies had no role in the design, collection, analysis, or interpretation of data in this study.	Amgad M, 2022, GIGASCIENCE, V11; Amgad M, 2019, BIOINFORMATICS, V35, P3461, DOI 10.1093/bioinformatics/btz083; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593; Bolya D, 2022, IEEE T PATTERN ANAL, V44, P1108, DOI 10.1109/TPAMI.2020.3014297; Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925; BRESLOW NE, 1975, INT STAT REV, V43, P45, DOI 10.2307/1402659; Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644; Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13; Cheng J, 2018, BIOINFORMATICS, V34, P1024, DOI 10.1093/bioinformatics/btx723; Folmsbee J, 2018, I S BIOMED IMAGING, P770, DOI 10.1109/ISBI.2018.8363686; Gamper Jevgenij, 2019, Digital Pathology. 15th European Congress, ECDP 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11435), P11, DOI 10.1007/978-3-030-23937-4_2; Ge Z, 2021, Arxiv, DOI arXiv:2107.08430; Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902; Kramer BS, 2011, J MED SCREEN, V18, P109, DOI 10.1258/jms.2011.011055; Li CY, 2022, Arxiv, DOI arXiv:2209.02976; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren MY, 2021, BIOINFORMATICS, V37, P3073, DOI 10.1093/bioinformatics/btab134; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Tabibu S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46718-3; Tan M., 2020, P IEEE CVF C COMP VI, P10778, DOI DOI 10.48550/ARXIV.1911.09070; Tan MX, 2019, PR MACH LEARN RES, V97; Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Tomczak Katarzyna, 2015, Contemp Oncol (Pozn), V19, pA68, DOI 10.5114/wo.2014.47136; Wand M. P., 1994, KERNEL SMOOTHING; Wang C., arXiv; Wang CY, 2021, Arxiv, DOI arXiv:2105.04206; Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283; Wang DY, 2016, Arxiv, DOI [arXiv:1606.05718, 10.48550/arXiv.1606.05718]; Wang SD, 2020, CANCER RES, V80, P2056, DOI 10.1158/0008-5472.CAN-19-1629; Wang SD, 2019, AM J PATHOL, V189, P1686, DOI 10.1016/j.ajpath.2019.05.007; Zhu XZ, 2021, Arxiv, DOI [arXiv:2010.04159, DOI 10.48550/ARXIV.2010.04159]; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	38	6	6	5	40	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0893-3952	1530-0285		MODERN PATHOL	Mod. Pathol.	AUG	2023	36	8							100196	10.1016/j.modpat.2023.100196	http://dx.doi.org/10.1016/j.modpat.2023.100196		JUN 2023	11	Pathology	Science Citation Index Expanded (SCI-EXPANDED)	Pathology	K0PL8	37100227	Green Accepted, hybrid			2024-09-18	WOS:001013553700001
J	Mercaldo, F; Brunese, L; Martinelli, F; Santone, A; Cesarelli, M				Mercaldo, Francesco; Brunese, Luca; Martinelli, Fabio; Santone, Antonella; Cesarelli, Mario			Object Detection for Brain Cancer Detection and Localization	APPLIED SCIENCES-BASEL			English	Article						brain; object detection; YOLO; deep learning; classification	THERAPY	Brain cancer is acknowledged as one of the most aggressive tumors, with a significant impact on patient survival rates. Unfortunately, approximately 70% of patients diagnosed with this malignant cancer do not survive. This paper introduces a method designed to detect and localize brain cancer by proposing an automated approach for the detection and localization of brain cancer. The method utilizes magnetic resonance imaging analysis. By leveraging the information provided by brain medical images, the proposed method aims to enhance the detection and precise localization of brain cancer to improve the prognosis and treatment outcomes for patients. We exploit the YOLO model to automatically detect and localize brain cancer: in the analysis of 300 brain images we obtain a precision of 0.943 and a recall of 0.923 in brain cancer detection while, relating to brain cancer localization, an mAP_0.5 equal to 0.941 is reached, thus showing the effectiveness of the proposed model for brain cancer detection and localization.	[Mercaldo, Francesco; Brunese, Luca; Santone, Antonella] Univ Molise, Dept Med & Hlth Sci Vincenzo Tiberio, I-86100 Campobasso, Italy; [Mercaldo, Francesco; Martinelli, Fabio] Natl Res Council Italy, Inst Informat & Telemat, I-56124 Pisa, Italy; [Cesarelli, Mario] Univ Sannio, Dept Engn, I-82100 Benevento, Italy	University of Molise; Consiglio Nazionale delle Ricerche (CNR); Istituto di Informatica e Telematica (IIT-CNR); University of Sannio	Mercaldo, F (corresponding author), Univ Molise, Dept Med & Hlth Sci Vincenzo Tiberio, I-86100 Campobasso, Italy.; Mercaldo, F (corresponding author), Natl Res Council Italy, Inst Informat & Telemat, I-56124 Pisa, Italy.	francesco.mercaldo@iit.cnr.it; luca.brunese@unimol.it; fabio.martinelli@iit.cnr.it; antonella.santone@unimol.it; mcesarelli@unisannio.it	Brunese, Luca/AAD-6742-2019	Mercaldo, Francesco/0000-0002-9425-1657	MUR-REASONING; National Plan for NRRP Complementary Investments D?3 4 Health; Health Operational Plan, FSC	MUR-REASONING; National Plan for NRRP Complementary Investments D?3 4 Health; Health Operational Plan, FSC	This work has been partially supported by MUR-REASONING: foRmal mEthods for computAtional analySis for diagnOsis and progNosis in imagING-PRIN, National Plan for NRRP Complementary Investments D?3 4 Health: Digital Driven Diagnostics, prognostics and therapeuticsfor sustainable Health care and e-DAI (Digital ecosystem for integrated analysis of heterogeneoushealth data related to high-impact diseases: innovative model of care and research), Health Operational Plan, FSC 2014-2020.	Ahmad S, 2023, IEEE ACCESS, V11, P87166, DOI 10.1109/ACCESS.2023.3296710; Alsubai S, 2022, FRONT COMPUT NEUROSC, V16, DOI 10.3389/fncom.2022.1005617; Amin S.E., 2012, P IEEE INT C WIRELES, P15; [Anonymous], 2012, International Journal of Advanced Computer Research; [Anonymous], 2022, YOLO DAT; Badran EF, 2010, ICCES'2010: THE 2010 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS, P368, DOI 10.1109/ICCES.2010.5674887; Brunese L, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105134; Di Giammarco Marcello, 2022, Applied Intelligence and Informatics: Second International Conference, AII 2022, Proceedings. Communications in Computer and Information Science (1724), P129, DOI 10.1007/978-3-031-24801-6_10; Dipu N.M., 2021, 2021 INT C SCI CONT, P1; Fomchenko EI, 2005, EXP CELL RES, V306, P323, DOI 10.1016/j.yexcr.2005.03.007; Gadpayleand P., 2013, INT C ADV COMPUT COM, P2320; Giammarco Marcello Di, 2022, Procedia Computer Science, P1633, DOI 10.1016/j.procs.2022.09.220; Gleeson HK, 2004, ENDOCR-RELAT CANCER, V11, P589, DOI 10.1677/erc.1.00779; Hauptmann M, 2023, LANCET ONCOL, V24, P45, DOI 10.1016/S1470-2045(22)00655-6; Horak K, 2019, PROC SPIE, V11179, DOI 10.1117/12.2539806; Hurtik P, 2022, NEURAL COMPUT APPL, V34, P8275, DOI 10.1007/s00521-021-05978-9; Isselmou A. E. K., 2016, Journal of Biomedical Science and Engineering, V09, P44, DOI 10.4236/jbise.2016.910B006; Jafari Mehdi., 2012, GLOBAL J SCI ENG TEC, V3, P1; Jiang PY, 2022, PROCEDIA COMPUT SCI, V199, P1066, DOI 10.1016/j.procs.2022.01.135; Martinelli F., 2022, 2022 IEEE INT C BIG, P4534; Martinelli F, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010075; Masood M, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-0105-y; Mercaldo F, 2023, NEURAL COMPUT APPL, V35, P17429, DOI 10.1007/s00521-023-08608-8; Mercaldo F, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534231; Paul S, 2022, Arxiv, DOI arXiv:2212.13599; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Reis D, 2024, Arxiv, DOI arXiv:2305.09972; Saeedi S, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02114-6; Sah S, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.051406; Sanchez S. A., 2020, IOP Conference Series: Materials Science and Engineering, V844, DOI 10.1088/1757-899X/844/1/012024; Selvy P.T., 2019, Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol, V169, P175; Sharma K., 2014, International Journal of Computer Application, V103, P7, DOI [DOI 10.5120/18036-6883, 10.5120/18036-6883]; Tandel GS, 2019, CANCERS, V11, DOI 10.3390/cancers11010111; WEITZNER MA, 1995, CANCER, V75, P1151, DOI 10.1002/1097-0142(19950301)75:5<1151::AID-CNCR2820750515>3.0.CO;2-Q; Xuan X, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P421, DOI 10.1109/ICIG.2007.181	35	2	2	9	22	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	AUG	2023	13	16							9158	10.3390/app13169158	http://dx.doi.org/10.3390/app13169158			17	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	Q2TB0		gold			2024-09-18	WOS:001056079700001
C	Barkhof, F; Abbring, S; Pardasani, R; Awasthi, N			IEEE	Barkhof, Francien; Abbring, Silvia; Pardasani, Rohit; Awasthi, Navchetan			Deep learning based tumor detection and segmentation for automated 3D breast ultrasound imaging	PROCEEDINGS OF THE 2024 IEEE SOUTH ASIAN ULTRASONICS SYMPOSIUM, SAUS 2024			English	Proceedings Paper	South Asian Ultrasonics Symposium (SAUS)	MAR 27-29, 2024	Gujarat, INDIA	IEEE		U-Net; Detection; Segmentation; Breast Cancer; YOLO		Breast cancer is one of the widely diagnosed cancer in the world. However, the detection and segmentation of the tumor is a problem which still needs to be solved. Here we proposed U-Net and YOLO for the segmentation and detection for breast tumor detection in ABUS images. The algorithms were used for 2D images and got a dice score of 0.567 for segmentation and a mAP score of 0.554 for detection of tumor for the split of training data. For validation dataset, the dice score was 0.5388 for segmentation and a detection score of 0.3988 for the detection of tumor in ABUS images.	[Barkhof, Francien; Abbring, Silvia; Awasthi, Navchetan] Univ Amsterdam, Amsterdam, Netherlands; [Pardasani, Rohit] Gen Elect Healthcare, Bangalore, Karnataka, India	University of Amsterdam; General Electric	Awasthi, N (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.	fj.barkhof@hotmail.com; silvia.abbring@student.uva.nl; rohit.r.pardasani@gmail.com; n.awasthi@uva.nl	Awasthi, Navchetan/AAA-3253-2019					[Anonymous], 2023, Tdsc-abus; Ju Xu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12261), P378, DOI 10.1007/978-3-030-59710-8_37; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Vourtsis A, 2019, DIAGN INTERV IMAG, V100, P579, DOI 10.1016/j.diii.2019.03.012; Wang K., 2022, Tumor Detection, Segmentation, and Classification Challenge on Automated 3D Breast Ultrasound, DOI [10.5281/zenodo.6362504, DOI 10.5281/ZENODO.6362504]; Wang LT, 2023, Arxiv, DOI arXiv:2305.15114; Zhang YC, 2022, COMPUT MED IMAG GRAP, V99, DOI 10.1016/j.compmedimag.2022.102088	7	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-8401-7; 979-8-3503-8402-4				2024										10.1109/SAUS61785.2024.10563487	http://dx.doi.org/10.1109/SAUS61785.2024.10563487			4	Acoustics; Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Radiology, Nuclear Medicine & Medical Imaging	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BX2KI					2024-09-18	WOS:001263778100011
C	Touazi, F; Gaceb, D; Chirane, M; Herzallah, S		Shakhovska, N; Kovac, M; Izonin, I; Chretien, S		Touazi, Faycal; Gaceb, Djamel; Chirane, Marouane; Herzallah, Selma			Two-Stage Approach for Semantic Image Segmentation of Breast Cancer : Deep Learning and Mass Detection in Mammographic images	6TH INTERNATIONAL CONFERENCE ON INFORMATICS & DATA-DRIVEN MEDICINE, IDDM 2023	CEUR Workshop Proceedings-Series		English	Proceedings Paper	6th International Conference on Informatics and Data-Driven Medicine (IDDM)	NOV 17-19, 2023	Bratislava, SLOVAKIA	Slovak Univ Technol Bratislava, Lviv Polytechn Natl Univ, Univ Lumiere Lyon 2, Polytechn Univ Valencia, Natl Univ Zaporizhzhia Polytechn, Linnaeus Univ		Breast Cancer; Deep Learning; ViT; NEST; YOLO		Breast cancer is a significant global health problem that predominantly affects women and requires effective screening methods. Mammography, the primary screening approach, presents challenges such as radiologist workload and associated costs. Recent advances in deep learning hold promise for improving breast cancer diagnosis. This paper focuses on early breast cancer detection using deep learning to assist radiologists, reduce their workload and costs. We employed the CBIS-DDSM dataset and various CNN models, including YOLO versions V5, V7, and V8 for mass detection, and transformer-based (nested) models inspired by ViT for mass segmentation. Our diverse approach aims to address the complexity of breast cancer detection and segmentation from medical images. Our results show promise, with a 59% mAP50 for cancer mass detection and an impressive 90.15% Dice coefficient for semantic segmentation. These findings highlight the potential of deep learning to enhance breast cancer diagnosis, paving the way for more efficient and accurate early detection methods.	[Touazi, Faycal; Gaceb, Djamel; Chirane, Marouane; Herzallah, Selma] Univ Mhamed Bougara, Dept Comp Sci, LIMOSE Lab, Independence Ave, Boumerdes 35000, Algeria	Universite de M'hammed Bougara Boumerdes	Touazi, F (corresponding author), Univ Mhamed Bougara, Dept Comp Sci, LIMOSE Lab, Independence Ave, Boumerdes 35000, Algeria.	f.touazi@univ-boumerdez.dz; d.gaceb@univ-boumerdez.dz; ch.marouanee@gmail.com; harzallahselma@gmail.com	Touazi, Faycal/JVZ-0366-2024					Aly GH, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105823; Ayana G, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020178; Bouzar-Benlabiod L, 2023, COMPUT BIOL MED, V163, DOI 10.1016/j.compbiomed.2023.107133; Cantone M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031229; Dluznevskij D, 2021, BALT J MOD COMPUT, V9, P333, DOI 10.22364/bjmc.2021.9.3.07; Heath M, 1998, COMP IMAG VIS, V13, P457; Ibrokhimov B, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094616; Jocher G., 2023, YOLO By Ultralytics; Jocher G., 2020, YOLOv5 by ultralytics, P5; Kamran SA, 2022, Arxiv, DOI arXiv:2211.08717; Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177; Liu DD, 2023, MED PHYS, V50, P2884, DOI 10.1002/mp.16216; Prinzi F, 2024, COGN COMPUT, V16, P107, DOI 10.1007/s12559-023-10189-6; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Soltani H, 2021, 2021 INT C REC ADV M, P1; Su YY, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106903; Sun H, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab5745; Ultralytics, 2023, GitHub Issue 189-Ultralytics; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Wang YH, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.5.054503; Yu H, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2020), P293, DOI [10.1109/cisp-bmei51763.2020.9263538, 10.1109/CISP-BMEI51763.2020.9263538]; Zhang ZZ, 2022, AAAI CONF ARTIF INTE, P3417; Zhou SY, 2023, J MAR SCI ENG, V11, DOI 10.3390/jmse11051051	23	0	0	0	0	RWTH AACHEN	Aachen	Ahornstr. 55, Aachen, *, GERMANY	1613-0073			CEUR WORKSHOP PROCEE			2023	3609													15	Computer Science, Information Systems; Engineering, Biomedical	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BX0RU					2024-09-18	WOS:001237876400006
J	Aly, GH; Marey, M; El-Sayed, SA; Tolba, MF				Aly, Ghada Hamed; Marey, Mohammed; El-Sayed, Safaa Amin; Tolba, Mohamed Fahmy			YOLO Based Breast Masses Detection and Classification in Full-Field Digital Mammograms	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						YOLO based breast mass detection; Anchor boxes; K-means clustering; Full-field digital mammograms; Breast masses classification	COMPUTER-AIDED DIAGNOSIS; CANCER; SYSTEM	Background and Objective: With the recent development in deep learning since 2012, the use of Convolutional Neural Networks (CNNs) in bioinformatics, especially medical imaging, achieved tremendous success. Besides that, breast masses detection and classifications in mammograms and their pathology classification are considered a critical challenge. Till now, the evaluation process of the screening mammograms is held by human readers which is considered very monotonous, tiring, lengthy, costly, and significantly prone to errors. Methods: We propose an end to end computer-aided diagnosis system based on You Only Look Once (YOLO). The proposed system first preprocesses the mammograms from their DICOM format to images without losing data. Then, it detects masses in full-field digital mammograms and distinguishes between the malignant and benign lesions without any human intervention. YOLO has three different architectures, and, in this paper, the three versions are used for mass detection and classification in the mammograms to compare their performance. The use of anchors in YOLO-V3 on the original form of data and its augmented version is proved to improve the detection accuracy especially when the k-means clustering is applied to generate anchors corresponding to the used dataset. Finally, ResNet and Inception are used as feature extractors to compare their classification performance against YOLO. Results: Mammograms with different resolutions are used and based on YOLO-V3, the best results are obtained through detecting 89.4% of the masses in the INbreast mammograms with an average precision of 94.2% and 84.6% for classifying the masses as benign and malignant respectively. YOLO's classification network is replaced with ResNet and InceptionV3 to get overall accuracy of 91.0% and 95.5%, respectively. Conclusion: The proposed system showed using the experimental results the YOLO impact on the breast masses detection and classification. Especially using the anchor boxes concept in YOLO-V3 that are generated by applying k-means clustering on the dataset, we can detect most of the challenging cases of masses and classify them correctly. Also, by augmenting the dataset using different approaches and comparing with other recent YOLO based studies, it is found that augmenting the training set only is the fairest and accurate to be applied in the realistic scenarios. (c) 2020 Elsevier B.V. All rights reserved.	[Aly, Ghada Hamed; Marey, Mohammed; El-Sayed, Safaa Amin; Tolba, Mohamed Fahmy] Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt	Egyptian Knowledge Bank (EKB); Ain Shams University	Aly, GH (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.	ghadahamed@cis.asu.edu.eg	Hamed, Ghada/C-5117-2017	Hamed, Ghada/0000-0001-7787-5479				Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774; Akselrod-Ballin A, 2016, LECT NOTES COMPUT SC, V10008, P197, DOI 10.1007/978-3-319-46976-8_21; Al-antari MA, 2016, GLOB C ENG APPL SCI, P1306; Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584; Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003; Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017; [Anonymous], 2015, CSI T ICT; Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014; CHAN HP, 1990, INVEST RADIOL, V25, P1102, DOI 10.1097/00004424-199010000-00006; Dhungel N., 2015, INT C DIGITAL IMAGE, V11, P1, DOI DOI 10.1109/DICTA.2015.7371234; Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009; Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002; Du J, 2018, J PHYS CONF SER, V1004, DOI 10.1088/1742-6596/1004/1/012029; Ellis RL, 2007, RADIOLOGY, V245, P88, DOI 10.1148/radiol.2451060760; Granata V, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/3918292; Hamed Ghada, ADV INTELLIGENCE SYS; Hologic, 2017, USER GUIDE MAN 03682; Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010; Jiang F, 2017, P 5 INT C BIOINF COM, P59; Jiang YL, 1999, ACAD RADIOL, V6, P22, DOI 10.1016/S1076-6332(99)80058-0; Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060; Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231; Lotter W, 2017, LECT NOTES COMPUT SC, V10553, P169, DOI 10.1007/978-3-319-67558-9_20; McGuire S, 2016, ADV NUTR, V7, P418, DOI 10.3945/an.116.012211; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Morton MJ, 2006, RADIOLOGY, V239, P375, DOI 10.1148/radiol.2392042121; Patel B.C, 2016, INT J BIOMED ENG TEC; Patel BC, 2014, J MED IMAG HEALTH IN, V4, P881, DOI 10.1166/jmihi.2014.1349; Patel C., 2014, MEDICAL IMAGE PROCES; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Rodriguez-Ruiz A, 2019, JNCI-J NATL CANCER I, V111, P916, DOI 10.1093/jnci/djy222; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Sadaf A, 2011, EUR J RADIOL, V77, P457, DOI 10.1016/j.ejrad.2009.08.024; Sampat MP, 2008, MED PHYS, V35, P2110, DOI 10.1118/1.2890080; Singh S, 2005, IEEE T INF TECHNOL B, V9, P109, DOI 10.1109/TITB.2004.837851; Song EM, 2010, ACAD RADIOL, V17, P1414, DOI 10.1016/j.acra.2010.07.008; Suzuki S, 2016, 2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1382, DOI 10.1109/SICE.2016.7749265; Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441; Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072; van Ginneken B, 2001, IEEE T MED IMAGING, V20, P1228, DOI 10.1109/42.974918; Wu N., 2019, IEEE T MED IMAGING; Yassin NIR, 2018, COMPUT METH PROG BIO, V156, P25, DOI 10.1016/j.cmpb.2017.12.012	47	79	82	12	109	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607	1872-7565		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	MAR	2021	200								105823	10.1016/j.cmpb.2020.105823	http://dx.doi.org/10.1016/j.cmpb.2020.105823		FEB 2021	16	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Medical Informatics	QO4KJ	33190942				2024-09-18	WOS:000623111700014
J	Lee, E; Kim, JS; Park, DK; Whangbo, T				Lee, Eunseo; Kim, Jae-Seoung; Park, Dong Kyun; Whangbo, Taegkeun			YOLO-MR: Meta-Learning-Based Lesion Detection Algorithm for Resolving Data Imbalance	IEEE ACCESS			English	Article						Endoscopy; you only look once (YOLO); meta-learning; model-agnostic meta-learning (MAML); residual block	FAST ADAPTATION	The early detection and precise diagnosis of gastrointestinal diseases, particularly gastric cancer, play a vital role in improving patient survival rates and treatment outcomes. However, diagnosing these conditions can be challenging when symptoms are mild or absent. Endoscopy is commonly used for diagnosis, but it requires endoscopists with a high level of specialized knowledge to accurately identify diseases. By integrating artificial intelligence (AI) with endoscopic imaging, AI can assist in diagnosis, reduce missed cases, and enable early treatment, thereby improving patient survival rates. Previous studies have mainly focused on improving disease classification and accuracy, often overlooking disproportionate and limited medical data reliability issues. In this study, we propose a solution to address the challenges posed by imbalanced and sparse medical image data by introducing model-agnostic meta-learning (MAML). To accomplish this, we employ the YOLO-MR model, which incorporates the concept of meta-recognition into the You Only Look Once (YOLO) model. Experimental results demonstrate that the mean average precision (mAP) of the conventional YOLO model is low at 41.7, indicating a significant impact of data imbalance. Traditional data augmentation methods provide a low mAP of 65.2, while the proposed YOLO-MR model achieves an impressive mAP of 96. This is significantly higher than the conventional YOLO model by 54.3, reducing accuracy disparities between different disease classes and addressing the issue of data imbalance. Furthermore, this research showcases the effectiveness of innovative techniques such as MAML and residual blocks in addressing data imbalance in medical image recognition. These findings hold substantial potential for tackling the challenges posed by limited and imbalanced medical data in the healthcare field.	[Lee, Eunseo; Whangbo, Taegkeun] Gachon Univ, Dept Comp Engn, Seongnam Si 13120, Gyeonggi Do, South Korea; [Kim, Jae-Seoung; Park, Dong Kyun] Gachon Univ, Gil Med Ctr, Hlth IT Res Ctr, Incheon 21565, South Korea	Gachon University; Gachon University	Whangbo, T (corresponding author), Gachon Univ, Dept Comp Engn, Seongnam Si 13120, Gyeonggi Do, South Korea.; Park, DK (corresponding author), Gachon Univ, Gil Med Ctr, Hlth IT Res Ctr, Incheon 21565, South Korea.	pdk66@gilhospital.com; tkwhangbo@gachon.ac.kr		Whangbo, Taegkeun/0000-0003-1409-0580	Gyeonggido Regional Research Center (GRRC) Program of Gyeonggi Province (Development of AI-Based Medical Service Technology)	Gyeonggido Regional Research Center (GRRC) Program of Gyeonggi Province (Development of AI-Based Medical Service Technology)	No Statement Available	Bai L, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172747; Baum ZMC, 2023, IEEE T MED IMAGING, V42, P823, DOI 10.1109/TMI.2022.3218147; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Bria A, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103735; Cui ZH, 2022, 2022 IEEE 46TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE (COMPSAC 2022), P1396, DOI 10.1109/COMPSAC54236.2022.00221; Deeba F, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P1006, DOI 10.1109/ICIEV.2016.7760150; Fan W., 2022, arXiv; Finn C, 2017, PR MACH LEARN RES, V70; Fu K, 2019, IEEE ACCESS, V7, P77597, DOI 10.1109/ACCESS.2019.2922438; Ge Z, 2021, Arxiv, DOI arXiv:2107.08430; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Griffin-Sobel JP, 2017, SEMIN ONCOL NURS, V33, P165, DOI 10.1016/j.soncn.2017.02.004; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jocher G., 2023, YOLO By Ultralytics; Jocher G., 2020, ULTRALYTICSYOLOV5 V3; Khushi M, 2021, IEEE ACCESS, V9, P109960, DOI 10.1109/ACCESS.2021.3102399; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Li CY, 2022, Arxiv, DOI arXiv:2209.02976; Li XL, 2017, IEEE ENG MED BIO, P1994, DOI 10.1109/EMBC.2017.8037242; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Mushtaq D, 2023, INT J IMAG SYST TECH, V33, P866, DOI 10.1002/ima.22850; Redmon J., 2018, arXiv; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren S., 2016, Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, DOI DOI 10.1109/TPAMI.2016.2577031; Ren XY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115543; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Wang H, 2019, Arxiv, DOI arXiv:1906.00358; Xu SL, 2022, Arxiv, DOI [arXiv:2203.16250, 10.48550/arXiv.2203.16250, DOI 10.48550/ARXIV.2203.16250]; Yong MP, 2023, 2023 11TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, ICBCB, P123, DOI 10.1109/ICBCB57893.2023.10246524; Yuan Zhaoyu, 2023, 2023 International Conference on Communications, Computing and Artificial Intelligence (CCCAI), P151, DOI 10.1109/CCCAI59026.2023.00035; Yue GH, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3264047	34	1	1	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						49762	49771		10.1109/ACCESS.2024.3384088	http://dx.doi.org/10.1109/ACCESS.2024.3384088			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	NJ1D4		gold			2024-09-18	WOS:001199984400001
C	Hasya, HF; Nuha, HH; Abdurohman, M		Ismail, IE; Hermawan, I; Rasyidin, MYB; Huzaifa, M; Muharram, AT; Marcheeta, N; Kurniawati, D; Yuly, AR; Agustin, M; Nalawati, RE; Nugrahadi, DT; Budiman, I		Hasya, Hasna Fadhilah; Nuha, Hilal Hudan; Abdurohman, Maman			Real Time-based Skin Cancer Detection System using Convolutional Neural Network and YOLO	2021 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATICS ENGINEERING (IC2IE 2021)			English	Proceedings Paper	4th IEEE International Conference on Computer and Informatics Engineering (IC2IE)	SEP 14-15, 2021	Jurusan Teknik Informatika Komputer, ELECTR NETWORK	Lambung Mangkurat Univ, FMIPA, PS Ilmu Komputer, IEEE Indonesia Sect, Politeknik Negeri Jakarta, Politeknik Negeri Batam, Lambung Mangkurat Univ, IEEE Computat Intelligence Soc, Citra Bunga Nusantara, Minist Res Technol & Higher Educ, Politeknik Negeri Jakarta, Dept Comp & Informat Engn, IC2iE, IEEE	Jurusan Teknik Informatika Komputer	skin cancer; deep learning; convolution neural network; YOLOV3	SEGMENTATION	Skin cancer arises by developing abnormal cells that invade or spread to other body parts. Nowadays, when a doctor examining someone's skin to make sure the patient has skin cancer or not, the patient still has to go through a process where after result carried out by the doctor, the patient still has to wait for the results to know the patient has skin cancer or not. No. In thisproject, the author has designed a skin cancer detection system in real-time to increase the efficiency of the skin cancer detection process for patients without waiting for data from the hospital lab. We use the Convolution Neural Network (CNN) to process skin images and for data grouping and YOLO for the system in real-time. The goal is to design a skin cancer detection system that makes it easier and increases the efficiency of doctors in analysing the results of skin cancer. The model shows the absolute accuracy is 96 per cent, and the real-time using YOLOV3, the accuracy is 80%.	[Hasya, Hasna Fadhilah; Nuha, Hilal Hudan; Abdurohman, Maman] Telkom Univ, Fac Informat, Bandung, Indonesia	Telkom University	Hasya, HF (corresponding author), Telkom Univ, Fac Informat, Bandung, Indonesia.	hasnahasya@student.telkomuniversity.ac.id; hilalnuha@365.telkomuniversity.ac.id; abdurohman@telkomuniversity.ac.id	Nuha, Hilal/AAD-5740-2021; Abdurohman, Maman/N-3853-2018					Albahli S, 2020, IEEE ACCESS, V8, P198403, DOI 10.1109/ACCESS.2020.3035345; Attia M, 2017, I S BIOMED IMAGING, P292, DOI 10.1109/ISBI.2017.7950522; Filali Y, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723791; Goyal M, 2020, IEEE ACCESS, V8, P4171, DOI 10.1109/ACCESS.2019.2960504; Guo Yulan, 2019, arXiv; Gupta Aurobindo, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1345, DOI 10.1109/ICRITO48877.2020.9197820; Jana E, 2018, 2017 IEEE INT C COMP, DOI DOI 10.1109/ICCIC.2017.8524554; Kharazmi P, 2017, IEEE J BIOMED HEALTH, V21, P1675, DOI 10.1109/JBHI.2016.2637342; Thao LT, 2017, 2017 21ST ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS (IES), P106, DOI 10.1109/IESYS.2017.8233570; Ly P, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P255, DOI 10.1109/UEMCON.2018.8796628; Manoorkar PB, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P1067, DOI 10.1109/ICACDOT.2016.7877750; Mirunalini P., 2017, ARXIV170304364; Mohandes M, 2021, APPL ARTIF INTELL, V35, P605, DOI 10.1080/08839514.2021.1922850; Moldovan D, 2019, E-HEALTH BIOENG CONF, DOI 10.1109/EHB47216.2019.8970067; Naeem A, 2020, IEEE ACCESS, V8, P110575, DOI 10.1109/ACCESS.2020.3001507; Nuha HH, 2020, ARAB J SCI ENG, V45, P1367, DOI 10.1007/s13369-019-03942-3; Nuha Hilal H., 2019, SEG INT EXPOSITION A; Shahin AH, 2018, CAIRO INT BIOM ENG, P150, DOI 10.1109/CIBEC.2018.8641815; Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161; Younis H., 2019, P 15 INT C EM TECHN, P1, DOI [10.1109/ICET48972.2019.8994508, DOI 10.1109/ICET48972.2019.8994508]	20	3	3	0	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-6654-4288-6				2021							152	157		10.1109/IC2IE53219.2021.9649224	http://dx.doi.org/10.1109/IC2IE53219.2021.9649224			6	Computer Science, Information Systems; Engineering, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BT7MN					2024-09-18	WOS:000850131100029
J	Xiong, YX; Zhou, YC; Wang, YJ; Liu, QX; Deng, L				Xiong, Yixin; Zhou, Yongcheng; Wang, Yujuan; Liu, Quanxing; Deng, Lei			Fully Automated Neural Network Framework for Pulmonary Nodules Detection and Segmentation	AI COMMUNICATIONS			English	Article						Pulmonary nodule; deep learning; medical segmentation	CLASSIFICATION	Lung cancer is the leading cause of cancer death worldwide, and most patients are diagnosed with advanced stages for lack of symptoms in the early stages of the disease, leading to poor prognosis. It is thus of great importance to detect lung cancer in the early stages which can reduce mortality and improve patient survival significantly. Although there are many computer aided diagnosis (CAD) systems used for detecting pulmonary nodules, there are still few CAD systems for detection and segmentation, and their performance on small nodules is not ideal. Thus, in this paper, we propose a deep cascaded multitask framework called mobilenet split-attention Yolo unet, the mobilenet split-attention Yolo(Msa-yolo) greatly enhance the feature of small nodules and boost up their performance, the overall result shows that the mean accuracy precision (mAP) of our Msa-Yolo compared to Yolox has increased from 85.10% to 86.64% on LUNA16 dataset, and from 90.13% to 94.15% on LCS dataset compared to YoloX. Besides, we get only 8.35 average number of candidates per scan with 96.32% sensitivity on LUNA16 dataset, which greatly outperforms other existing systems. At the segmentation stage, the mean intersection over union (mIOU) of our CAD system has increased from 71.66% to 76.84% on LCS dataset comparing to baseline. Conclusion: A fast, accurate and robust CAD system for nodule detection, segmentation and classification is proposed in this paper. And it is confirmed by the experimental results that the proposed system possesses the ability to detect and segment small nodules.	[Xiong, Yixin; Zhou, Yongcheng; Wang, Yujuan; Deng, Lei] Chongqing Univ, Sch Automat, State Key Lab Power Transmiss Equipment & Syst Se, Chongqing, Peoples R China; [Liu, Quanxing] UniArmy Med Vers Xinqiao Hosp, Dept Thorac Surg, Chongqing, Peoples R China	Chongqing University	Zhou, YC (corresponding author), Chongqing Univ, Sch Automat, State Key Lab Power Transmiss Equipment & Syst Se, Chongqing, Peoples R China.	cquxyx@163.com; 289077816@qq.com	Wang, Yujuan/JHT-8286-2023; Deng, Lei/I-7030-2018		National Natural Science Foundation of China [61991400, 61991403, 61860206008, 61933012]; National Key Research and Development Program of China [2021ZD0201300]; medical and scientific research project of science and health joint department of Chongqing [2020MSXM031]; Natural Science Foundation of Chongqing [cstc2019jcyj-msxmX0319, cstc2019jscx-fxydX0092]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China(National Key Research & Development Program of China); medical and scientific research project of science and health joint department of Chongqing; Natural Science Foundation of Chongqing(Natural Science Foundation of Chongqing)	This work was supported in part by the National Natural Science Foundation of China under Grant 61991400, Grant 61991403, Grant 61860206008, and Grant 61933012, in part by the National Key Research and Development Program of China under Grant 2021ZD0201300, in part by the medical and scientific research project of science and health joint department of Chongqing for Liu (2020MSXM031), and in part by Natural Science Foundation of Chongqing under Grant cstc2019jcyj-msxmX0319 and Grant cstc2019jscx-fxydX0092.	Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204; Bochkovskiy A., 2020, COMPUTER VISION PATT, DOI DOI 10.48550/ARXIV.2004.10934; Cao WM, 2020, IEEE ACCESS, V8, P154007, DOI 10.1109/ACCESS.2020.3018666; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Dey R, 2018, I S BIOMED IMAGING, P774, DOI 10.1109/ISBI.2018.8363687; Ding J., MED IM COMP COMP ASS, P559; Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Ge Z, 2021, Arxiv, DOI arXiv:2107.08430; Gu JH, 2020, IEEE ACCESS, V8, P16302, DOI 10.1109/ACCESS.2020.2967238; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]; Knight SB, 2017, OPEN BIOL, V7, DOI 10.1098/rsob.170070; Midthun D.E., 2013, Prime Reports, V5, P12; Monkam P, 2019, IEEE ACCESS, V7, P78075, DOI 10.1109/ACCESS.2019.2920980; Pereira FR, 2021, IEEE ACCESS, V9, P123134, DOI 10.1109/ACCESS.2021.3109860; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Setio AAA, 2015, MED PHYS, V42, P5642, DOI 10.1118/1.4929562; Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866; Tang SY, 2021, IEEE ACCESS, V9, P43397, DOI 10.1109/ACCESS.2021.3060178; Wang J, 2019, IEEE ACCESS, V7, P46033, DOI 10.1109/ACCESS.2019.2908195; Wang WL, 2020, INT CONF AWARE SCI, DOI 10.1109/ICAST51195.2020.9319472; Wang WZ, 2019, IEEE ACCESS, V7, P128796, DOI 10.1109/ACCESS.2019.2939850; Wu HS, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2020.114532; Wu J, 2018, COMPUT METH PROG BIO, V159, P87, DOI 10.1016/j.cmpb.2018.03.004; Yan X, 2017, LECT NOTES COMPUT SC, V10118, P91, DOI 10.1007/978-3-319-54526-4_7; Yu CQ, 2021, INT J COMPUT VISION, V129, P3051, DOI 10.1007/s11263-021-01515-2; Yue Wu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10183, DOI 10.1109/CVPR42600.2020.01020; Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309; Zhang JJ, 2018, NEUROCOMPUTING, V317, P159, DOI 10.1016/j.neucom.2018.08.022; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao Y., Medical Imaging 2018: Computer-Aided Diagnosis, V0575, P713; Zheng SY, 2020, IEEE T MED IMAGING, V39, P797, DOI 10.1109/TMI.2019.2935553; Zhou ZX, 2022, IEEE J BIOMED HEALTH, V26, P5619, DOI 10.1109/JBHI.2022.3198509; Zhu WT, 2018, IEEE WINT CONF APPL, P673, DOI 10.1109/WACV.2018.00079	36	1	1	14	26	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126	1875-8452		AI COMMUN	AI Commun.		2023	36	4					269	284		10.3233/AIC-220318	http://dx.doi.org/10.3233/AIC-220318			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	U8LZ3					2024-09-18	WOS:001087274200002
J	Ishtaiwi, A; Ali, A; AI-Qerem, A; Alsmadi, Y; Aldweesh, A; Alauthman, M; Alzubi, O; Nashwan, S; Ramadan, A; AI-Zghoul, M; Alangari, S				Ishtaiwi, Abdelraouf; Ali, Ali; AI-Qerem, Ahmed; Alsmadi, Yazan; Aldweesh, Amjad; Alauthman, Mohammed; Alzubi, Omar; Nashwan, Shadi; Ramadan, Awad; AI-Zghoul, Musab; Alangari, Someah			Impact of Data-Augmentation on Brain Tumor Detection Using Different YOLO Versions Models	INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY			English	Article						Data-augmentation; objects detection; brain tumor; yolov7; computer vision	COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION	Brain tumors are widely recognized as one of the world's worst and most disabling diseases. Every year, thousands of people die as a result of brain tumors caused by the rapid growth of tumor cells. As a result, saving the lives of tens of thousands of people worldwide needs speedy investigation and automatic identification of brain tumors. In this paper, we propose a new methodology for detecting brain tumors. The designed framework assesses the application of cutting -edge YOLO models such as YOLOv3, YOLO v5n, YOLO v5s, YOLO v5m, YOLOv5l, YOLOv5x, and YOLOv7 with varying weights and data augmentation on a dataset of 7382 samples from three distinct MRI orientations, namely, axial, coronal, and sagittal. Several data augmentation techniques were also employed to minimize detector sensitivity while increasing detection accuracy. In addition, the Adam and Stochastic Gradient Descent (SGD) optimizers were compared. We aim to find the ideal network weight and MRI orientation for detecting brain cancers. The results show that with an IoU of 0.5, axial orientation had the highest detection accuracy with an average mAP of 97.33%. Furthermore, SGD surpasses Adam optimizer by more than 20% mAP. Also, it was found that YOLO 5n, YOLOv5s, YOLOv5x, and YOLOv3 surpass others by more than 95% mAP. Besides that, it was observed that the YOLOv5 and YOLOv3 models are more sensitive to data augmentation than the YOLOv7 model.	[Ishtaiwi, Abdelraouf; Alauthman, Mohammed] Univ Petra, Fac Informat Technol, Amman, Jordan; [Ali, Ali] Al Ahliyya Amman Univ, Fac Engn, Amman, Jordan; [AI-Qerem, Ahmed; Alsmadi, Yazan] Zarqa Univ, Fac Informat Technol, Zarqa, Jordan; [Aldweesh, Amjad; Alangari, Someah] Shaqra Univ, Coll Comp & Informat Technol, Shaqra, Saudi Arabia; [Alzubi, Omar] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia; [Nashwan, Shadi] Middle East Univ, Fac Informat Technol, Amman, Jordan; [Ramadan, Awad] Umm Al Qura Univ, Coll Comp Al Qunfudah, Al Qunfudah, Saudi Arabia; [AI-Zghoul, Musab] Isra Univ, Fac Informat Technol, Amman, Jordan	Petra University; Al-Ahliyya Amman University; Zarqa University; Shaqra University; Umm Al Qura University; Middle East University; Umm Al Qura University; Isra University	Ishtaiwi, A (corresponding author), Univ Petra, Fac Informat Technol, Amman, Jordan.	aishtaiwi@uop.edu.jo; a.mahmoud@ammanu.edu.jo; ahmad_qerm@zu.edu.jo; Alsmadi@zu.edu.jo; a.aldweesh@su.edu.sa; mohammad.alauthman@uop.edu.jo; orzubi@uqu.edu.sa; snashwan@meu.edu.jo; amabker@uqu.edu.sa; musab.alzgool@iu.edu.jo; salangari@su.edu.sa	Aldweesh, Amjad/AAI-2027-2021; Nashwan, Shadi/N-9471-2019; Mohd Ali, Ali/AAP-1832-2020	Mohd Ali, Ali/0000-0003-4759-2835	Deanship of Scientific Research at Shaqra University	Deanship of Scientific Research at Shaqra University	<B>Acknowledgement</B> The authors would like to thank the Deanship of Scientific Research at Shaqra University for supporting this research.	Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33; Atik Muhammed Enes, 2021, Innovations in Smart Cities Applications. Proceedings of the 5th International Conference on Smart City Applications. Lecture Notes in Networks and Systems (LNNS 183), P797, DOI 10.1007/978-3-030-66840-2_60; Atik SO, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125551; Badran EF, 2010, ICCES'2010: THE 2010 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS, P368, DOI 10.1109/ICCES.2010.5674887; Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047; Batra P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145283; Bayram AF, 2022, AVRUPA BILIM TEKNOLO, V40, P67, DOI DOI 10.31590/EJOSAT.1171777; Cepni S, 2020, BALT J MOD COMPUT, V8, P347, DOI 10.22364/bjmc.2020.8.2.10; Chan HP, 2020, MED PHYS, V47, pE218, DOI 10.1002/mp.13764; Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14; Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381; Dai JF, 2016, ADV NEUR IN, V29; Gupta A., 2021, P 13 ANN WORKSH OPT; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13; Huang X, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533813; Joseph R., 2018, YOLOV3 INCREMENTAL I, DOI DOI 10.48550/ARXIV.1804.02767; Kavitha R., 2016, International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering, V5, P1468, DOI [10.15662/IJAREEIE.2016.0503043, DOI 10.15662/IJAREEIE.2016.0503043]; Khambhata KG, 2016, Int J Innov Res Comput Commun Eng, V4, P8982; Kuznetsova A., 2021, Cyber-Physical Systems: Modelling and Intelligent Control, DOI 10.1007/978-3-030-66077-228; Lee S, 2019, LECT NOTES COMPUT SC, V11366, P373, DOI 10.1007/978-3-030-20876-9_24; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Logeswari T., 2010, Journal of Cancer Research and Experimental Oncology, V2, P006; Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002; Magnuska ZA, 2022, CANCERS, V14, DOI 10.3390/cancers14020277; Mohiyuddin A, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/1359019; Montalbo FJP, 2020, KSII T INTERNET INF, V14, P4816, DOI 10.3837/tiis.2020.12.011; Nepal U, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020464; Nogales A, 2021, ARTIF INTELL MED, V112, DOI 10.1016/j.artmed.2021.102020; Oza P, 2022, NEURAL COMPUT APPL, V34, P1815, DOI 10.1007/s00521-021-06804-y; Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458; Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren S., 2015, Faster r-cnn: Towards real-time object detection with region proposal networks, P28; Shelatkar T, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/2858845; Singh L, 2012, LECT NOTES COMPUT SC, V7632, P94, DOI 10.1007/978-3-642-34123-6_9; Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455; Tian L, 2019, LECT NOTES COMPUT SC, V11542, P476, DOI 10.1007/978-3-030-22514-8_47; Vengaloor R, 2024, INT ARAB J INF TECHN, V21, P94, DOI 10.34028/iajit/21/1/9; Walia IS, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232996; Wang C, 2023, NEURAL COMPUT APPL, V35, P2575, DOI 10.1007/s00521-022-07730-3; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Wang Z, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10071190; Wenkel S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134350; White NS, 2013, AM J NEURORADIOL, V34, P958, DOI 10.3174/ajnr.A3327; Xianjia Y, 2022, Arxiv, DOI arXiv:2203.04064; Xu S, 2022, LECT NOTES COMPUT SC, V13531, P531, DOI 10.1007/978-3-031-15934-3_44; Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619; Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147; Zhang Shangjie Ge, 2022, Comput Intell Neurosci, V2022, P6081680, DOI 10.1155/2022/6081680; Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038	51	0	0	6	6	ZARKA PRIVATE UNIV	ZARQA	COLL COMPUTING & INFORMATION SOC, PO BOX 132222, ZARQA, 13132, JORDAN	1683-3198			INT ARAB J INF TECHN	Int. Arab J. Inf. Technol.	MAY	2024	21	3					466	482		10.34028/iajit/21/3/10	http://dx.doi.org/10.34028/iajit/21/3/10			17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TE7W3		gold			2024-09-18	WOS:001239661100010
J	Zheng, X; Tian, B; Li, JJ				Zheng Xin; Tian Bo; Li Jing-jing			Intelligent recognition method of cervical cell cluster based on YOLO model	CHINESE JOURNAL OF LIQUID CRYSTALS AND DISPLAYS			Chinese	Article						cervical cell cluster; data augmentation; Resnet 50; YOLO v2		Aiming to the automatic recognition of cervical cell cluster, a smart recognition method based on YOLO v2 model was proposed. At first, the model resnet50 was used as basic feature extraction module according to the characters of cervical cell cluster recognition task. Meanwhile, the related data amplification and training program of YOLO v2 network were also proposed. At the same time, we collect the scan image of cervical cell liquid base smear to build the cervical cell cluster image data set and the cell cluster was marked by cytopathic experts. The result shows that the automatic recognition of cervical cell cluster was effectively realized with this method. The accuracy rate of cervical cell cluster was 75.9% and the recall rate was 86.3%. The accuracy rate of cervical cell pathological identification was 87.0% and the recall rate was 86.7%. In this paper, deep learning technique was leaded into the cervical cell auxiliary screening field, it can promote the research of automatic auxiliary screening of early cervical cancer.	[Zheng Xin] Univ Elect Sci & Technol China, Coll Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China; [Tian Bo] ChengduJiuding Tianyuan Intellectual Property Agc, Chengdu 610041, Sichuan, Peoples R China; [Li Jing-jing] Jiangsu Univ Sci & Technol, Coll Comp Sci & Engn, Zhenjiang 212003, Peoples R China	University of Electronic Science & Technology of China; Jiangsu University of Science & Technology	Li, JJ (corresponding author), Jiangsu Univ Sci & Technol, Coll Comp Sci & Engn, Zhenjiang 212003, Peoples R China.	ljj121607@163.com			National Natural Science Foundation of China [61775030]; Light Control Key Laboratory Open Fund of the Chinese Academy of Sciences [2017LBC003]; Important Special Fund for Applied R & D in Guangdong Province [2015BD10131002]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Light Control Key Laboratory Open Fund of the Chinese Academy of Sciences; Important Special Fund for Applied R & D in Guangdong Province	Supported by National Natural Science Foundation of China (No. 61775030); Light Control Key Laboratory Open Fund of the Chinese Academy of Sciences (No.2017LBC003); The Important Special Fund for Applied R & D in Guangdong Province (No.2015BD10131002)	Ashtarian Hossein PhD, 2017, Int J Community Based Nurs Midwifery, V5, P188; BRADLEY A P, 2010, IMAGE VISION COMPUT, P279; Geng QT, 2018, CHIN OPT, V11, P174, DOI 10.3788/CO.20181102.0174; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Latsuzbaia A, 2017, DIAGN CYTOPATHOL, V45, P384, DOI 10.1002/dc.23678; Li F, 2016, CHIN OPT, V9, P74, DOI 10.3788/CO.20160901.0074; Li Yu, 2018, Optics and Precision Engineering, V26, P201, DOI 10.3788/OPE.20182601.0200; Long SY, 2017, CHIN OPT, V10, P719, DOI 10.3788/CO.20171006.0719; Lu Z, 2015, IEEE T IMAGE PROCESS, V24, P1261, DOI 10.1109/TIP.2015.2389619; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Nosrati MS, 2015, I S BIOMED IMAGING, P186, DOI 10.1109/ISBI.2015.7163846; PHOULADY H A, 2015, P 2015 12 IEEE INT S, P186; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; USHIZIMA D M, 2014, OVERLAPPING CERVICAL, P286; Xin L, 2018, CHIN J LIQ CRYST DIS, V33, P347, DOI 10.3788/YJYXS20183304.0347; Zhu SS, 2018, CHIN OPT, V11, P459, DOI 10.3788/CO.20181103.0459	16	5	8	0	26	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING, 100717, PEOPLES R CHINA	1007-2780			CHIN J LIQ CRYST DIS	Chin. J. Liq. Cryst. Disp.	NOV 5	2018	33	11					965	971		10.3788/YJYXS20183311.0965	http://dx.doi.org/10.3788/YJYXS20183311.0965			7	Crystallography	Emerging Sources Citation Index (ESCI)	Crystallography	HG6VA					2024-09-18	WOS:000455123100010
J	Al-masni, MA; Al-antari, MA; Park, JM; Gi, G; Kim, TY; Rivera, P; Valarezo, E; Choi, MT; Han, SM; Kim, TS				Al-masni, Mohammed A.; Al-antari, Mugahed A.; Park, Jeong-Min; Gi, Geon; Kim, Tae-Yeon; Rivera, Patricio; Valarezo, Edwin; Choi, Mun-Taek; Han, Seung-Moo; Kim, Tae-Seong			Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						Breast cancer; Mass detection and classification; Computer Aided Diagnosis; Deep learning; You Only Look Once (YOLO)	SEGMENTATION	Background and objective: Automatic detection and classification of the masses in mammograms are still a big challenge and play a crucial role to assist radiologists for accurate diagnosis. In this paper, we propose a novel Computer-Aided Diagnosis (CAD) system based on one of the regional deep learning techniques, a ROI-based Convolutional Neural Network (CNN) which is called You Only Look Once (YOLO). Although most previous studies only deal with classification of masses, our proposed YOLO-based CAD system can handle detection and classification simultaneously in one framework. Methods: The proposed CAD system contains four main stages: preprocessing of mammograms, feature extraction utilizing deep convolutional networks, mass detection with confidence, and finally mass classification using Fully Connected Neural Networks (FC-NNs). In this study, we utilized original 600 mammograms from Digital Database for Screening Mammography (DDSM) and their augmented mammograms of 2,400 with the information of the masses and their types in training and testing our CAD. The trained YOLO-based CAD system detects the masses and then classifies their types into benign or malignant. Results: Our results with five-fold cross validation tests show that the proposed CAD system detects the mass location with an overall accuracy of 99.7%. The system also distinguishes between benign and malignant lesions with an overall accuracy of 97%. Conclusions: Our proposed system even works on some challenging breast cancer cases where the masses exist over the pectoral muscles or dense regions. (C) 2018 Elsevier B.V. All rights reserved.	[Al-masni, Mohammed A.; Al-antari, Mugahed A.; Park, Jeong-Min; Gi, Geon; Kim, Tae-Yeon; Rivera, Patricio; Valarezo, Edwin; Han, Seung-Moo; Kim, Tae-Seong] Kyung Hee Univ, Coll Elect & Informat, Dept Biomed Engn, Yongin, South Korea; [Choi, Mun-Taek] Sungkyunkwan Univ, Sch Mech Engn, Seoul, South Korea	Kyung Hee University; Sungkyunkwan University (SKKU)	Kim, TS (corresponding author), Kyung Hee Univ, Coll Elect & Informat, Dept Biomed Engn, Yongin, South Korea.	m.almasani@khu.ac.kr; en.mualshz@khu.ac.kr; jmpark@khu.ac.kr; geon@khu.ac.kr; kty@khu.ac.kr; patoalejor@khu.ac.kr; edgivala@khu.ac.kr; mtchoi@skku.edu; smhan@khu.ac.kr; tskim@khu.ac.kr	Han, Seungmoo/KIC-1598-2024; Al-masni, Mohammed/AFR-0105-2022; Añazco, Edwin/AAH-1458-2021; Choi, Mun-Taek/N-2351-2014; Al-antari, Prof. Mugahed A./M-5602-2018	AL-MASNI, MOHAMMED/0000-0002-1548-965X; Choi, Mun-Taek/0000-0002-5025-8785; Al-antari, Prof. Mugahed A./0000-0002-4457-4407; Rivera, Patricio/0000-0001-6440-5478; Valarezo Anazco, Edwin/0000-0003-0077-8528	Center for Integrated Smart Sensors - Ministry of Science, ICT & Future Planning as a Global Frontier Project [CISS- 2011-0031863]; International Collaborative Research and Development Programme (Ministry of Trade, Industry and Energy (MOTIE, Korea)) [N0002252]	Center for Integrated Smart Sensors - Ministry of Science, ICT & Future Planning as a Global Frontier Project(Ministry of Science, ICT & Future Planning, Republic of Korea); International Collaborative Research and Development Programme (Ministry of Trade, Industry and Energy (MOTIE, Korea))(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea)	This work was supported by the Center for Integrated Smart Sensors funded by the Ministry of Science, ICT & Future Planning as a Global Frontier Project (CISS- 2011-0031863). This work was also supported by International Collaborative Research and Development Programme (funded by the Ministry of Trade, Industry and Energy (MOTIE, Korea) (N0002252).	Akselrod-Ballin A, 2016, LECT NOTES COMPUT SC, V10008, P197, DOI 10.1007/978-3-319-46976-8_21; Al-antari M. A., 2017, J MED BIOL ENG; Al-antari M. A., 2016, GLOB C ENG APPL SCI; Al-antari MA., 2017, J SCI ENG, V04, P114; Al-Masni M. A, 2017, ENG MED BIOL SOC EMB; Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014; Bar Y, 2018, COMP M BIO BIO E-IV, V6, P259, DOI 10.1080/21681163.2016.1138324; Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523; Cernazanu-Glavan C, 2013, ADV ELECTR COMPUT EN, V13, P87, DOI 10.4316/AECE.2013.01015; Chakraborty DP, 2004, MED PHYS, V31, P2313, DOI 10.1118/1.1769352; Coates A., 2011, 14 INT C ART INT STA; Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009; Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160; Dong M, 2015, J DIGIT IMAGING, V28, P613, DOI 10.1007/s10278-015-9778-4; Guo Q, 2016, NEUROCOMPUTING, V184, P78, DOI 10.1016/j.neucom.2015.07.135; Heath M., 2000, 5 INT WORKSH DIG MAM; Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060; Joseph RK, 2016, CRIT POL ECON S ASIA, P1; KALLENBERG M, 2010, DIG MAMM IWDM, V6136, P191; Kooi T., 2016, INT WORKSH DIG MAMM; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Li HX, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0332-0; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Metz Charles E, 2006, J Am Coll Radiol, V3, P413, DOI 10.1016/j.jacr.2006.02.021; Muramatsu C, 2016, COMPUT BIOL MED, V72, P43, DOI 10.1016/j.compbiomed.2016.03.007; Park J. H., 2016, 4 WORLD C APPL SCI E; Qiu YC, 2017, J X-RAY SCI TECHNOL, V25, P751, DOI 10.3233/XST-16226; Redmon J., 2013, OPEN SOURCE NEURAL N; Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Samala RK, 2016, MED PHYS, V43, P6654, DOI 10.1118/1.4967345; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Siegel RL, 2023, CA-CANCER J CLIN, V73, P233, DOI 10.3322/caac.21772; Szymanska Ewa, 2012, Metabolomics, V8, P3; Taghanaki SA, 2017, COMPUT METH PROG BIO, V145, P85, DOI 10.1016/j.cmpb.2017.04.012; Virmani J., 2016, PCA PNN PCA SVM BASE, P159; Wu T., 2010, U.S. Patent, Patent No. [7,764,820, 7764820]; Yosinski Jason, 2014, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1411.1792	38	264	279	19	249	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607	1872-7565		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	APR	2018	157						85	94		10.1016/j.cmpb.2018.01.017	http://dx.doi.org/10.1016/j.cmpb.2018.01.017			10	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Medical Informatics	FX2NJ	29477437		Y	N	2024-09-18	WOS:000425897400009
J	Su, YY; Liu, Q; Xie, WT; Hu, PZ				Su, Yongye; Liu, Qian; Xie, Wentao; Hu, Pingzhao			YOLO-LOGO: A transformer-based YOLO segmentation model for breast mass detection and segmentation in digital mammograms	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						Breast cancer; Mass detection; Mass segmentation; Deep learning; Transformer		Background and objective: Both mass detection and segmentation in digital mammograms play a crucial role in early breast cancer detection and treatment. Furthermore, clinical experience has shown that they are the upstream tasks of pathological classification of breast lesions. Recent advancements in deep learning have made the analyses faster and more accurate. This study aims to develop a deep learning model architecture for breast cancer mass detection and segmentation using the mammography. Methods: In this work we proposed a double shot model for mass detection and segmentation simultaneously using a combination of YOLO (You Only Look Once) and LOGO (Local-Global) architectures. Firstly, we adopted YoloV5L6, the state-of-the-art object detection model, to position and crop the breast mass in mammograms with a high resolution; Secondly, to balance training efficiency and segmentation performance, we modified the LOGO training strategy to train the whole images and cropped images on the global and local transformer branches separately. The two branches were then merged to form the final segmentation decision. Results: The proposed YOLO-LOGO model was tested on two independent mammography datasets (CBIS-DDSM and INBreast). The proposed model performs significantly better than previous works. It achieves true positive rate 95.7% and mean average precision 65.0% for mass detection on CBIS-DDSM dataset. Its performance for mass segmentation on CBIS-DDSM dataset is F1-score = 74.5% and IoU= 64.0%. The similar performance trend is observed in another independent dataset INBreast as well. Conclusions: The proposed model has a higher efficiency and better performance, reduces computational requirements, and improves the versatility and accuracy of computer-aided breast cancer diagnosis. Hence it has the potential to enable more assistance for doctors in early breast cancer detection and treatment, thereby reducing mortality. (C) 2022 Elsevier B.V. All rights reserved.	[Su, Yongye; Liu, Qian; Xie, Wentao; Hu, Pingzhao] Univ Manitoba, Dept Biochem & Med Genet, Room 308 Basic Med Sci Bldg,745 Bannatyne Ave, Winnipeg, MB R3E 0J9, Canada; [Liu, Qian; Hu, Pingzhao] Univ Manitoba, Dept Comp Sci, Winnipeg, MB, Canada; [Hu, Pingzhao] CancerCare Manitoba Res Inst, CancerCare Manitoba, Winnipeg, MB, Canada; [Hu, Pingzhao] Univ Manitoba, Dept Biochem & Med Genet, Room 308-Basic Med Sci Bldg,745 Bannatyne Ave, Winnipeg, MB R3E 0J9, Canada	University of Manitoba; University of Manitoba; CancerCare Manitoba Foundation; University of Manitoba	Hu, PZ (corresponding author), Univ Manitoba, Dept Biochem & Med Genet, Room 308-Basic Med Sci Bldg,745 Bannatyne Ave, Winnipeg, MB R3E 0J9, Canada.	pingzhao.hu@umanitoba.ca		Hu, Pingzhao/0000-0002-9546-2245; Su, Yongye/0000-0001-9297-5902	Cancer Care Manitoba Foundation; Research Manitoba; Mitacs	Cancer Care Manitoba Foundation; Research Manitoba; Mitacs	This work was supported in part by Cancer Care Manitoba Foundation, Research Manitoba and Mitacs. P.H. is the holder of Manitoba Medical Services Foundation (MMSF) Allen Rouse Basic Science Career Development Research Award.	Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774; Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584; Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003; Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017; Alom MZ, 2018, PROC NAECON IEEE NAT, P228, DOI 10.1109/NAECON.2018.8556686; [Anonymous], 2020, ARXIV; Baccouche A, 2021, NPJ BREAST CANCER, V7, DOI 10.1038/s41523-021-00358-x; Beitzel Steven M., 2009, MAP, P1691, DOI [DOI 10.1007/978-0-387-39940-9_492, 10.1007/978-0-387-39940-9492]; Boyle P., 2008, World Cancer Report 2008; Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9; Chefer H., 2020, TRANSFORMER INTERPRE; Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5; Cheng H., 2019, LOCAL GLOBAL LEARNIN; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; Clauwaert J, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab060; Famouri S, 2021, IEEE ACCESS, V9, P66163, DOI 10.1109/ACCESS.2021.3072997; Gotzsche PC, 2009, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001877.pub3; Ho Jonathan, 2019, Axial attention in multidimensional transformers; Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]; Hung Jane, 2017, Conf Comput Vis Pattern Recognit Workshops, V2017, P808, DOI [10.1109/cvprw.2017.112, 10.1109/CVPRW.2017.112]; Jeub L.G.S., 2021, LO CAL2GLOBAL SCALIN; Jocher G., **DATA OBJECT**, DOI 10.5281/ ZENODO.5563715; Jocher G., 2021, LS AWS SUPERVISELY Y, DOI [10.5281/ZENODO, DOI 10.5281/ZENODO]; Joseph R., 2018, YOLOV3 INCREMENTAL I, DOI DOI 10.48550/ARXIV.1804.02767; Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855; Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177; Lee RS., 2016, CANC IMAGING ARCH, V8, P2016, DOI [DOI 10.7937/K9/TCIA.2016.7O02S9CY, 10.1038/sdata.2017.177, DOI 10.1038/SDATA.2017.177]; Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Marmot MG, 2013, BRIT J CANCER, V108, P2205, DOI 10.1038/bjc.2013.177; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Oktay O., arXiv; Parkin DM, 2006, BREAST J, V12, pS70, DOI 10.1111/j.1075-122X.2006.00205.x; Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082; Provost F, 1998, MACH LEARN, V30, P127, DOI 10.1023/A:1007442505281; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Soulami KB, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102481; ThambawitaVajira V., ARXIV210700471; Tsochatzidis L, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105913; Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4; van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453; Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203; Wei J, 2011, MED PHYS, V38, P1867, DOI 10.1118/1.3560462; Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009; Yan YT, 2021, BIOCYBERN BIOMED ENG, V41, P746, DOI 10.1016/j.bbe.2021.03.005; Zhou K, 2016, DESTECH TRANS COMP; Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1	48	37	39	6	73	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607	1872-7565		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	JUN	2022	221								106903	10.1016/j.cmpb.2022.106903	http://dx.doi.org/10.1016/j.cmpb.2022.106903		MAY 2022	10	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Medical Informatics	1X9MA	35636358				2024-09-18	WOS:000807771600010
J	Ahmed, AM; Gargett, M; Madden, L; Mylonas, A; Chrystall, D; Brown, R; Briggs, A; Nguyen, T; Keall, P; Kneebone, A; Hruby, G; Booth, J				Ahmed, Abdella M.; Gargett, Maegan; Madden, Levi; Mylonas, Adam; Chrystall, Danielle; Brown, Ryan; Briggs, Adam; Nguyen, Trang; Keall, Paul; Kneebone, Andrew; Hruby, George; Booth, Jeremy			Evaluation of deep learning based implanted fiducial markers tracking in pancreatic cancer patients	BIOMEDICAL PHYSICS & ENGINEERING EXPRESS			English	Article						deep learning; stereotactic body radiation therapy; CNN and YOLO; fiducial markers	AUTOMATIC SEGMENTATION; RADIATION-THERAPY; QUALITY-ASSURANCE; TARGET TRACKING; KILOVOLTAGE; PROSTATE; TIME; LOCALIZATION; MOTION	Real-time target position verification during pancreas stereotactic body radiation therapy (SBRT) is important for the detection of unplanned tumour motions. Fast and accurate fiducial marker segmentation is a Requirement of real-time marker-based verification. Deep learning (DL) segmentation techniques are ideal because they don't require additional learning imaging or prior marker information (e.g., shape, orientation). In this study, we evaluated three DL frameworks for marker tracking applied to pancreatic cancer patient data. The DL frameworks evaluated were (1) a convolutional neural network (CNN) classifier with sliding window, (2) a pretrained you-only-look-once (YOLO) version-4 architecture, and (3) a hybrid CNN-YOLO. Intrafraction kV images collected during pancreas SBRT treatments were used as training data (44 fractions, 2017 frames). All patients had 1-4 implanted fiducial markers. Each model was evaluated on unseen kV images (42 fractions, 2517 frames). The ground truth was calculated from manual segmentation and triangulation of markers in orthogonal paired kV/MV images. The sensitivity, specificity, and area under the precision-recall curve (AUC) were calculated. In addition, the mean-absolute-error (MAE), root-mean-square-error (RMSE) and standard-error-of-mean (SEM) were calculated for the centroid of the markers predicted by the models, relative to the ground truth. The sensitivity and specificity of the CNN model were 99.41% and 99.69%, respectively. The AUC was 0.9998. The average precision of the YOLO model for different values of recall was 96.49%. The MAE of the three models in the left-right, superior-inferior, and anterior-posterior directions were under 0.88 +/- 0.11 mm, and the RMSE were under 1.09 +/- 0.12 mm. The detection times per frame on a GPU were 48.3, 22.9, and 17.1 milliseconds for the CNN, YOLO, and CNN-YOLO, respectively. The results demonstrate submillimeter accuracy of marker position predicted by DL models compared to the ground truth. The marker detection time was fast enough to meet the requirements for real-time application.	[Ahmed, Abdella M.; Gargett, Maegan; Madden, Levi; Chrystall, Danielle; Brown, Ryan; Kneebone, Andrew; Hruby, George; Booth, Jeremy] Royal North Shore Hosp, Northern Sydney Canc Ctr, St Leonards, NSW, Australia; [Madden, Levi; Mylonas, Adam; Nguyen, Trang; Keall, Paul] Univ Sydney, ACRF Image Inst 10, Fac Med & Hlth, Sydney, NSW, Australia; [Ahmed, Abdella M.; Gargett, Maegan] Univ Sydney, Fac Med & Hlth, Sch Hlth Sci, Sydney, Australia; [Chrystall, Danielle; Booth, Jeremy] Univ Sydney, Inst Med Phys, Sch Phys, Sydney, NSW, Australia; [Briggs, Adam] Shoalhaven Dist Mem Hosp, Shoalhaven Canc Care Ctr, Nowra, NSW, Australia; [Kneebone, Andrew; Hruby, George] Univ Sydney, Northern Clin Sch, Sydney Med Sch, Sydney, NSW, Australia	Royal North Shore Hospital; University of Sydney; University of Sydney; University of Sydney; NSW Health; Shoalhaven District Memorial Hospital; University of Sydney	Ahmed, AM (corresponding author), Royal North Shore Hosp, Northern Sydney Canc Ctr, St Leonards, NSW, Australia.; Ahmed, AM (corresponding author), Univ Sydney, Fac Med & Hlth, Sch Hlth Sci, Sydney, Australia.	abdella.ahmed@health.nsw.gov.au	Mylonas, Adam/AAY-1171-2021; Keall, Paul/A-6453-2018	Stewart, Maegan/0000-0002-7756-5187; Madden, Levi/0000-0002-7754-0756; Keall, Paul/0000-0003-4803-6507; Chrystall, Danielle/0009-0006-9251-6806; Ahmed, Abdella M/0000-0002-8210-4908; Mylonas, Adam/0000-0001-6941-383X				Amarsee K, 2021, J MED PHYS, V46, P80, DOI 10.4103/jmp.JMP_117_20; Balter JM, 1995, INT J RADIAT ONCOL, V33, P1281, DOI 10.1016/0360-3016(95)02083-7; Bertholet J, 2017, PHYS MED BIOL, V62, P1327, DOI 10.1088/1361-6560/aa52f7; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Campbell WG, 2017, MED PHYS, V44, P364, DOI 10.1002/mp.12073; Cui SN, 2020, MED PHYS, V47, pE127, DOI 10.1002/mp.14140; Edmunds D, 2019, BIOMED PHYS ENG EXPR, V5, DOI 10.1088/2057-1976/ab0734; Fledelius W, 2014, PHYS MED BIOL, V59, P2787, DOI 10.1088/0031-9155/59/11/2787; Fledelius W, 2011, MED PHYS, V38, P6351, DOI 10.1118/1.3658566; Hewson EA, 2019, MED PHYS, V46, P4725, DOI 10.1002/mp.13784; Ilic M, 2016, WORLD J GASTROENTERO, V22, P9694, DOI 10.3748/wjg.v22.i44.9694; Imura M, 2005, INT J RADIAT ONCOL, V63, P1442, DOI 10.1016/j.ijrobp.2005.04.024; Keall PJ, 2006, MED PHYS, V33, P3874, DOI 10.1118/1.2349696; Kim JH, 2018, RADIOTHER ONCOL, V126, P236, DOI 10.1016/j.radonc.2017.10.030; Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392; Liang ZW, 2020, MED PHYS, V47, P5482, DOI 10.1002/mp.14501; MATLAB, 2021, MATLAB 2021; Motley R, 2022, BIOMED PHYS ENG EXPR, V8, DOI 10.1088/2057-1976/ac34da; Mylonas A, 2021, J MED IMAG RADIAT ON, V65, P596, DOI 10.1111/1754-9485.13285; Mylonas A, 2019, MED PHYS, V46, P2286, DOI 10.1002/mp.13519; Nguyen DT, 2017, RADIOTHER ONCOL, V123, P37, DOI 10.1016/j.radonc.2017.02.013; Petrelli F, 2017, INT J RADIAT ONCOL, V97, P313, DOI 10.1016/j.ijrobp.2016.10.030; Poulsen PR, 2008, PHYS MED BIOL, V53, P4331, DOI 10.1088/0031-9155/53/16/008; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Regmi R, 2014, MED PHYS, V41, DOI 10.1118/1.4881335; Tang XL, 2007, PHYS MED BIOL, V52, P4081, DOI 10.1088/0031-9155/52/14/005; Wan HL, 2014, PHYS MED BIOL, V59, P1935, DOI 10.1088/0031-9155/59/8/1935; Willoughby T, 2012, MED PHYS, V39, P1728, DOI 10.1118/1.3681967; Wysocka B, 2010, INT J RADIAT ONCOL, V77, P53, DOI 10.1016/j.ijrobp.2009.04.046	31	2	2	0	7	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	2057-1976			BIOMED PHYS ENG EXPR	Biomed. Phys. Eng. Express	MAY 1	2023	9	3							035008	10.1088/2057-1976/acb550	http://dx.doi.org/10.1088/2057-1976/acb550			9	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	9Q9GD	36689758				2024-09-18	WOS:000945262900001
J	Wang, X; Li, HL; Zheng, P				Wang, Xun; Li, Hanlin; Zheng, Pan			RETRACTED: Automatic Detection and Segmentation of Ovarian Cancer Using a Multitask Model in Pelvic CT Images (Retracted Article)	OXIDATIVE MEDICINE AND CELLULAR LONGEVITY			English	Article; Retracted Publication							ULTRASOUND IMAGES; TUMORS	Ovarian cancer is one of the most common malignant tumours of female reproductive organs in the world. The pelvic CT scan is a common examination method used for the screening of ovarian cancer, which shows the advantages in safety, efficiency, and providing high-resolution images. Recently, deep learning applications in medical imaging attract more and more attention in the research field of tumour diagnostics. However, due to the limited number of relevant datasets and reliable deep learning models, it remains a challenging problem to detect ovarian tumours on CT images. In this work, we first collected CT images of 223 ovarian cancer patients in the Affiliated Hospital of Qingdao University. A new end-to-end network based on YOLOv5 is proposed, namely, YOLO-OCv2 (ovarian cancer). We improved the previous work YOLO-OC firstly, including balanced mosaic data enhancement and decoupled detection head. Then, based on the detection model, a multitask model is proposed, which can simultaneously complete the detection and segmentation tasks.	[Wang, Xun; Li, Hanlin] China Univ Petr East China, Coll Comp Sci & Technol, Qingdao 266580, Peoples R China; [Zheng, Pan] Univ Canterbury, Dept Accounting & Informat Syst, Christchurch 8140, New Zealand	China University of Petroleum; University of Canterbury	Zheng, P (corresponding author), Univ Canterbury, Dept Accounting & Informat Syst, Christchurch 8140, New Zealand.	wangsyun@upc.edu.cn; hlli@upc.edu.cn; pan.zheng@canterbury.ac.nz	Wang, Xun/HOH-8824-2023; Zheng, Pan/A-5435-2009	Zheng, Pan/0000-0002-6067-626X	National Key Research and Development Project of China [2021YFA1000103]; National Natural Science Foundation of China [61873280, 61972416, 62272479, 62202498]; Taishan Scholarship [tsqn201812029]; Foundation of Science and Technology Development of Jinan [201907116]; Natural Science Foundation of Shandong Province [ZR2021QF023]; Fundamental Research Funds for the Central Universities [21CX06018A]; Spanish project [PID2019106960GB-I00]; Juan de la Cierva [IJC2018-038539-I]	National Key Research and Development Project of China(National Key Research & Development Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Taishan Scholarship; Foundation of Science and Technology Development of Jinan; Natural Science Foundation of Shandong Province(Natural Science Foundation of Shandong Province); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Spanish project(Spanish Government); Juan de la Cierva(Instituto de Salud Carlos IIISpanish Government)	This work was supported by the National Key Research and Development Project of China (2021YFA1000103), the National Natural Science Foundation of China (Grant Nos. 61873280, 61972416, 62272479, and 62202498), the Taishan Scholarship (tsqn201812029), the Foundation of Science and Technology Development of Jinan (201907116), the Natural Science Foundation of Shandong Province (ZR2021QF023), the Fundamental Research Funds for the Central Universities (21CX06018A), the Spanish project PID2019106960GB-I00, and Juan de la Cierva IJC2018-038539-I.	Acharya UR, 2018, INT J FUZZY SYST, V20, P1385, DOI 10.1007/s40815-018-0456-9; [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386; [Anonymous], 2019, ARTIFICIAL INTELLIGE; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cheng JZ, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]; Ge Z, 2021, Arxiv, DOI arXiv:2107.08430; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]; Huttunen MJ, 2018, J BIOMED OPT, V23, DOI 10.1117/1.JBO.23.6.066002; Joseph R., 2018, YOLOV3 INCREMENTAL I, DOI DOI 10.48550/ARXIV.1804.02767; Khazendar S, 2015, FACTS VIEWS VIS OBGY, V7, P7; Khiewvan B, 2017, EUR J NUCL MED MOL I, V44, P1079, DOI 10.1007/s00259-017-3638-z; Ko SY, 2019, HEAD NECK-J SCI SPEC, V41, P885, DOI 10.1002/hed.25415; Kuan KS, 2017, Arxiv, DOI arXiv:1705.09435; Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; McCloskey CW, 2014, FRONT ONCOL, V4, DOI 10.3389/fonc.2014.00053; Mutch DG, 2014, GYNECOL ONCOL, V133, P401, DOI 10.1016/j.ygyno.2014.04.013; Perol T, 2018, SCI ADV, V4, DOI 10.1126/sciadv.1700578; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Srivastava S., 2020, SN Comput. Sci, V1, P81, DOI [10.1007/s42979-020-0109-6, DOI 10.1007/S42979-020-0109-6]; Tan M., 2020, P IEEE CVF C COMP VI, P10778, DOI DOI 10.48550/ARXIV.1911.09070; Teichmann M, 2018, IEEE INT VEH SYM, P1013, DOI 10.1109/IVS.2018.8500504; Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972; Torre LA, 2018, CA-CANCER J CLIN, V68, P284, DOI 10.3322/caac.21456; Vázquez MA, 2018, BIOMED SIGNAL PROCES, V46, P86, DOI 10.1016/j.bspc.2018.07.001; Wang X, 2022, OXID MED CELL LONGEV, V2022, DOI 10.1155/2022/2129303; Wang X, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/9452157; Wang X, 2021, INTELL DATA ANAL, V25, P1565, DOI 10.3233/IDA-205542; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Wu M, 2018, BIOSCIENCE REP, V38, DOI 10.1042/BSR20180289; Yu YC, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183555; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442; Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094; Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953	40	3	4	1	26	HINDAWI LTD	LONDON	ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND	1942-0900	1942-0994		OXID MED CELL LONGEV	Oxidative Med. Cell. Longev.	OCT 11	2022	2022								6009107	10.1155/2022/6009107	http://dx.doi.org/10.1155/2022/6009107			13	Cell Biology	Science Citation Index Expanded (SCI-EXPANDED)	Cell Biology	5U4FQ	36267814	Green Published, gold			2024-09-18	WOS:000876505200007
J	Karaman, A; Karaboga, D; Pacal, I; Akay, B; Basturk, A; Nalbantoglu, U; Coskun, S; Sahin, O				Karaman, Ahmet; Karaboga, Dervis; Pacal, Ishak; Akay, Bahriye; Basturk, Alper; Nalbantoglu, Ufuk; Coskun, Seymanur; Sahin, Omur			Hyper-parameter optimization of deep learning architectures using artificial bee colony (ABC) algorithm for high performance real-time automatic colorectal cancer (CRC) polyp detection	APPLIED INTELLIGENCE			English	Article						Colorectal cancer; Deep learning; Hyper-parameter optimization; Artificial bee colony; Real-time polyp detection; YOLOv4	CONVOLUTIONAL NEURAL-NETWORKS	Colorectal cancer (CRC) is one of the most common and malignant types of cancer worldwide. Colonoscopy, considered the gold standard for CRC screening, allows immediate removal of polyps, which are precursors to CRC. Many computer-aided diagnosis systems (CADs) have been proposed for automatic polyp detection. Most of these systems are based on traditional machine learning algorithms and their generalization ability, sensitivity and specificity are limited. On the other hand, with the widespread use of deep learning algorithms in medical image analysis and the successful results in the analysis of colonoscopy images, especially in the early and accurate detection of polyps, these problems are eliminated in recent years. In short, deep learning algorithms and applications have gained a critical role in CAD systems for real-time autonomous polyp detection. Here, we make significant improvements to object detection algorithms to improve the performance of CAD-based real-time polyp detection systems. We integrate the artificial bee colony algorithm (ABC) into the YOLO algorithm to optimize the hyper-parameters of YOLO-based algorithms. The proposed method can be easily integrated into all YOLO algorithms such as YOLOv3, YOLOv4, Scaled-YOLOv4, YOLOv5, YOLOR and YOLOv7. The proposed method improves the performance of the Scaled-YOLOv4 algorithm with an average of more than 3% increase in mAP and a more than 2% improvement in F1 value. In addition, the most comprehensive study is conducted by evaluating the performance of all existing models in the Scaled-YOLOv4 algorithm (YOLOv4s, YOLOv4m, YOLOV4-CSP, YOLOv4-P5, YOLOV4-P6 and YOLOv4-P7) on the novel SUN and PICCOLO polyp datasets. The proposed method is the first study for the optimization of YOLO-based algorithms in the literature and makes a significant contribution to the detection accuracy.	[Karaman, Ahmet; Coskun, Seymanur] Acibadem Hosp, Dept Gastroenterol, Kayseri, Turkey; [Karaboga, Dervis; Akay, Bahriye; Basturk, Alper; Nalbantoglu, Ufuk; Sahin, Omur] Erciyes Univ, Engn Fac, Dept Comp Engn, Kayseri, Turkey; [Karaboga, Dervis; Pacal, Ishak; Akay, Bahriye; Basturk, Alper; Nalbantoglu, Ufuk; Sahin, Omur] Erciyes Univ, Artificial Intelligence & Big Data Applicat & Res, Kayseri, Turkey; [Pacal, Ishak] Igdir Univ, Engn Fac, Dept Comp Engn, Igdir, Turkey	Acibadem Hastaneleri; Erciyes University; Erciyes University; Igdir University	Pacal, I (corresponding author), Erciyes Univ, Artificial Intelligence & Big Data Applicat & Res, Kayseri, Turkey.; Pacal, I (corresponding author), Igdir Univ, Engn Fac, Dept Comp Engn, Igdir, Turkey.	Ishakpacal@gmail.com	Sahin, Omur/AAO-3107-2020; Basturk, Alper/A-8953-2012; Karaboga, Dervis/AAY-8495-2020; Pacal, Ishak/HJJ-1662-2023; Basturk Akay, Bahriye/A-8934-2012	Sahin, Omur/0000-0003-1213-7445; Pacal, Ishak/0000-0001-6670-2169; Basturk Akay, Bahriye/0000-0001-6575-4725; Basturk, Alper/0000-0001-5810-0643				Akay B, 2022, ARTIF INTELL REV, V55, P829, DOI 10.1007/s10462-021-09992-0; Ali M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081485; [Anonymous], ALEXEYAB DARKNET YOL; [Anonymous], WONGKINYIU SCALEDYOL; Badem H, 2017, NEUROCOMPUTING, V266, P506, DOI 10.1016/j.neucom.2017.05.061; Banharnsakun A, 2019, INT J MACH LEARN CYB, V10, P1301, DOI 10.1007/s13042-018-0811-z; Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934; Bora K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83788-8; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Durak S, 2021, MED BIOL ENG COMPUT, V59, P1563, DOI 10.1007/s11517-021-02398-8; Erkan U, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03631-w; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoang MC, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101878; Isik G, 2020, J FAC ENG ARCHIT GAZ, V35, P213, DOI 10.17341/gazimmfd.453677; Jocher Glenn, 2022, Zenodo; Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006; Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77; Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0; Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6; Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6; Kiliçarslan S, 2022, NEURAL COMPUT APPL, V34, P13909, DOI 10.1007/s00521-022-07211-7; Kilicarslan S, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102231; Lee JN, 2022, J ELECTR ENG TECHNOL, V17, P3057, DOI 10.1007/s42835-022-01191-3; Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079; Nogueira-Rodríguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4; Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y; Ozkok FO, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103168; Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031; Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519; Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003; Qian ZQ, 2022, IEEE SENS J, V22, P10841, DOI 10.1109/JSEN.2022.3170034; Rawla P, 2019, GASTROENTEROL REV, V14, P89, DOI 10.5114/pg.2018.81072; Reboiro-Jato A, 2022, CITATION NOGUEIRA RO, DOI [10.3390/diagnostics12040898, DOI 10.3390/DIAGNOSTICS12040898]; Redmon J., 2018, arXiv; Ren S., 2015, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Sanchez-Peralta LF, 2021, ARTIF INTELL MED, P1, DOI [10.1007/978-3-030-58080-3_308-1, DOI 10.1007/978-3-030-58080-3_308-1]; Schiele S, 2021, CANCERS, V13, DOI 10.3390/cancers13092074; Souaidi M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12082030; Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660; Tamang LD, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210982; Theodosi A, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01184-8; Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264; Wang C.-Y., 2021, You Only Learn One Representation: Unified Network for Multiple Tasks, P1; Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283; Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203; Younas F, 2023, APPL INTELL, V53, P2410, DOI 10.1007/s10489-022-03689-9; Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026	54	27	27	15	31	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X	1573-7497		APPL INTELL	Appl. Intell.	JUN	2023	53	12					15603	15620		10.1007/s10489-022-04299-1	http://dx.doi.org/10.1007/s10489-022-04299-1		NOV 2022	18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	I1FG3					2024-09-18	WOS:000887886700001
C	Tseng, PH; Lin, JT; Liao, XY; Lee, SL; Lin, MC; Huang, YL; Lou, PJ; Dong, CY		Amelink, A; Nadkarni, SK; Scarcelli, G		Tseng, Po-Hang; Lin, Jin-Tang; Liao, Xin-Yu; Lee, Sheng-Lin; Lin, Mei-Chun; Huang, Yen-Lin; Lou, Pei-Jen; Dong, Chen-Yuan			Calculating Tumor Proportional Score of HNSCC Patients with Deep Learning Object Detection	EMERGING TECHNOLOGIES FOR CELL AND TISSUE CHARACTERIZATION	Proceedings of SPIE		English	Proceedings Paper	European Conferences on Biomedical Optics - Emerging Technologies for Cell and Tissue Characterization	JUN 20-25, 2021	ELECTR NETWORK	SPIE, Opt Soc			CANCER; HEAD	This work illustrates how tumor proportional score is estimated using object detection method YOLO and compared with a pathologist's calculation. Results show deep learning can achieve good results and be used on clinical applications.	[Tseng, Po-Hang; Lin, Jin-Tang; Liao, Xin-Yu; Lee, Sheng-Lin; Dong, Chen-Yuan] Natl Taiwan Univ, Dept Phys, Taipei 106, Taiwan; [Lin, Mei-Chun; Huang, Yen-Lin; Lou, Pei-Jen] Natl Taiwan Univ Hosp, Dept Otolaryngol, Taipei 100, Taiwan	National Taiwan University; National Taiwan University; National Taiwan University Hospital	Dong, CY (corresponding author), Natl Taiwan Univ, Dept Phys, Taipei 106, Taiwan.	pjlou@ntu.edu.tw; cydong@phys.ntu.edu.tw	Huang, Yen-Lin/ABC-1546-2020; Chen, Yen-Yuan/AAF-4335-2020					Cohen EEW, 2019, J IMMUNOTHER CANCER, V7, DOI 10.1186/s40425-019-0662-5; Denaro N, 2016, CLIN EXP OTORHINOLAR, V9, P287	2	0	0	0	4	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	1996-756X	978-1-5106-4709-1; 978-1-5106-4708-4	PROC SPIE			2021	11921								119210L	10.1117/12.2615639	http://dx.doi.org/10.1117/12.2615639			3	Engineering, Biomedical; Optics; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Engineering; Optics; Imaging Science & Photographic Technology	BT1EX					2024-09-18	WOS:000797280300020
J	Wang, X; Li, HL; Wang, LS; Yu, YZ; Zhou, H; Wang, L; Song, T				Wang, Xun; Li, Hanlin; Wang, Lisheng; Yu, Yongzhi; Zhou, Hao; Wang, Lei; Song, Tao			An improved YOLOv3 model for detecting location information of ovarian cancer from CT images	INTELLIGENT DATA ANALYSIS			English	Article						Ovarian cancer; deep learning; CT image; object detection; YOLOv3		Ovarian cancer is a malignant tumor that poses a serious threat to women's lives. Computer-aided diagnosis (CAD) systems can classify the type of ovarian tumors, but few of them can provide exactly the location information of ovarian cancer cells. Recently, deep learning technology becomes hot for automatic detection of cancer cells, particularly for detecting their locations. In this work, we propose a novel end-to-end network YOLO-OC (Ovarian cancer) model, which can extract the characteristics of ovarian cancer more efficiently. In our method, deformable convolution is used to enhance the model's ability to learn geometric deformation in space. Squeeze-and-Excitation (SE) module is proposed to automatically learn the importance of different channel features. Data experiments are conducted on datasets collected from The Affiliated Hospital of Qingdao University Medical College, China. Experimental results show that our YOLO-OC model achieves 91.83%, 85.66% and 73.82% on mean average precision mAP@.5, mAP@.75 and mAP@[.5,.95], respectively, which performs better than Faster R-CNN, SSD and RetinaNet on both accuracy and efficiency.	[Wang, Xun; Li, Hanlin; Wang, Lisheng; Yu, Yongzhi; Song, Tao] China Univ Petr, Coll Comp Sci & Technol, Qingdao 266580, Shandong, Peoples R China; [Zhou, Hao; Wang, Lei] Qingdao Univ, Dept Gynaecol, Affiliated Hosp, Qingdao, Shandong, Peoples R China; [Song, Tao] Univ Politecn Madrid, Fac Comp Sci, Dept Artificial Intelligence, Campus Montegancedo, Madrid, Spain	China University of Petroleum; Qingdao University; Universidad Politecnica de Madrid	Song, T (corresponding author), China Univ Petr, Coll Comp Sci & Technol, Qingdao 266580, Shandong, Peoples R China.	t.song@upm.es	Wang, Xun/HOH-8824-2023; Song, Tao/T-7360-2018; Wang, Lei/AAI-3381-2020		National Natural Science Foundation of China [61873280, 61672033, 61672248, 61972416, 61772376]; Taishan Scholarship [tsqn201812029]; Major projects of the National Natural Science Foundation of China [41890851]; Natural Science Foundation of Shandong Province [ZR2019MF012]; Fundamental Research Funds for the Central Universities [18CX02152A, 19CX05003A-6]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Taishan Scholarship; Major projects of the National Natural Science Foundation of China; Natural Science Foundation of Shandong Province(Natural Science Foundation of Shandong Province); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported by National Natural Science Foundation of China (Grant Nos. 61873280, 61672033, 61672248, 61972416, 61772376), Taishan Scholarship (tsqn201812029), Major projects of the National Natural Science Foundation of China (Grant No. 41890851), Natural Science Foundation of Shandong Province (No. ZR2019MF012), Fundamental Research Funds for the Central Universities (18CX02152A, 19CX05003A-6).	Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hongkai Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P260, DOI 10.1007/978-3-030-58555-6_16; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]; Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1; Lheureux S, 2019, CA-CANCER J CLIN, V69, P280, DOI 10.3322/caac.21559; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo G., 2020, ARXIV200602334; McCloskey CW, 2014, FRONT ONCOL, V4, DOI 10.3389/fonc.2014.00053; Pang S., 2019, Pus Data Inform Keseh Kementr Keseh, V99, P1, DOI 10.1109/ACCESS.2019.2962862; Pang S.C., 2020, PEER PEER NETW APPL; Pang SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217647; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Shiwei Wang, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P29, DOI 10.1109/ICIVC50857.2020.9177456; Song T, 2019, IEEE ACCESS, V7, P166823, DOI 10.1109/ACCESS.2019.2953934; Song T, 2019, IEEE T NANOBIOSCI, V18, P176, DOI 10.1109/TNB.2019.2896981; Song T, 2018, IEEE T COGN DEV SYST, V10, P1106, DOI 10.1109/TCDS.2017.2785332; Sultana F, 2018, 2018 FOURTH IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P122, DOI 10.1109/ICRCICN.2018.8718718; Wang R, 2015, BIO-MED MATER ENG, V26, pS975, DOI 10.3233/BME-151392; Wu C., 2018, ECOC; Wu M., 2018, P 3 INT S ASIAN BR C; Zhang L, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1356-8; Zhou Xingyi, 2019, ABS190407850 ARXIV; Zhou XY, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P631; Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953	33	6	6	6	53	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X	1571-4128		INTELL DATA ANAL	Intell. Data Anal.		2021	25	6					1565	1578		10.3233/IDA-205542	http://dx.doi.org/10.3233/IDA-205542			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	WS6SS					2024-09-18	WOS:000715309500012
C	Lin, W		Chen, Y; Ludwig, H; Tu, Y; Fayyad, U; Zhu, X; Hu, X; Byna, S; Liu, X; Zhang, J; Pan, S; Papalexakis, V; Wang, J; Cuzzocrea, A; Ordonez, C		Lin, Wesley			YOLO-Green: A Real-Time Classification and Object Detection Model Optimized for Waste Management	2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)	IEEE International Conference on Big Data		English	Proceedings Paper	9th IEEE International Conference on Big Data (IEEE BigData)	DEC 15-18, 2021	ELECTR NETWORK	IEEE, IEEE Comp Soc, Ankura, Lyve Cloud, Seagate, NSF		Image classification; object detection; deep learning; convolutional neural networks; waste recycling		Deep neural networks (DNNs) play an important role in our daily lives, from aiding us in menial tasks to solving world issues such as cancer cell detection. However, few pieces of research have been conducted using DNNs and deep learning models as a medium to help classify and detect trash, in efforts to solve our global waste crisis. This is because current DNNs struggle to be both efficient and accurate while detecting indistinct objects such as waste. To address this issue, this work focuses on YOLO-Green, a novel real-time object detection model designed specifically for trash detection. The model is trained on a dataset gathered from real-world trash divided into seven of the most common types of solid waste. With only 100 epochs of training, YOLO-Green achieves an outstanding mAP of 78.04%, FPS of 2.72, while retaining a model size of only 117 MB. Based on the original object detection of YOLOv4, YOLO-Green exceeds YOLOv4 and other popular deep learning models in both its accuracy and efficiency, while maintaining a relatively small model size. Ultimately, this study sheds a positive light on the potential of using deep learning models as an alternative to manual waste management.	[Lin, Wesley] Morrison Acad Taichung, Dept Sci, Taichung, Taiwan		Lin, W (corresponding author), Morrison Acad Taichung, Dept Sci, Taichung, Taiwan.	linw@mca.org.tw						Albawi S, 2017, I C ENG TECHNOL; Aral RA, 2018, IEEE INT CONF BIG DA, P2058, DOI 10.1109/BigData.2018.8622212; Beltrami EJ, 1974, NETWORKS, V4, P65, DOI [10.1002/net.3230040106, DOI 10.1002/NET.3230040106]; Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934,ARXIV; Delalleau O., 2011, Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011, V24, P666; Fang W, 2020, IEEE ACCESS, V8, P1935, DOI 10.1109/ACCESS.2019.2961959; Hoornweg D., 2012, WORLD BANK; Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865; Liu Z, 2018, RESOUR CONSERV RECY, V136, P22, DOI 10.1016/j.resconrec.2018.04.005; Najafabadi M. M., 2015, J. Big Data, V2, P1; Parker Laura., 2018, National Geographic; Read AD, 1999, RESOUR CONSERV RECY, V26, P217, DOI 10.1016/S0921-3449(99)00008-7; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Wang Y, 2018, PROCEEDINGS OF THE 2018 1ST IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE INNOVATION AND INVENTION (ICKII 2018), P221, DOI 10.1109/ICKII.2018.8569109; Zhu QF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154314; Zhu Y, 2017, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.2017.8296389	16	6	6	1	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2639-1589		978-1-6654-3902-2	IEEE INT CONF BIG DA			2021							51	57		10.1109/BigData52589.2021.9671821	http://dx.doi.org/10.1109/BigData52589.2021.9671821			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BT1RU					2024-09-18	WOS:000800559500005
C	Naranpanawa, DNU; Gu, YY; Chandra, SS; Betz-Stablein, B; Sturm, RA; Soyer, HP; Eriksson, AP			IEEE	Naranpanawa, D. Nathasha U.; Gu, Yanyang; Chandra, Shekhar S.; Betz-Stablein, Brigid; Sturm, Richard A.; Soyer, H. Peter; Eriksson, Anders P.			Slim-YOLO: A Simplified Object Detection Model for the Detection of Pigmented Iris Freckles as a Potential Biomarker for Cutaneous Melanoma	2021 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2021)			English	Proceedings Paper	International Conference on Digital Image Computing - Techniques and Applications (DICTA)	NOV 29-DEC 01, 2021	ELECTR NETWORK	IEEE, IAPR, Australian Govt, Dept Def, Def Sci & Technol Grp, APRS, MathWorks, SmartSat CRC, AI4Space, Singular Hlth, Griffith Univ, Destinat Gold Coast		melanoma; deep learning; object detection; pigmented iris freckles		Melanomas are the most dangerous form of skin cancer, accounting for a majority of mortality among all skin cancers. As melanomas tend to go unnoticed without constant supervision, it is important that steps are taken to identify and prevent their spread before they reach more severe stages. Many recent clinical trials and research have identified various indicators of melanoma that may be used for early detection. In this work, we explore the use of Convolutional Neural Networks (CNN) to localize and detect one such indicator - a strong correlation between the number of pigmented freckles in a person's iris and their risk of developing melanoma on the skin. We model this task of detecting pigmented iris freckles as a single-class, one-sized object detection problem. For this, we propose Slim-YOLO, a lighter and simpler object detection model based on YOLOv3. The simplifications of Slim-YOLO are introduced through reducing the model computations by removing the need for multiple detection scales and classification. We also remove the constraints applied by anchor boxes. The experimental results show that Slim-YOLO is capable of achieving comparable performance (90:7% in mAP) with YOLOv3 (93:7%) while yielding a smaller model size of two-third the size of YOLOv3. These may prove highly beneficial to better facilitate deployment of the model on mobile devices in the future. Thus, we automate the iris freckle detection process successfully to help provide insights to practitioners, and contribute to the use of deep learning methods in detection of anomalies in medical imaging.	[Naranpanawa, D. Nathasha U.; Gu, Yanyang; Chandra, Shekhar S.; Eriksson, Anders P.] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia; [Betz-Stablein, Brigid; Sturm, Richard A.; Soyer, H. Peter] Univ Queensland, Diamantina Inst, Dermatol Res Ctr, Brisbane, Qld, Australia	University of Queensland; University of Queensland	Naranpanawa, DNU (corresponding author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.	nathasha.naranpanawa@uq.edu.au	H. Peter, Soyer/W-3791-2017; Sturm, Richard/C-9943-2009; Chandra, Shekhar/B-3698-2011; Betz-Stablein, Brigid/S-6925-2018	Chandra, Shekhar/0000-0001-6544-900X; Betz-Stablein, Brigid/0000-0003-3876-501X; Naranpanawa, Dilmi Nathasha Upendrini/0000-0001-5383-8788	Merchant Charitable Foundation; Australian Research Council [FT170100072, APP1137127]; Australian Research Council [FT170100072] Funding Source: Australian Research Council	Merchant Charitable Foundation; Australian Research Council(Australian Research Council); Australian Research Council(Australian Research Council)	This work has been funded by the Merchant Charitable Foundation and the Australian Research Council through grant FT170100072.; HPS holds an NHMRC MRFF Next Generation Clinical Researchers Program Practitioner Fellowship (APP1137127).	Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]; Cao ZG, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113833; Csoma RZ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160146; Dai JF, 2016, ADV NEUR IN, V29; EHINZ-Environmental Health Indicators New Zealand, MEL; Fang W, 2020, IEEE ACCESS, V8, P1935, DOI 10.1109/ACCESS.2019.2961959; Ferlay J, 2019, INT J CANCER, V144, P1941, DOI 10.1002/ijc.31937; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]; International Agency for Research on CancerWorld Health Organisation, 2018, GLOBAL CANC OBSERVAT; LabelBox Inc, LABELBOX; Laino AM, 2018, BRIT J DERMATOL, V178, P1119, DOI 10.1111/bjd.16323; Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Pham MT, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152501; Molchanov VV, 2017, PROC SPIE, V10334, DOI 10.1117/12.2270326; Narayanan DL, 2010, INT J DERMATOL, V49, P978, DOI 10.1111/j.1365-4632.2010.04474.x; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Schwab C, 2017, INVEST OPHTH VIS SCI, V58, P174, DOI 10.1167/iovs.17-21751; skin cancer foundation, 2021, SKIN CANC FACTS STAT; Sturm RA, 2009, PIGM CELL MELANOMA R, V22, P544, DOI 10.1111/j.1755-148X.2009.00606.x; Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012; Wong A, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P22, DOI 10.1109/EMC2-NIPS53020.2019.00013; Yao SJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051818	28	0	0	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-6654-1709-9				2021							266	273		10.1109/DICTA52665.2021.9647150	http://dx.doi.org/10.1109/DICTA52665.2021.9647150			8	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BT3XW					2024-09-18	WOS:000824642300037
J	Singh, SK; Abolghasemi, V; Anisi, MH				Singh, Sumit Kumar; Abolghasemi, Vahid; Anisi, Mohammad Hossein			Fuzzy Logic with Deep Learning for Detection of Skin Cancer	APPLIED SCIENCES-BASEL			English	Article						skin cancer; melanoma; YOLO; fuzzy logic; melanoma detection	MELANOMA; DIAGNOSIS; SEGMENTATION	Featured Application Deep learning-based diagnosis of a suspicious lesion using a simple handheld device such as smartphone. Awareness and frequency of diagnosis of malignant melanoma will be increased thereafter, increasing the chances of detection of skin cancer at an early stage. Out motivation is to deploy the deep learning algorithm using a smartphone application. Melanoma is the deadliest type of cancerous cell, which is developed when melanocytes, melanin producing cell, starts its uncontrolled growth. If not detected and cured in its situ, it might decrease the chances of survival of patients. The diagnosis of a melanoma lesion is still a challenging task due to its visual similarities with benign lesions. In this paper, a fuzzy logic-based image segmentation along with a modified deep learning model is proposed for skin cancer detection. The highlight of the paper is its dermoscopic image enhancement using pre-processing techniques, infusion of mathematical logics, standard deviation methods, and the L-R fuzzy defuzzification method to enhance the results of segmentation. These pre-processing steps are developed to improve the visibility of lesion by removing artefacts such as hair follicles, dermoscopic scales, etc. Thereafter, the image is enhanced by histogram equalization method, and it is segmented by proposed method prior to performing the detection phase. The modified model employs a deep neural network algorithm, You Look Only Once (YOLO), which is established on the application of Deep convolutional neural network (DCNN) for detection of melanoma lesion from digital and dermoscopic lesion images. The YOLO model is composed of a series of DCNN layers we have added more depth by adding convolutional layer and residual connections. Moreover, we have introduced feature concatenation at different layers which combines multi-scale features. Our experimental results confirm that YOLO provides a better accuracy score and is faster than most of the pre-existing classifiers. The classifier is trained with 2000 and 8695 dermoscopic images from ISIC 2017 and ISIC 2018 datasets, whereas PH2 datasets along with both the previously mentioned datasets are used for testing the proposed algorithm.	[Singh, Sumit Kumar; Abolghasemi, Vahid; Anisi, Mohammad Hossein] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, England	University of Essex	Abolghasemi, V (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, England.	ss20727@essex.ac.uk; v.abolghasemi@essex.ac.uk; m.anisi@essex.ac.uk	Abolghasemi, Vahid/AAC-8242-2020; Anisi, Mohammad Hossein/L-3718-2016	Abolghasemi, Vahid/0000-0002-2151-5180				Abuzaghleh O., 2014, Signal Image Process. Int. J. (SIPIJ), V15, P1, DOI [DOI 10.5121/SIPIJ.2014.5601, 10.5121/sipij.2014.5601]; Ahmed N, 2023, MULTIMED TOOLS APPL, V82, P11873, DOI 10.1007/s11042-022-13618-0; Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351; Alenezi F, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020262; [Anonymous], 2017, Am. Cancer Soc, DOI DOI 10.1101/GAD.1593107; Banerjee S, 2021, TRAIT SIGNAL, V38, P1327, DOI 10.18280/ts.380507; Barin S, 2022, ENG SCI TECHNOL, V34, DOI 10.1016/j.jestch.2022.101174; Bi L, 2017, Arxiv, DOI arXiv:1703.04197; Bi L, 2019, PATTERN RECOGN, V85, P78, DOI 10.1016/j.patcog.2018.08.001; Codella NCF, 2018, Arxiv, DOI arXiv:1710.05006; Chakraborty A, 2021, GRANULAR COMPUT, V6, P507, DOI 10.1007/s41066-020-00212-8; Chakraborty A, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020248; Cheng LB, 2021, LANDSLIDES, V18, P2751, DOI 10.1007/s10346-021-01694-6; Codella N, 2019, Arxiv, DOI [arXiv:1902.03368, 10.48550/arXiv.1902.03368]; Diwan T, 2023, MULTIMED TOOLS APPL, V82, P9243, DOI 10.1007/s11042-022-13644-y; Feng J, 2013, METABOLITES, V3, P1011, DOI 10.3390/metabo3041011; Gajera HK, 2022, INT J IMAG SYST TECH, V32, P1774, DOI 10.1002/ima.22729; Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473; Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034; HALL WH, 1992, JAMA-J AM MED ASSOC, V268, P1314, DOI 10.1001/jama.1992.03490100112037; Harrington E, 2017, BMJ OPEN, V7, DOI 10.1136/bmjopen-2016-014096; Hasan MK, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103738; He JJ, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107947; Jiang PY, 2022, PROCEDIA COMPUT SCI, V199, P1066, DOI 10.1016/j.procs.2022.01.135; Kaufman H.L., 2005, The melanoma book: a complete guide to prevention and treatment; Khan MA, 2024, NEURAL COMPUT APPL, V36, P37, DOI 10.1007/s00521-021-06490-w; Koohbanani N.A., 2018, LEVERAGING TRANSFER; Korotkov K, 2012, ARTIF INTELL MED, V56, P69, DOI 10.1016/j.artmed.2012.08.002; Kroemer S, 2011, BRIT J DERMATOL, V164, P973, DOI 10.1111/j.1365-2133.2011.10208.x; Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6; Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556; Massone C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000483; Mayer JE, 2014, J AM ACAD DERMATOL, V71, DOI 10.1016/j.jaad.2014.05.045; Mendonça T, 2013, IEEE ENG MED BIO, P5437; Mobiny A, 2019, J CLIN MED, V8, DOI 10.3390/jcm8081241; Qian C., 2018, SKIN LESION ANAL; Redmon J., 2018, arXiv; Rigel DS, 2010, CA-CANCER J CLIN, V60, P301, DOI 10.3322/caac.20074; Robinson JK, 2006, ARCH DERMATOL, V142, P447, DOI 10.1001/archderm.142.4.447; Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3; Sarker M.K., 2018, P INT C MED IM COMP, VVolume 11071; Shahin AH, 2019, I S BIOMED IMAGING, P451, DOI [10.1109/ISBI.2019.8759172, 10.1109/isbi.2019.8759172]; Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21551, 10.3322/caac.21442]; Singh S.K., 2022, THESIS U ESSEX COLCH; Soudani A, 2019, EXPERT SYST APPL, V118, P400, DOI 10.1016/j.eswa.2018.10.029; Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072; Wang PQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196116; Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964; Yen KK, 1999, FUZZY SET SYST, V106, P167, DOI 10.1016/S0165-0114(97)00269-8; Yuan YD, 2017, Arxiv, DOI arXiv:1703.05165; Zaqout I, 2019, PATTERN RECOGN; Zhao C, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104667	52	9	9	0	4	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	AUG	2023	13	15							8927	10.3390/app13158927	http://dx.doi.org/10.3390/app13158927			20	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	O7BR9		gold, Green Published, Green Accepted			2024-09-18	WOS:001045324000001
J	Al-antari, MA; Han, SM; Kim, TS				Al-antari, Mugahed A.; Han, Seung-Moo; Kim, Tae-Seong			Evaluation of deep learning detection and classification towards computer-aided diagnosis of breast lesions in digital X-ray mammograms	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						Deep learning; Detection; Classification; Evaluation; Breast lesions; Computer-aided diagnosis (CAD)	SEGMENTATION; CANCER; MASSES; SYSTEM	Background and Objective: Deep learning detection and classification from medical imagery are key components for computer-aided diagnosis (CAD) systems to efficiently support physicians leading to an accurate diagnosis of breast lesions. Methods: In this study, an integrated CAD system of deep learning detection and classification is proposed aiming to improve the diagnostic performance of breast lesions. First, a deep learning YOLO detector is adopted and evaluated for breast lesion detection from entire mammograms. Then, three deep learning classifiers, namely regular feedforward CNN, ResNet-50, and InceptionResNet-V2, are modified and evaluated for breast lesion classification. The proposed deep learning system is evaluated over 5 fold cross-validation tests using two different and widely used databases of digital X-ray mammograms: DDSM and INbreast. Results: The evaluation results of breast lesion detection show the capability of the YOLO detector to achieve overall detection accuracies of 99.17% and 97.27% and F1-scores of 99.28% and 98.02% for DDSM and INbreast datasets, respectively. Meanwhile, the YOLO detector could predict 71 frames per second (FPS) at the testing time for both DDSM and INbreast datasets. Using detected breast lesions, the classification models of CNN, ResNet-50, and InceptionResNet-V2 achieve promising average overall accuracies of 94.50%, 95.83%, and 97.50%, respectively, for the DDSM dataset and 88.74%, 92.55%, and 95.32%, respectively, for the INbreast dataset. Conclusion: The capability of the YOLO detector boosted the classification models to achieve a promising breast lesion diagnostic performance. Such prediction results should help to develop a feasible CAD system for practical breast cancer diagnosis. (C) 2020 Elsevier B.V. All rights reserved.	[Al-antari, Mugahed A.; Han, Seung-Moo; Kim, Tae-Seong] Kyung Hee Univ, Coll Elect & Informat, Dept Biomed Engn, 1732 Deogyeong Daero, Yongin 17104, Gyeonggi Do, South Korea; [Al-antari, Mugahed A.] Sanaa Community Coll, Dept Biomed Engn, Sanaa, Yemen	Kyung Hee University	Kim, TS (corresponding author), Kyung Hee Univ, Coll Elect & Informat, Dept Biomed Engn, 1732 Deogyeong Daero, Yongin 17104, Gyeonggi Do, South Korea.	en.mualshz@khu.ac.kr; smhan@khu.ac.kr; tskim@khu.ac.kr	Han, Seungmoo/KIC-1598-2024; Al-antari, Prof. Mugahed A./M-5602-2018	Al-antari, Prof. Mugahed A./0000-0002-4457-4407	National Research Foundation of Korea (NRF) - Korean government (MEST) [NRF2019R1A2C1003713]	National Research Foundation of Korea (NRF) - Korean government (MEST)(Ministry of Education, Science & Technology (MEST), Republic of KoreaNational Research Foundation of KoreaKorean Government)	This work was supported by a National Research Foundation of Korea (NRF) grant funded by the Korean government (MEST) (NRF2019R1A2C1003713).	Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774; Agarwal R, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031409; Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003; Al-antari MA, 2018, J MED BIOL ENG, V38, P443, DOI 10.1007/s40846-017-0321-6; Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027; Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017; Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523; Casti P, 2017, COMPUT METH PROG BIO, V140, P11, DOI 10.1016/j.cmpb.2016.11.010; Celik Y, 2020, PATTERN RECOGN LETT, V133, P232, DOI 10.1016/j.patrec.2020.03.011; Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009; Hagos YB, 2018, LECT NOTES COMPUT SC, V11040, P90, DOI 10.1007/978-3-030-00946-5_10; Hamed Ghada, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P322, DOI 10.1007/978-3-030-44289-7_30; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; HEATH KBM, 2001, MED PHYS, P212; Huang G., 2017, ARXIV160806993V5, P4700, DOI [DOI 10.1109/CVPR.2017.243, 10.1109/CVPR.2017.243]; Jemal A, 2010, CA-CANCER J CLIN, V60, P277, DOI [10.3322/caac.21254, 10.3322/caac.20073]; Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Kozegar E, 2013, J CANCER RES THER, V9, P592, DOI 10.4103/0973-1482.126453; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Qiu YC, 2017, J X-RAY SCI TECHNOL, V25, P751, DOI 10.3233/XST-16226; Raghavendra U, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103041; Rahmati P, 2012, MED IMAGE ANAL, V16, P1167, DOI 10.1016/j.media.2012.05.005; Redmon J., 2016, P IEEE C COMP VIS PA, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/cvpr.2016.91, 10.1109/CVPR.2016.91]; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Sharpless N.E., 2020, NATL CANC I COMPREHE; Simonyan K., 2014, ZISSERMAN VERY DEEP; Szegedy C., 2015, IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI [DOI 10.1109/CVPR.2015.7298594, 10.1109/CVPR.2015.7298594, 10.1109/cvpr.2015.7298594, 10.48550/arXiv.1409.4842]; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Wang D., 2016, Deep learning for identifying metastatic breast cancer; Yassin NIR, 2018, COMPUT METH PROG BIO, V156, P25, DOI 10.1016/j.cmpb.2017.12.012	38	129	130	3	53	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607	1872-7565		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	NOV	2020	196								105584	10.1016/j.cmpb.2020.105584	http://dx.doi.org/10.1016/j.cmpb.2020.105584			15	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Medical Informatics	OE5ZU	32554139				2024-09-18	WOS:000580609200022
J	Prinzi, F; Insalaco, M; Orlando, A; Gaglio, S; Vitabile, S				Prinzi, Francesco; Insalaco, Marco; Orlando, Alessia; Gaglio, Salvatore; Vitabile, Salvatore			A Yolo-Based Model for Breast Cancer Detection in Mammograms	COGNITIVE COMPUTATION			English	Article						Breast cancer detection; Explainable AI; YoloV5; Transfer learning; Proprietary dataset	ARCHITECTURAL DISTORTION; CLASSIFICATION	This work aims to implement an automated data-driven model for breast cancer detection in mammograms to support physicians' decision process within a breast cancer screening or detection program. The public available CBIS-DDSM and the INbreast datasets were used as sources to implement the transfer learning technique on full-field digital mammography proprietary dataset. The proprietary dataset reflects a real heterogeneous case study, consisting of 190 masses, 46 asymmetries, and 71 distortions. Several Yolo architectures were compared, including YoloV3, YoloV5, and YoloV5-Transformer. In addition, Eigen-CAM was implemented for model introspection and outputs explanation by highlighting all the suspicious regions of interest within the mammogram. The small YoloV5 model resulted in the best developed solution obtaining an mAP of 0.621 on proprietary dataset. The saliency maps computed via Eigen-CAM have proven capable solution reporting all regions of interest also on incorrect prediction scenarios. In particular, Eigen-CAM produces a substantial reduction in the incidence of false negatives, although accompanied by an increase in false positives. Despite the presence of hard-to-recognize anomalies such as asymmetries and distortions on the proprietary dataset, the trained model showed encouraging detection capabilities. The combination of Yolo predictions and the generated saliency maps represent two complementary outputs for the reduction of false negatives. Nevertheless, it is imperative to regard these outputs as qualitative tools that invariably necessitate clinical radiologic evaluation. In this view, the model represents a trusted predictive system to support cognitive and decision-making, encouraging its integration into real clinical practice.	[Prinzi, Francesco; Vitabile, Salvatore] Univ Palermo, Dept Biomed Neurosci & Adv Diagnost BiND, Palermo, Italy; [Insalaco, Marco; Orlando, Alessia] Univ Hosp Paolo Giaccone, Dept Biomed Neurosci & Adv Diagnost BiND, Sect Radiol, Palermo, Italy; [Gaglio, Salvatore] Univ Palermo, Dept Engn, Palermo, Italy; [Gaglio, Salvatore] Natl Res Council ICAR CNR, Inst High Performance Comp & Networking, Palermo, Italy	University of Palermo; University of Palermo; Policlinico Paolo Giaccone; University of Palermo; Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR)	Prinzi, F (corresponding author), Univ Palermo, Dept Biomed Neurosci & Adv Diagnost BiND, Palermo, Italy.	francesco.prinzi@unipa.it; marco.insalaco@community.unipa.it; orlandoalessiamed@hotmail.it; salvatore.gaglio@unipa.it; salvatore.vitabile@unipa.it	Vitabile, Salvatore/F-6323-2013; Prinzi, Francesco/HLG-2123-2023	PRINZI, Francesco/0000-0002-8152-3297	Universita degli Studi di Palermo within the CRUI-CARE Agreement; University of Palermo Grant EUROSTART [CUP B79J21038330001]	Universita degli Studi di Palermo within the CRUI-CARE Agreement; University of Palermo Grant EUROSTART	& nbsp;Open access funding provided by Universita degli Studi di Palermo within the CRUI-CARE Agreement. This work was partially supported by the University of Palermo Grant EUROSTART, CUP B79J21038330001, Project TRUSTAI4NCDI.	Abdelrahman L, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104248; 2013, ACR BIRADS ATL BREAS, P37; Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774; Agarwal R, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031409; Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584; Al-Dhabyani W, 2019, INT J ADV COMPUT SC, V10, P618; Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017; AlGhamdi M, 2021, COMPUT METH PROG BIO, V207, DOI 10.1016/j.cmpb.2021.106152; Aly GH, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105823; [Anonymous], 2022, ULTR YOLOV5 ULTR GIT; Arian A, 2022, IRAN J RADIOL, V19, DOI 10.5812/iranjradiol-121155; Babkina Tetiana M, 2021, Wiad Lek, V74, P1674; Baccouche A, 2021, CMC-COMPUT MATER CON, V69, P1407, DOI 10.32604/cmc.2021.018461; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Bodria F., 2021, BENCHMARKING SURVEY; Chattopadhay Aditya, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P839, DOI 10.1109/WACV.2018.00097; Chugh G, 2021, COGN COMPUT, V13, P1451, DOI 10.1007/s12559-020-09813-6; Darma WAS, 2021, 2021 5TH INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS 2021), DOI [10.1109/ICICOS53627.2021.9651855, 10.1109/ICICoS53627.2021.9651855]; Dosovitskiy A., 2021, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.2010.11929; Duffy SW, 2020, CANCER-AM CANCER SOC, V126, P2971, DOI 10.1002/cncr.32859; Durand MA, 2016, RADIOGRAPHICS, V36, P311, DOI 10.1148/rg.2016150093; Ekpo Ernest Usang, 2018, Asian Pac J Cancer Prev, V19, P291, DOI 10.22034/APJCP.2018.19.2.291; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20107, 10.3322/caac.21492, 10.3322/caac.20115]; Joseph RK, 2016, CRIT POL ECON S ASIA, P1; Jung H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203355; Kulesza T., 2015, P 20 INT C INT US IN, P126, DOI [10.1145/2678025.2701399, DOI 10.1145/2678025.2701399]; Kyono T., 2018, ARXIV, DOI [10.48550/arXiv.1811.02661, DOI 10.48550/ARXIV.1811.02661]; Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177; Li WS, 2023, PATTERN RECOGN LETT, V168, P86, DOI 10.1016/j.patrec.2023.03.003; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Lipton Z.C., 2018, Queue, V16, P31, DOI 10.1145/3236386.3241340; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Mahmood T, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0263126; Militello C, 2022, ACAD RADIOL, V29, P830, DOI 10.1016/j.acra.2021.08.024; Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Muduli D, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.102825; Muhammad MB, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206626; Oyelade ON, 2020, IEEE ACCESS, V8, P148644, DOI 10.1109/ACCESS.2020.3016223; Poceviciut e, 2020, Artificial Intelligence and Machine Learning for Digital Pathology: State-of-the-Art and Future Challenges, P56, DOI 10.1007/978-3-030-50402-1_4; Prinzi Francesco, 2022, Applied Intelligence and Informatics: Second International Conference, AII 2022, Proceedings. Communications in Computer and Information Science (1724), P144, DOI 10.1007/978-3-031-24801-6_11; Prinzi F, 2023, APPL ARTIF INTELL, V360, DOI [10.1007/978-981-99-3592-5_7, DOI 10.1007/978-981-99-3592-5_7]; QIU M, 2022, 2022 IEEE APPL IM PA, P1, DOI DOI 10.1109/AIPR57179.2022.10092237; Ragab DA, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104245; Rangayyan RM, 2010, J DIGIT IMAGING, V23, P611, DOI 10.1007/s10278-009-9257-x; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]; Soulami KB, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103696; Tan Qixi, 2022, 2022 5th International Conference on Information Communication and Signal Processing (ICICSP), P218, DOI 10.1109/ICICSP55539.2022.10050627; Torrey L., 2010, HDB RES MACHINE LEAR, P242; Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324; wandb, 2022, WEIGHTS BIASES; Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Wu BXC, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.03677; Yu XC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71431-x; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang J, 2021, MEDRXIV; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhu Huaisheng, 2023, arXiv	64	14	14	11	25	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1866-9956	1866-9964		COGN COMPUT	Cogn. Comput.	JAN	2024	16	1					107	120		10.1007/s12559-023-10189-6	http://dx.doi.org/10.1007/s12559-023-10189-6		AUG 2023	14	Computer Science, Artificial Intelligence; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Neurosciences & Neurology	FB2A4		hybrid			2024-09-18	WOS:001049932200001
J	Lin, TL; Lu, CT; Karmakar, R; Nampalley, K; Mukundan, A; Hsiao, YP; Hsieh, SC; Wang, HC				Lin, Teng-Li; Lu, Chun-Te; Karmakar, Riya; Nampalley, Kalpana; Mukundan, Arvind; Hsiao, Yu-Ping; Hsieh, Shang-Chin; Wang, Hsiang-Chen			Assessing the Efficacy of the Spectrum-Aided Vision Enhancer (SAVE) to Detect Acral Lentiginous Melanoma, Melanoma In Situ, Nodular Melanoma, and Superficial Spreading Melanoma	DIAGNOSTICS			English	Article						skin cancer; acral lentiginous melanoma; melanoma in situ; modular melanoma; superficial spreading melanoma; hyperspectral imaging; band selection; spectrum-aided visual enhancer	NARROW-BAND; DIFFERENTIAL-DIAGNOSIS; CANCER	Skin cancer is the predominant form of cancer worldwide, including 75% of all cancer cases. This study aims to evaluate the effectiveness of the spectrum-aided visual enhancer (SAVE) in detecting skin cancer. This paper presents the development of a novel algorithm for snapshot hyperspectral conversion, capable of converting RGB images into hyperspectral images (HSI). The integration of band selection with HSI has facilitated the identification of a set of narrow band images (NBI) from the RGB images. This study utilizes various iterations of the You Only Look Once (YOLO) machine learning (ML) framework to assess the precision, recall, and mean average precision in the detection of skin cancer. YOLO is commonly preferred in medical diagnostics due to its real-time processing speed and accuracy, which are essential for delivering effective and efficient patient care. The precision, recall, and mean average precision (mAP) of the SAVE images show a notable enhancement in comparison to the RGB images. This work has the potential to greatly enhance the efficiency of skin cancer detection, as well as improve early detection rates and diagnostic accuracy. Consequently, it may lead to a reduction in both morbidity and mortality rates.	[Lin, Teng-Li] Dalin Tzu Chi Gen Hosp, Dept Dermatol, 2,Min-Sheng Rd,Dalin Town, Chiayi 62247, Taiwan; [Lu, Chun-Te] Natl Yang Ming Chiao Tung Univ, Inst Med, Coll Med, Sch Med, Sec 2,Li Nong St, Taipei 112304, Taiwan; [Lu, Chun-Te] Taichung Vet Gen Hosp, Dept Surg, Div Plast & Reconstruct Surg, 1650 Taiwan Blvd Sect 4, Taichung 407219, Taiwan; [Karmakar, Riya; Nampalley, Kalpana; Mukundan, Arvind; Wang, Hsiang-Chen] Natl Chung Cheng Univ, Dept Mech Engn, 168 Univ Rd Min Hsiung, Chiayi 62102, Taiwan; [Hsiao, Yu-Ping] Chung Shan Med Univ Hosp, Dept Dermatol, 110,Sec 1,Jianguo N Rd, Taichung 40201, Taiwan; [Hsiao, Yu-Ping] Chung Shan Med Univ, Inst Med, Sch Med, 110,Sec 1,Jianguo N Rd, Taichung 40201, Taiwan; [Hsieh, Shang-Chin] Kaohsiung Armed Forces Gen Hosp, Dept Surg, Div Gen Surg, 2 Zhongzheng 1st Rd, Kaohsiung 802, Taiwan; [Wang, Hsiang-Chen] Hitspectra Intelligent Technol Co Ltd, Dept Technol Dev, Kaohsiung 80661, Taiwan	Buddhist Tzu Chi General Hospital; National Yang Ming Chiao Tung University; Taichung Veterans General Hospital; National Chung Cheng University; Chung Shan Medical University; Chung Shan Medical University Hospital; Chung Shan Medical University	Wang, HC (corresponding author), Natl Chung Cheng Univ, Dept Mech Engn, 168 Univ Rd Min Hsiung, Chiayi 62102, Taiwan.; Hsieh, SC (corresponding author), Kaohsiung Armed Forces Gen Hosp, Dept Surg, Div Gen Surg, 2 Zhongzheng 1st Rd, Kaohsiung 802, Taiwan.; Wang, HC (corresponding author), Hitspectra Intelligent Technol Co Ltd, Dept Technol Dev, Kaohsiung 80661, Taiwan.	tanglilin1121@hotmail.com; ctlu119@vghtc.gov.tw; karmakarriya345@gmail.com; nampellykalpana91@gmail.com; d09420003@ccu.edu.tw; missyuping@gmail.com; sschin522@gmail.com; hcwang@ccu.edu.tw	Mukundan, Arvind/JXY-1561-2024; Wang, Hsiang-Chen/F-8674-2018	Mukundan, Arvind/0000-0002-7741-3722; Wang, Hsiang-Chen/0000-0003-4107-2062	National Science and Technology Council, the Republic of China [NSTC 112-2221-E-194-036, 112-2222-E-194-002]; Dalin Tzu Chi Hospital, Buddhist Tzu Chi Medical Foundation-National Chung Cheng University Joint Research Program [DTCRD113-C-01]; Kaohsiung Armed Forces General Hospital Research Program in Taiwan [KAFGH_D_113024]	National Science and Technology Council, the Republic of China; Dalin Tzu Chi Hospital, Buddhist Tzu Chi Medical Foundation-National Chung Cheng University Joint Research Program; Kaohsiung Armed Forces General Hospital Research Program in Taiwan	This research was supported by the National Science and Technology Council, the Republic of China under the grants NSTC 112-2221-E-194-036 and 112-2222-E-194-002. This work was financially/partially supported by the Dalin Tzu Chi Hospital, Buddhist Tzu Chi Medical Foundation-National Chung Cheng University Joint Research Program (DTCRD113-C-01) and the Kaohsiung Armed Forces General Hospital Research Program KAFGH_D_113024 in Taiwan.	Agrahari P., 2020, P FUT COMM NETW TECH, P179; Ahmadi Mehr Reza, 2022, J Biomed Phys Eng, V12, P559, DOI 10.31661/jbpe.v0i0.2207-1517; Arisholm E, 2010, J SYST SOFTWARE, V83, P2, DOI 10.1016/j.jss.2009.06.055; Aziz F., 2024, J. Med. Inform. Technol, V2, P11, DOI [10.37034/medinftech.v2i1.30, DOI 10.37034/MEDINFTECH.V2I1.30]; Balch CM, 2009, J CLIN ONCOL, V27, P6199, DOI 10.1200/JCO.2009.23.4799; Basurto-Lozada P, 2021, PIGM CELL MELANOMA R, V34, P59, DOI 10.1111/pcmr.12885; Lipton ZC, 2014, Arxiv, DOI arXiv:1402.1892; Chun-Tse C, 2024, Arxiv, DOI [arXiv:2403.11249, DOI 10.1049/ELL2.13248, 10.1049/ell2.13248]; Corneli P, 2018, EXPERT REV ANTICANC, V18, P1007, DOI 10.1080/14737140.2018.1507822; Dildar M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105479; Du Le VN, 2014, APPL OPTICS, V53, P4061, DOI 10.1364/AO.53.004061; ElMasry G., 2010, HYPERSPECTRAL IMAGIN, P3, DOI DOI 10.1016/B978-0-12-374753-2.10001-2; Ezoe Y, 2011, GASTROENTEROLOGY, V141, P2017, DOI 10.1053/j.gastro.2011.08.007; Ezoe Y, 2010, GASTROINTEST ENDOSC, V71, P477, DOI 10.1016/j.gie.2009.10.036; Fei BW, 2020, DATA HANDL SCI TECHN, V32, P523, DOI 10.1016/B978-0-444-63977-6.00021-3; Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563; Goydos JS, 2016, CANCER TREAT RES, V167, P321, DOI 10.1007/978-3-319-22539-5_14; Gray David, 2011, 15th Annual Conference on Evaluation & Assessment in Software Engineering (EASE 2011), P129, DOI 10.1049/ic.2011.0016; Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13; Higgins HW, 2015, J AM ACAD DERMATOL, V73, P181, DOI 10.1016/j.jaad.2015.04.014; Huang HY, 2023, J CLIN MED, V12, DOI 10.3390/jcm12031134; Hussain M, 2023, MACHINES, V11, DOI 10.3390/machines11070677; Kim DH, 2022, OTOLARYNG HEAD NECK, V166, P795, DOI 10.1177/01945998211029617; Kousis I, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091294; Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117, DOI [DOI 10.1109/CVPR.2017.106, 10.1109/CVPR.2017.106]; Linares MA, 2015, PRIMARY CARE, V42, P645, DOI 10.1016/j.pop.2015.07.006; Liu HY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155817; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu W, 2006, ARCH DERMATOL, V142, P1551, DOI 10.1001/archderm.142.12.1551; Lu B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162659; Mukundan A, 2023, PROC SPIE, V12770, DOI 10.1117/12.2689086; National Cancer Institute Surveillance Epidemiology and End Results (SEER), 2018, Program Cancer Statistics, SEER Data & Software, Registry Operations; Park JS, 2015, GASTROINTEST ENDOSC, V82, P94, DOI 10.1016/j.gie.2014.11.044; Ren J, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.3.033033; Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432; Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644; Simoes MCF, 2015, CANCER LETT, V357, P8, DOI 10.1016/j.canlet.2014.11.001; Tsai CL, 2021, CANCERS, V13, DOI 10.3390/cancers13184593; Tsai TJ, 2022, CANCERS, V14, DOI 10.3390/cancers14174292; van Schaik JE, 2021, ORAL ONCOL, V121, DOI 10.1016/j.oraloncology.2021.105504; Wang CY, 2024, Arxiv, DOI arXiv:2402.13616; Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203; Wang J., 2021, P INT C WIR COMM SMA, P197, DOI 10.1109/ICWCSG53609.2021.00045; Yang KY, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-47833-y; Zheng CJ, 2012, BJU INT, V110, pE680, DOI 10.1111/j.1464-410X.2012.11500.x	45	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4418		DIAGNOSTICS	Diagnostics	AUG	2024	14	15							1672	10.3390/diagnostics14151672	http://dx.doi.org/10.3390/diagnostics14151672			18	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	C1G7P	39125548	Green Published, gold			2024-09-18	WOS:001286922500001
J	Cheng, DC; Hsieh, TC; Yen, KY; Kao, CH				Cheng, Da-Chuan; Hsieh, Te-Chun; Yen, Kuo-Yang; Kao, Chia-Hung			Lesion-Based Bone Metastasis Detection in Chest Bone Scintigraphy Images of Prostate Cancer Patients Using Pre-Train, Negative Mining, and Deep Learning	DIAGNOSTICS			English	Article						bone metastasis detection; classification; YOLO; pre-train; negative mining; transfer learning; deep learning		This study aimed to explore efficient ways to diagnose bone metastasis early using bone scintigraphy images through negative mining, pre-training, the convolutional neural network, and deep learning. We studied 205 prostate cancer patients and 371 breast cancer patients and used bone scintigraphy data from breast cancer patients to pre-train a YOLO v4 with a false-positive reduction strategy. With the pre-trained model, transferred learning was applied to prostate cancer patients to build a model to detect and identify metastasis locations using bone scintigraphy. Ten-fold cross validation was conducted. The mean sensitivity and precision rates for bone metastasis location detection and classification (lesion-based) in the chests of prostate patients were 0.72 +/- 0.04 and 0.90 +/- 0.04, respectively. The mean sensitivity and specificity rates for bone metastasis classification (patient-based) in the chests of prostate patients were 0.94 +/- 0.09 and 0.92 +/- 0.09, respectively. The developed system has the potential to provide pre-diagnostic reports to aid in physicians' final decisions.	[Cheng, Da-Chuan] China Med Univ, Dept Biomed Imaging & Radiol Sci, Taichung 404, Taiwan; [Cheng, Da-Chuan; Hsieh, Te-Chun; Kao, Chia-Hung] China Med Univ Hosp, Ctr Augmented Intelligence Healthcare, Taichung 404, Taiwan; [Hsieh, Te-Chun; Yen, Kuo-Yang; Kao, Chia-Hung] China Med Univ Hosp, Dept Nucl Med & PET Ctr, Taichung 404, Taiwan	China Medical University Taiwan; China Medical University Taiwan; China Medical University Hospital - Taiwan; China Medical University Taiwan; China Medical University Hospital - Taiwan	Cheng, DC (corresponding author), China Med Univ, Dept Biomed Imaging & Radiol Sci, Taichung 404, Taiwan.; Cheng, DC; Kao, CH (corresponding author), China Med Univ Hosp, Ctr Augmented Intelligence Healthcare, Taichung 404, Taiwan.; Kao, CH (corresponding author), China Med Univ Hosp, Dept Nucl Med & PET Ctr, Taichung 404, Taiwan.	dccheng@mail.cmu.edu.tw; D10119@mail.cmuh.org.tw; T10540@mail.cmuh.org.tw; d10040@mail.cmuh.org.tw	; Cheng, Da-Chuan/M-2431-2013	Kao, Chia-Hung/0000-0002-6368-3676; Cheng, Da-Chuan/0000-0001-7955-9234	China Medical University [CMU109-ASIA-02]	China Medical University(China Medical University)	This research was partially funded by China Medical University under grant number CMU109-ASIA-02.	[Anonymous], 2015, Us patent, Patent No. [20,140,105,471, 20140105471]; Apiparakoon T, 2020, IEEE ACCESS, V8, P27047, DOI 10.1109/ACCESS.2020.2971391; Bochkovskiy A., 2020, ARXIV200410934; Bubendorf L, 2000, HUM PATHOL, V31, P578, DOI 10.1053/hp.2000.6698; Cheng DC, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0626-y; Even-Sapir E, 2006, J NUCL MED, V47, P287; Hamaoka T, 2004, J CLIN ONCOL, V22, P2942, DOI 10.1200/jco.2004.08.181; He K., 2017, IEEE I CONF COMP VIS, P2961, DOI DOI 10.1109/ICCV.2017.322; Huang YJ, 2013, SENSORS-BASEL, V13, P4855, DOI 10.3390/s130404855; Hui J., 2018, OBJECT DETECTION SPE; Imbriaco M, 1998, CLIN CANCER RES, V4, P1765; Kao C.H., 2019, P 32 IPPR C COMP VIS; Kolesnikov A., 1912, ARXIV 2020; Papandrianos N, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237213; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Ren S., 2015, IEEE T PATTERN ANAL, DOI [DOI 10.1109/TPAMI.2016.2577031, 10.1109/tpami.2016.2577031]; Sadik M, 2008, J NUCL MED, V49, P1958, DOI 10.2967/jnumed.108.055061; Shimizu A, 2020, INT J COMPUT ASS RAD, V15, P389, DOI 10.1007/s11548-019-02105-x; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; The American Cancer Society Medical and Editorial Content Team, TREAT PROST CANC SPE; Ulmert D, 2012, EUR UROL, V62, P78, DOI 10.1016/j.eururo.2012.01.037; Wuestemann J, 2020, CANCERS, V12, DOI 10.3390/cancers12092654; Zhao Z, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74135-4; Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865	24	27	28	1	20	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4418		DIAGNOSTICS	Diagnostics	MAR	2021	11	3							518	10.3390/diagnostics11030518	http://dx.doi.org/10.3390/diagnostics11030518			14	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	RD6OB	33803921	gold, Green Published			2024-09-18	WOS:000633593600001
J	Baccouche, A; Garcia-Zapirain, B; Olea, CC; Elmaghraby, AS				Baccouche, Asma; Garcia-Zapirain, Begonya; Olea, Cristian Castillo; Elmaghraby, Adel S.			Breast Lesions Detection and Classification via YOLO-Based Fusion Models	CMC-COMPUTERS MATERIALS & CONTINUA			English	Article						Breast cancer; detection; classification; YOLO; deep learning; fusion	AIDED-DIAGNOSIS SYSTEM; DIGITAL MAMMOGRAMS; MASS DETECTION; DEEP; CANCER; SEGMENTATION; RECOGNITION; PREDICTION; NETWORKS	With recent breakthroughs in artificial intelligence, the use of deep learning models achieved remarkable advances in computer vision, ecommerce, cybersecurity, and healthcare. Particularly, numerous applications provided efficient solutions to assist radiologists for medical imaging analysis. For instance, automatic lesion detection and classification in mammograms is still considered a crucial task that requires more accurate diagnosis and precise analysis of abnormal lesions. In this paper, we propose an end-to-end system, which is based on You-Only-Look-Once (YOLO) model, to simultaneously localize and classify suspicious breast lesions from entire mammograms. The proposed system first preprocesses the raw images, then recognizes abnormal regions as breast lesions and determines their pathology classification as either mass or calcification. We evaluated the model on two publicly available datasets, with 2907 mammograms from the Curated Breast Imaging Subset of Digital Database for Screening Mammography (CBIS-DDSM) and 235 mammograms from INbreast database. We also used a privately collected dataset with 487 mammograms. Furthermore, we suggested a fusion models approach to report more precise detection and accurate classification. Our best results reached a detection accuracy rate of 95.7%, 98.1% and 98% for mass lesions and 74.4%, 71.8% and 73.2% for calcification lesions, respectively on CBIS-DDSM, INbreast and the private dataset.	[Baccouche, Asma; Elmaghraby, Adel S.] Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA; [Garcia-Zapirain, Begonya; Olea, Cristian Castillo] Univ Deusto, EVida Res Grp, Bilbao 4800, Spain	University of Louisville; University of Deusto	Baccouche, A (corresponding author), Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.	asma.baccouche@louisville.edu	Elmaghraby, Adel/B-3353-2014; Garcia-Zapirain, Begonya/L-5619-2014	Elmaghraby, Adel/0000-0001-5274-8596; Garcia-Zapirain, Begonya/0000-0002-9356-1186; Baccouche, Asma/0000-0001-6236-8626				Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4; Agarwal R, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031409; Akselrod-Ballin A, 2016, LECT NOTES COMPUT SC, V10008, P197, DOI 10.1007/978-3-319-46976-8_21; Akselrod-Ballin A, 2017, LECT NOTES COMPUT SC, V10553, P321, DOI 10.1007/978-3-319-67558-9_37; Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584; Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003; Al-antari MA, 2018, J MED BIOL ENG, V38, P443, DOI 10.1007/s40846-017-0321-6; Al-masni MA, 2017, IEEE ENG MED BIO, P1230, DOI 10.1109/EMBC.2017.8037053; Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017; Albahli S, 2021, CMC-COMPUT MATER CON, V67, P1333, DOI 10.32604/cmc.2021.014691; Aly GH, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105823; Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453; Arancibia Hernandez P.L., 2016, Rev. Chilena De Radiol, V22, P80, DOI [DOI 10.1016/J.RCHIRA.2016.06.004, 10.1016/j.rchira.2016.06.004]; Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523; Celik Y, 2020, PATTERN RECOGN LETT, V133, P232, DOI 10.1016/j.patrec.2020.03.011; Chakraborty J, 2018, EXPERT SYST APPL, V99, P168, DOI 10.1016/j.eswa.2018.01.010; Cokkinides V., 2020, CANC FACTS FIGURES 2; Couture HD, 2018, NPJ BREAST CANCER, V4, DOI 10.1038/s41523-018-0079-1; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009; Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160; Eltrass AS, 2020, IET IMAGE PROCESS, V14, P495, DOI 10.1049/iet-ipr.2018.5953; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Gao J, 2019, MATH BIOSCI ENG, V16, P6536, DOI 10.3934/mbe.2019326; Gardezi SJS, 2019, J MED INTERNET RES, V21, DOI 10.2196/14464; He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824; Kallenberg M, 2010, LECT NOTES COMPUT SC, V6136, P191, DOI 10.1007/978-3-642-13666-5_26; Khosla A., 2016, ABS160605718 ARXIV; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Kozegar E, 2013, J CANCER RES THER, V9, P592, DOI 10.4103/0973-1482.126453; Kriti, 2016, INTEL SYST REF LIBR, V96, P159, DOI 10.1007/978-3-319-21212-8_7; Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855; Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177; Li HX, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0332-0; Li WY, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1808, DOI 10.1109/SSCI47803.2020.9308604; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Mehmood M, 2021, CMC-COMPUT MATER CON, V67, P641, DOI 10.32604/cmc.2021.013774; Mohebian MR, 2017, COMPUT STRUCT BIOTEC, V15, P75, DOI 10.1016/j.csbj.2016.11.004; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Nguyen D. T., 2019, ABS191001842 ARXIV; Peng JC, 2020, MED BIOL ENG COMPUT, V58, P1405, DOI 10.1007/s11517-020-02170-4; Pushpa TR, 2012, MALAYS J MED SCI, V19, P52; Qian HF, 2020, CMC-COMPUT MATER CON, V65, P2153, DOI 10.32604/cmc.2020.011843; Qiu YC, 2017, J X-RAY SCI TECHNOL, V25, P751, DOI 10.3233/XST-16226; Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201; Ramachandran SS, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293699; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Samala RK, 2016, MED PHYS, V43, P6654, DOI 10.1118/1.4967345; Samuelson F, 2016, INT J BIOSTAT, V12, DOI 10.1515/ijb-2016-0017; Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4; Shen RB, 2020, NEUROCOMPUTING, V393, P27, DOI 10.1016/j.neucom.2020.01.099; Siddiqui SY, 2021, CMC-COMPUT MATER CON, V67, P1033, DOI 10.32604/cmc.2021.013952; Sierra-Sosa D, 2021, CMC-COMPUT MATER CON, V67, P1849, DOI 10.32604/cmc.2021.013196; Sierra-Sosa D, 2021, CMC-COMPUT MATER CON, V67, P1629, DOI 10.32604/cmc.2021.013618; Sun Ke, 2019, arXiv:1904.04514; Suzuki S, 2016, 2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1382, DOI 10.1109/SICE.2016.7749265; van Zelst JCM, 2017, EUR J RADIOL, V89, P54, DOI 10.1016/j.ejrad.2017.01.021; Vorontsov E, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180014; Wang DR, 2022, IEEE T CYBERNETICS, V52, P7427, DOI 10.1109/TCYB.2020.3041481; Wang Y, 2011, PATTERN RECOGN, V44, P1903, DOI 10.1016/j.patcog.2010.08.002; Wang ZQ, 2019, IEEE ACCESS, V7, P105146, DOI 10.1109/ACCESS.2019.2892795; Xi P., 2018, Proceedings IEEE International Symposium on Medical Measurements and Applications, P1; Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381; Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873; Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839; Zhou TX, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100004; Zou Z., 2019, ABS1905050 ARXIV	70	27	29	6	52	TECH SCIENCE PRESS	HENDERSON	871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA	1546-2218	1546-2226		CMC-COMPUT MATER CON	CMC-Comput. Mat. Contin.		2021	69	1					1407	1425		10.32604/cmc.2021.018461	http://dx.doi.org/10.32604/cmc.2021.018461			19	Computer Science, Information Systems; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Materials Science	SO5YN		gold			2024-09-18	WOS:000659047600030
J	Ünver, HM; Ayan, E				Unver, Halil Murat; Ayan, Enes			Skin Lesion Segmentation in Dermoscopic Images with Combination of YOLO and GrabCut Algorithm	DIAGNOSTICS			English	Article						skin cancer; skin lesion segmentation; melanoma; convolutional neural networks; Yolo; GrabCut	CONVOLUTIONAL NEURAL-NETWORKS; BORDER DETECTION; MELANOMA; DIAGNOSIS	Skin lesion segmentation has a critical role in the early and accurate diagnosis of skin cancer by computerized systems. However, automatic segmentation of skin lesions in dermoscopic images is a challenging task owing to difficulties including artifacts (hairs, gel bubbles, ruler markers), indistinct boundaries, low contrast and varying sizes and shapes of the lesion images. This paper proposes a novel and effective pipeline for skin lesion segmentation in dermoscopic images combining a deep convolutional neural network named as You Only Look Once (YOLO) and the GrabCut algorithm. This method performs lesion segmentation using a dermoscopic image in four steps: 1. Removal of hairs on the lesion, 2. Detection of the lesion location, 3. Segmentation of the lesion area from the background, 4. Post-processing with morphological operators. The method was evaluated on two publicly well-known datasets, that is the PH2 and the ISBI 2017 (Skin Lesion Analysis Towards Melanoma Detection Challenge Dataset). The proposed pipeline model has achieved a 90% sensitivity rate on the ISBI 2017 dataset, outperforming other deep learning-based methods. The method also obtained close results according to the results obtained from other methods in the literature in terms of metrics of accuracy, specificity, Dice coefficient, and Jaccard index.	[Unver, Halil Murat; Ayan, Enes] Kirikkale Univ, Dept Comp Engn, TR-71451 Kirikkale, Turkey	Kirikkale University	Ayan, E (corresponding author), Kirikkale Univ, Dept Comp Engn, TR-71451 Kirikkale, Turkey.	enesayan@kku.edu.tr	Ayan, Enes/ISA-5710-2023		Research Fund (Scientific Research Projects Coordination Unit) of the Kirikkale University [2018/40]	Research Fund (Scientific Research Projects Coordination Unit) of the Kirikkale University	This paper was supported by Research Fund (Scientific Research Projects Coordination Unit) of the Kirikkale University. Project Number: 2018/40.	Abbas Q, 2012, SKIN RES TECHNOL, V18, P133, DOI 10.1111/j.1600-0846.2011.00544.x; Abbas Q, 2011, SKIN RES TECHNOL, V17, P91, DOI 10.1111/j.1600-0846.2010.00472.x; Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027; Ali ARA, 2012, PROC SPIE, V8318, DOI 10.1117/12.912389; [Anonymous], P 2018 IEEE ACIS 17; [Anonymous], P 17 INT C ICPR PATT; [Anonymous], ARXIV151100561; [Anonymous], 2017, SKIN LES AN MEL DET; [Anonymous], 2014 IEEE C COMP VIS; [Anonymous], P INT C MED IM COMP; [Anonymous], ARXIV171110449; [Anonymous], ARXIV170305165; [Anonymous], 2017, P 2017 IEEE S SER CO; [Anonymous], BMC BIOINFORMATICS; Ashour AS, 2018, SIGNAL IMAGE VIDEO P, V12, P1311, DOI 10.1007/s11760-018-1284-y; Bi L., ARXIV170304197; Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771; Burdick J, 2018, J DIGIT IMAGING, V31, P435, DOI 10.1007/s10278-017-0026-y; Celebi M. E., 2015, DERMOSCOPY IMAGE ANA, P97, DOI DOI 10.1201/B19107; Celebi ME, 2008, SKIN RES TECHNOL, V14, P347, DOI 10.1111/j.1600-0846.2008.00301.x; Celebi ME, 2013, SKIN RES TECHNOL, V19, pE252, DOI 10.1111/j.1600-0846.2012.00636.x; Celebi ME, 2009, COMPUT MED IMAG GRAP, V33, P148, DOI 10.1016/j.compmedimag.2008.11.002; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Codella N.C.F., 2018, P 2018 IEEE 15 INT S; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Erkol B, 2005, SKIN RES TECHNOL, V11, P17, DOI 10.1111/j.1600-0846.2005.00092.x; Feng J, 2013, METABOLITES, V3, P1011, DOI 10.3390/metabo3041011; Filho M, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0354-8; Gandhi SA, 2015, MED CLIN N AM, V99, P1323, DOI 10.1016/j.mcna.2015.06.002; Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473; Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jemal A, 2010, CA-CANCER J CLIN, V60, P277, DOI [10.3322/caac.21254, 10.3322/caac.20073]; Joseph RK, 2016, CRIT POL ECON S ASIA, P1; Karimkhani C, 2017, BRIT J DERMATOL, V177, P134, DOI 10.1111/bjd.15510; Kockara S, 2010, BIOINFORMATICS, V26, pi21, DOI 10.1093/bioinformatics/btq178; Korotkov K, 2012, ARTIF INTELL MED, V56, P69, DOI 10.1016/j.artmed.2012.08.002; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6; Li H, 2019, IEEE J BIOMED HEALTH, V23, P527, DOI 10.1109/JBHI.2018.2859898; Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Long YJ, 2015, INTERNATIONAL CONFERENCE ON NEW ENERGY AND RENEWABLE RESOURCES (ICNERR 2015), P7; Mendonca T., 2013, P 2013 35 ANN INT C; Mollersen K, 2010, SKIN RES TECHNOL, V16, P401, DOI 10.1111/j.1600-0846.2010.00455.x; Okur E, 2018, ENG APPL ARTIF INTEL, V73, P50, DOI 10.1016/j.engappai.2018.04.028; Oliveira RB, 2016, COMPUT METH PROG BIO, V131, P127, DOI 10.1016/j.cmpb.2016.03.032; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pathan S, 2018, BIOMED SIGNAL PROCES, V39, P237, DOI 10.1016/j.bspc.2017.07.010; Pellacani G, 2002, CLIN DERMATOL, V20, P222, DOI 10.1016/S0738-081X(02)00231-6; Peng YJ, 2019, MULTIMED TOOLS APPL, V78, P10965, DOI 10.1007/s11042-018-6523-2; Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465; Peruch F, 2014, IEEE T BIO-MED ENG, V61, P557, DOI 10.1109/TBME.2013.2283803; Powers D. M. W., 2011, J MACH LEARN TECHNOL, V2, P37; Redmon J., Darknet: Open-Source Neural Networks in C 2013-2016; Redmon J., 2017, CVPR 2017, DOI DOI 10.1142/9789812771728_0012; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rodriguez -Ruiz A, 2018, P SPIE, V0718, DOI 1117/12.2317937; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schaefer G, 2014, MEMET COMPUT, V6, P233, DOI 10.1007/s12293-014-0144-8; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Silveira M, 2009, IEEE J-STSP, V3, P35, DOI 10.1109/JSTSP.2008.2011119; Sinz C, 2017, J AM ACAD DERMATOL, V77, P1100, DOI 10.1016/j.jaad.2017.07.022; Suer S, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-S10-S12; Szegedy C., 2015, IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI [DOI 10.1109/CVPR.2015.7298594, 10.1109/CVPR.2015.7298594, 10.1109/cvpr.2015.7298594, 10.48550/arXiv.1409.4842]; Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177; Wang HZ, 2011, COMPUT MED IMAG GRAP, V35, P116, DOI 10.1016/j.compmedimag.2010.09.006; Xie FY, 2013, PATTERN RECOGN, V46, P1012, DOI 10.1016/j.patcog.2012.08.012; Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166; Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487; Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227; Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300; Zhou HY, 2009, IEEE J-STSP, V3, P26, DOI 10.1109/JSTSP.2008.2010631	77	155	159	2	40	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4418		DIAGNOSTICS	Diagnostics	SEP	2019	9	3							72	10.3390/diagnostics9030072	http://dx.doi.org/10.3390/diagnostics9030072			21	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	JA6WS	31295856	Green Published, Green Submitted, gold			2024-09-18	WOS:000487983100027
J	Hamed, G; Marey, M; Amin, SE; Tolba, MF				Hamed, Ghada; Marey, Mohammed; Amin, Safaa Elsayed; Tolba, Mohamed F.			Automated Breast Cancer Detection and Classification in Full Field Digital Mammograms Using Two Full and Cropped Detection Paths Approach	IEEE ACCESS			English	Article						Mammography; Breast cancer; Lesions; Cancer; Solid modeling; Feature extraction; Tumors; Breast cancer; breast mammograms; breast masses classification; lesions detection; You Only Look Once	COMPUTER-AIDED DETECTION; DIAGNOSIS; RADIOLOGISTS; MASSES; SYSTEM	Breast cancer is one of the most severe diseases that threaten women's life results in increasing the death rate annually as confirmed by the World Health Organization. Breast cancer early detection is one of the main reasons behind reducing cancer severity. However, with the huge number of mammograms taken daily, the checking process conducted by radiologists becomes lengthy, tiring, and pruning to errors process. Hence, with the tremendous success achieved by utilizing CNNs in bioinformatics, the development of Computer-Aided Detection (CAD) systems has proved its necessity to solve the challenging cases for the biopsies missed by the ordinary checking leads to decreasing the false positive and negative rates. In this paper, we present a YOLOV4 based CAD system to localize lesions in full and cropped mammograms and then classify them to obtain their pathology type. The proposed method mainly consists of three phases that are applied on the full-field digital mammograms of the INbreast dataset. First, the mammograms are preprocessed to remove any extra artifacts and then cropped into small, overlapped slices. Second, masses are localized through two paths: the full mammograms and the cropped slices detection after configuring the YOLO-V4 model. Third, other feature extractors like ResNet, VGG, Inception, etc. are used to classify the localized lesions to compare their performance against YOLO. The proposed method proved using the experimental results the impact of utilizing YOLO-V4 as a detector with the 2-paths of detection of a full mammogram and the cropped slices in a trial to avoid any data loss by resizing the large-sized mammograms. Our system succeeds in detecting the masses' location with an overall accuracy of approximate to 98% which is more than the recently introduced breast cancer detection methods. Moreover, its ability to distinguish between benign and malignant tumors with an accuracy of approximate to 95%.	[Hamed, Ghada; Marey, Mohammed; Amin, Safaa Elsayed; Tolba, Mohamed F.] Ain Shams Univ, Fac Comp & Informat Sci, Dept Sci Comp, Cairo 11566, Egypt	Egyptian Knowledge Bank (EKB); Ain Shams University	Hamed, G (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Dept Sci Comp, Cairo 11566, Egypt.	ghadahamed@cis.asu.edu.eg	Hamed, Ghada/C-5117-2017					Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774; Al Husaini MAS, 2020, IEEE ACCESS, V8, P208922, DOI 10.1109/ACCESS.2020.3038817; Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584; Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003; Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017; Aly GH, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105823; [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]; [Anonymous], INBREAST DATASET; Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014; Bargalló X, 2014, EUR J RADIOL, V83, P2019, DOI 10.1016/j.ejrad.2014.08.010; Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED; Chan H.-P., 1990, INVEST RADIOL, V1001, P48109; Chanda Pramit Brata, 2020, Advances in Control, Signal Processing and Energy Systems. Select Proceedings of CSPES 2018. Lecture Notes in Electrical Engineering (LNEE 591), P107, DOI 10.1007/978-981-32-9346-5_9; Chaurasia V, 2018, J ALGORITHMS COMPUT, V12, P119, DOI 10.1177/1748301818756225; Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009; Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002; Ekpo Ernest Usang, 2018, Asian Pac J Cancer Prev, V19, P291, DOI 10.22034/APJCP.2018.19.2.291; Evans KK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064366; Fatima N, 2020, IEEE ACCESS, V8, P150360, DOI 10.1109/ACCESS.2020.3016715; Hamed G, 2021, Int J Intell Comput Inf Sci, V21, P33, DOI [10.21608/ijicis.2021.56425.1050, DOI 10.21608/IJICIS.2021.56425.1050]; Hamed G., 2020, INT C ARTIFICIAL INT, P322; Hamed G., 2020, P INT C ADV INTELLIG, P324; Henriksen EL, 2019, ACTA RADIOL, V60, P13, DOI 10.1177/0284185118770917; Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516; Jiang F, 2017, P 5 INT C BIOINF COM, P59; Jiang YL, 1999, ACAD RADIOL, V6, P22, DOI 10.1016/S1076-6332(99)80058-0; Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060; Jung H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203355; Lotter W, 2017, LECT NOTES COMPUT SC, V10553, P169, DOI 10.1007/978-3-319-67558-9_20; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014; Onega T, 2010, ACAD RADIOL, V17, P1217, DOI 10.1016/j.acra.2010.05.007; Rao VM, 2010, J AM COLL RADIOL, V7, P802, DOI 10.1016/j.jacr.2010.05.019; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Rodriguez-Ruiz A, 2019, JNCI-J NATL CANCER I, V111, P916, DOI 10.1093/jnci/djy222; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Romero C, 2011, AM J ROENTGENOL, V197, P1492, DOI 10.2214/AJR.09.3408; Roslidar R, 2020, IEEE ACCESS, V8, P116176, DOI 10.1109/ACCESS.2020.3004056; Sato M, 2014, BREAST CANCER-TOKYO, V21, P532, DOI 10.1007/s12282-012-0423-5; Singh S, 2005, IEEE T INF TECHNOL B, V9, P109, DOI 10.1109/TITB.2004.837851; Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514; Yassin NIR, 2018, COMPUT METH PROG BIO, V156, P25, DOI 10.1016/j.cmpb.2017.12.012	42	13	14	1	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2021	9						116898	116913		10.1109/ACCESS.2021.3105924	http://dx.doi.org/10.1109/ACCESS.2021.3105924			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	UI2DG		gold			2024-09-18	WOS:000690424100001
J	Haq, I; Mazhar, T; Asif, RN; Ghadi, YY; Ullah, N; Khan, MA; Al-Rasheed, A				Haq, Inayatul; Mazhar, Tehseen; Asif, Rizwana Naz; Ghadi, Yazeed Yasin; Ullah, Najib; Khan, Muhammad Amir; Al-Rasheed, Amal			YOLO and residual network for colorectal cancer cell detection and counting	HELIYON			English	Article						Biomedical image processing; Computer-aided diagnosis; Medical image analysis; Machine learning; Deep learning; HT-29 cells; Colon cancer	COLON-CANCER	The HT-29 cell line, derived from human colon cancer, is valuable for biological and cancer research applications. Early detection is crucial for improving the chances of survival, and researchers are introducing new techniques for accurate cancer diagnosis. This study introduces an efficient deep learning-based method for detecting and counting colorectal cancer cells (HT-29). The colorectal cancer cell line was procured from a company. Further, the cancer cells were cultured, and a transwell experiment was conducted in the lab to collect the dataset of colorectal cancer cell images via fluorescence microscopy. Of the 566 images, 80 % were allocated to the training set, and the remaining 20 % were assigned to the testing set. The HT-29 cell detection and counting in medical images is performed by integrating YOLOv2, ResNet-50, and ResNet-18 architectures. The accuracy achieved by ResNet-18 is 98.70 % and ResNet-50 is 96.66 %. The study achieves its primary objective by focusing on detecting and quantifying congested and overlapping colorectal cancer cells within the images. This innovative work constitutes a significant development in overlapping cancer cell detection and counting, paving the way for novel advancements and opening new avenues for research and clinical applications. Researchers can extend the study by exploring variations in ResNet and YOLO architectures to optimize object detection performance. Further investigation into real-time deployment strategies will enhance the practical applicability of these models.	[Haq, Inayatul] Zhengzhou Univ, Sch Elect & Informat Engn, Zhengzhou 450001, Peoples R China; [Mazhar, Tehseen] Virtual Univ Pakistan, Dept Comp Sci, Lahore 55150, Pakistan; [Asif, Rizwana Naz] Natl Coll Business Adm & Econ, Sch Comp Sci, Lahore 54000, Pakistan; [Ghadi, Yazeed Yasin] Al Ain Univ, Dept Software Engn & Comp Sci, Abu Dhabi 12555, U Arab Emirates; [Ullah, Najib] Univ Balochistan, Fac Pharm & Hlth Sci, Dept Pharm, Quetta 08770, Pakistan; [Khan, Muhammad Amir] Univ Teknol MARA, Coll Comp Informat & Math, Sch Comp Sci, Shah Alam 40450, Selangor, Malaysia; [Al-Rasheed, Amal] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Syst, POB 84428, Riyadh 11671, Saudi Arabia	Zhengzhou University; Virtual University of Pakistan; University of Balochistan; Universiti Teknologi MARA; Princess Nourah bint Abdulrahman University	Khan, MA (corresponding author), Univ Teknol MARA, Coll Comp Informat & Math, Sch Comp Sci, Shah Alam 40450, Selangor, Malaysia.	Inayatulhaq1@gmail.com; tehseenmazhar719@gmail.com; rizwana@ncbae.edu.pk; ghadi@aau.ac.ae; najibullah9@yahoo.com; amirkhan@uitm.edu.my; aaalrasheed@pnu.edu.sa	Mazhar, TEHSEEN/JED-4787-2023; Haq, Inayatul/HNB-5810-2023; Khan, Muhammad Amir/JEZ-6363-2023	Ghadi, Yazeed Yasin/0000-0002-7121-495X; Khan, Muhammad Amir/0000-0003-3669-2080; MAZHAR, TEHSEEN/0000-0002-4649-2376	Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia [PNURSP2024R235]	Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia(Princess Nourah bint Abdulrahman University)	Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2024R235) , Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia.	Abu Al-Haija Q, 2020, 2020 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS 2020), P96, DOI 10.1109/iemtronics51293.2020.9216455; Ahmed M, 2020, GASTROENTEROL RES, V13, P1, DOI 10.14740/gr1239; Aishwarya N., 2023, Procedia Computer Science, P651, DOI 10.1016/j.procs.2023.03.083; Al-Haija Q.A., 2020, American Journal of Science & Engineering, V1, P30; Alam S., 2022, A Comparative Study of Object Detection Models for Real Time Application in Surveillance Systems; Alkadi R, 2019, J DIGIT IMAGING, V32, P793, DOI 10.1007/s10278-018-0160-1; Ayyachamy S., 2019, SPIE; Babu T, 2021, J INTELL FUZZY SYST, V41, P5275, DOI 10.3233/JIFS-189850; Basu S., 2021, Colon cancer; Ben Hamida A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104730; Bie NN, 2020, INT J BIOL MACROMOL, V147, P79, DOI 10.1016/j.ijbiomac.2020.01.062; Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404; Bodavarapu P.N.R., 2021, SMART TECHNOLOGIES D; Borre M, 2022, ACTA ONCOL, V61, P1192, DOI 10.1080/0284186X.2022.2101901; Budhiman A., 2019, 2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI); Buenrostro-Mariscal R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12126262; Buikhuisen JY, 2020, ONCOGENESIS, V9, DOI 10.1038/s41389-020-00250-6; Center M.S.K.C, 2023, HT-29: human colorectal adenocarcinoma cell line (ATCC HTB-38); Chen B, 2016, ONCOTARGET, V7, P71400, DOI 10.18632/oncotarget.12147; Chen YL, 2022, FRONT PHARMACOL, V13, DOI 10.3389/fphar.2022.952587; Crosby D, 2022, SCIENCE, V375, P1244, DOI 10.1126/science.aay9040; Das A., 2021, 2021 12 INT C COMPUT; Du ZQ, 2022, LAB CHIP, V22, P3390, DOI 10.1039/d2lc00190j; El-Feshawy SA, 2023, J SUPERCOMPUT, V79, P1081, DOI 10.1007/s11227-022-04678-y; Gai RL, 2023, NEURAL COMPUT APPL, V35, P13895, DOI 10.1007/s00521-021-06029-z; Godkhindi A.M., 2017, 2017 INT C ENERGY CO; Guerrero-Ibañez J, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4169; Guo YX, 2020, J FUNCT FOODS, V75, DOI 10.1016/j.jff.2020.104290; Haq I., 2022, Symmetry, V14; Haq I, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122412614; Haq I, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115744; Haq M.T., 2023, PeerJ Computer Science, V9; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hussain M, 2023, MACHINES, V11, DOI 10.3390/machines11070677; Idrees H., 2018, Google Patents; Ilyas N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010043; Ji ZL, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11102344; Jin XW, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133770; Kakarwal S., 2022, System research and information technologies, P104; Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730; Khodavirdipour A, 2021, J GASTROINTEST CANC, V52, P575, DOI 10.1007/s12029-020-00439-3; Kumar P., 2021, Annals of the Romanian Society for Cell Biology, P2258; Li F, 2022, INT J BIOL MACROMOL, V209, P552, DOI 10.1016/j.ijbiomac.2022.04.023; Li Y., 2021, Int. J. Cogn. Comput. Eng., V2, P21; Liu K, 2023, CANCERS, V15, DOI 10.3390/cancers15112974; Masud M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030748; Medico E, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8002; Mehra A., 2021, EMERGING TECHNOLOGIE, V2, P55; Montanari F, 2020, IEEE INT VEH SYM, P590, DOI 10.1109/IV47402.2020.9304560; Mukherjee S., 2022, Explaining how ResNet-50 works and why it is so popular; Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38; Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003; Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17; Sahaai M.B., 2022, AIP C P; Salman ME, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117148; Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429; Sarwinda D, 2021, PROCEDIA COMPUT SCI, V179, P423, DOI 10.1016/j.procs.2021.01.025; Selcuk B., 2023, 2023 8 INT C COMPUTE; Shadab S.A., 2022, Computational Intelligence in Healthcare Applications, P237; Shathviha Palaniappan Chithambara, 2021, Avicenna Journal of Medical Biotechnology, V13, P42, DOI 10.18502/ajmb.v13i1.4577; Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Society, 2023, AC colorectal cancer; Tahir H., 2021, 2021 INT C COMPUTING; Tan MX, 2019, PR MACH LEARN RES, V97; Vasu K, 2022, J PHARM NEGAT RESULT, V13, P1413, DOI 10.47750/pnr.2022.13.S04.169; Xi Y, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101174; Yang S.D., 2021, P IEEECVF WINTER C A; Yin YH, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102756; Yu X, 2021, IEEE ACM T COMPUT BI, V18, P94, DOI 10.1109/TCBB.2020.2986544; Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146; Zeng Y., 2020, Optical Coherence Tomography; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70	73	1	1	7	8	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA		2405-8440		HELIYON	Heliyon	JAN 30	2024	10	2							e24403	10.1016/j.heliyon.2024.e24403	http://dx.doi.org/10.1016/j.heliyon.2024.e24403		JAN 2024	21	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	IY4Z9	38304780	Green Published, gold			2024-09-18	WOS:001169901400001
C	Mei, S; Jiang, HQ; Ma, L		Li, Q; Wang, L; Wang, Y; Li, W		Mei, Sen; Jiang, HuiQin; Ma, Ling			YOLO-lung: A Practical Detector Based on Imporved YOLOv4 for Pulmonary Nodule Detection	2021 14TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2021)			English	Proceedings Paper	14th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)	OCT 23-25, 2021	Shanghai, PEOPLES R CHINA	IEEE, IEEE Engn Med & Biol Soc, E China Normal Univ, MI, NAIS, Fudan Univ, SVS		Deep learning; Pulmonary nodule detection; Network slimming		Automatic pulmonary nodule detection based on CT images plays a key role in the screening of lung cancer. In recent years, deep learning techniques have a significant progress in this field. However, there is often a huge volume of medical data but a limited hardware in most hospitals. It is often necessary to sacrifice accuracy to ensure the infer speed of the detector in practical applications. Therefore, it is meaningful to comprehensively consider the balance between the effectiveness and efficiency of the detector. The aim of this paper is to implement a pulmonary nodule detector with a relative balance of effectiveness and efficiency that can be applied directly in the hospital field, rather than to propose a new model. Our work is completed in two stages. Firstly, we mainly attempts to improve the accuracy of the model by combining various existing techniques: the depthwise over-parameterized convolution layer, the convolutional block attention module and focal loss function. Finally, we perform redundant channel pruning on the designed model to obtain a more efficient pulmonary nodule detector, named YOLO-lung. By combining multiple tricks, extensive experimental results on the LIDC-IDRI dataset show that YOLO-lung can achieve better balance between effectiveness (90.5% AP) and efficiency (25 FPS). Compared with several state-of-the-art detection methods, YOLO-lung has better detection performance. The method presented in this paper is of reference significance for the design of the practical pulmonary nodule detection model.	[Mei, Sen; Jiang, HuiQin; Ma, Ling] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China	Zhengzhou University	Mei, S (corresponding author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.		jiang, hui/KYP-5273-2024		key project of Nature Science Foundation of China [U1604262]; Zhengzhou collaborative innovation major special project [20XTZX11020]	key project of Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Zhengzhou collaborative innovation major special project	This research is supported by the key project of Nature Science Foundation of China (U1604262) and Zhengzhou collaborative innovation major special project (20XTZX11020).	Aberle DR, 2011, NEW ENGL J MED, V365, P395, DOI 10.1056/NEJMoa1102873; Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1; Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999; Bochkovskiy A., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2004.10934; Cao J., 2020, ARXIV200511475; Changpinyo S., 2017, The Power of Sparsity in Convolutional Neural Networks; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0; Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667; Everingham M., 2010, INT J COMPUT VISION, V88, P303, DOI DOI 10.1007/s11263-009-0275-4; Firmino M, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-015-0120-7; Han S., 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; Henschke CI, 1999, LANCET, V354, P99, DOI 10.1016/S0140-6736(99)06093-6; Ioffe S., 2015, P INT C MACH LEARN L, DOI [10.48550/arXiv.1502.03167, DOI 10.48550/ARXIV.1502.03167]; Jia Ding, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P559, DOI 10.1007/978-3-319-66179-7_64; Joseph RK, 2016, CRIT POL ECON S ASIA, P1; Ker J, 2019, J CLIN NEUROSCI, V66, P239, DOI 10.1016/j.jocn.2019.05.019; Ker J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092167; Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Naqi SM, 2018, INT J COMPUT ASS RAD, V13, P1083, DOI 10.1007/s11548-018-1715-9; Ramesh KKD., 2021, EAI Endorsed Transactions on Pervasive Health and Technology; Redmon J., 2018, YOLOv3: Increm. Improv., P6848; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Singh M, 2020, IEEE SENSOR, DOI 10.1109/sensors47125.2020.9278585; Singh SP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185097; Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660; Tan M., 2020, P IEEE CVF C COMP VI, P10778, DOI DOI 10.48550/ARXIV.1911.09070; Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324; [王璐 Wang Lu], 2019, [中国实用内科杂志, Chinese Journal of Practical Internal Medicine], V39, P440; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]; Zhao B., MED PHYS, V38, P915; Zhou TX, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100004; Zhu WT, 2018, IEEE WINT CONF APPL, P673, DOI 10.1109/WACV.2018.00079	36	6	6	2	18	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-6654-0004-6				2021										10.1109/CISP-BMEI53629.2021.9624373	http://dx.doi.org/10.1109/CISP-BMEI53629.2021.9624373			6	Engineering, Biomedical; Medical Informatics; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Engineering; Medical Informatics; Imaging Science & Photographic Technology	BT0MJ					2024-09-18	WOS:000789442100080
J	Maria, HH; Jossy, AM; Malarvizhi, S				Maria, H. Heartlin; Jossy, A. Maria; Malarvizhi, S.			A hybrid deep learning approach for detection and segmentation of ovarian tumours	NEURAL COMPUTING & APPLICATIONS			English	Article						Ovarian tumours; YOLO; U-Net; Deep learning; CAD	U-NET; IMAGES	In recent days, artificial intelligence (AI) is gaining worldwide popularity in several industries among which healthcare is an important sector. AI is being used in healthcare to reduce human errors and save time thereby aiding in accurate disease diagnosis. In healthcare, AI relies on analysing and interpreting thousands of datasets. This work is one such healthcare application involving a hybrid deep learning approach to detect and segment cancerous ovarian tumours. Doctors and radiologists have revealed that it is highly challenging to detect ovarian cancer. This is because identifying whether the tumour is cancerous or not using medical imaging modalities is a tedious task. Intending to eliminate this stereotype, the proposed model incorporates the efficiency of the YOLO v5 detection model and the accuracy of the attention U-Net segmentation model to pin down cancerous ovarian tumours in computed tomography images. The performance of this model is verified using clinical data and its performance metrics have been analysed. Simulation results have shown that the proposed model works efficiently on ovarian tumours in terms of accuracy and dice scores. The YOLO v5 model has located the ovarian tumours with an accuracy of 98%, and the attention U-Net has segmented the detected ovarian tumours with an accuracy of 99.2%. This computer-aided diagnosis system can be used to aid radiologists in the diagnosis of ovarian cancer.	[Maria, H. Heartlin; Jossy, A. Maria; Malarvizhi, S.] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur, Chennai, India	SRM Institute of Science & Technology Chennai	Maria, HH (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur, Chennai, India.	hm8472@srmist.edu.in	Jossy, Maria/AAE-9901-2021					Aboussaleh I, 2021, J IMAGING, V7, DOI 10.3390/jimaging7120269; Acharya UR, 2018, INT J FUZZY SYST, V20, P1385, DOI 10.1007/s40815-018-0456-9; Ahmed L, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01680-1; Amer A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073676; Beer L, 2020, EUR RADIOL, V30, P4306, DOI 10.1007/s00330-020-06755-3; Deng W, 2020, IEEE ACCESS, V8, P26665, DOI 10.1109/ACCESS.2020.2966879; Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013; drugwise, US; Guo LY, 2020, BIODATA MIN, V13, DOI 10.1186/s13040-020-00222-x; Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015; Hoffmann S, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-172; Jung SE, 2002, RADIOGRAPHICS, V22, P1305, DOI 10.1148/rg.226025033; Lei T, 2022, IEEE T RADIAT PLASMA, V6, P68, DOI 10.1109/TRPMS.2021.3059780; Lemay A, 2019, ARXIV; Li MY, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-021-00694-1; Liu ZC, 2022, IEEE T POWER ELECTR, V37, P8767, DOI 10.1109/TPEL.2022.3153797; Long JS, 2020, MULTIMED TOOLS APPL, V79, P24929, DOI 10.1007/s11042-020-09210-z; Maria HH, 2021, OPTIK, V241, DOI 10.1016/j.ijleo.2021.166883; Mathew MP, 2022, SIGNAL IMAGE VIDEO P, V16, P841, DOI 10.1007/s11760-021-02024-y; Milletari F, 2017, COMPUT VIS IMAGE UND, V164, P92, DOI 10.1016/j.cviu.2017.04.002; Mubashar M, 2022, NEURAL COMPUT APPL, V34, P17723, DOI 10.1007/s00521-022-07419-7; Natl Acad Sci Engn Med, 2016, OVARIAN CANCERS: EVOLVING PARADIGMS IN RESEARCH AND CARE, P1, DOI 10.17226/21841; Oktay O., 2018, Medical Imaging with Deep Learning, DOI DOI 10.48550/ARXIV; Pang SC, 2020, EUR J NUCL MED MOL I, V47, P2248, DOI 10.1007/s00259-020-04781-3; Pham TN, 2023, J SUPERCOMPUT, V79, P8966, DOI 10.1007/s11227-022-04979-2; Punn NS, 2022, ARTIF INTELL REV, V55, P5845, DOI 10.1007/s10462-022-10152-1; Qin CJ, 2022, MEASUREMENT, V194, DOI 10.1016/j.measurement.2022.111090; Shafi U, 2019, Int J Recent Technol Eng, V8, P545; Shakrani KV., 2022, ACTA INFORM MALAYS, DOI [10.26480/aim.02.2022, DOI 10.26480/AIM.02.2022]; Shalini R, 2022, PHYS ENG SCI MED, V45, P1111, DOI 10.1007/s13246-022-01178-4; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; Siddique N, 2021, IEEE ACCESS, V9, P82031, DOI 10.1109/ACCESS.2021.3086020; Srivastava S., 2020, SN Comput. Sci, V1, P81, DOI [10.1007/s42979-020-0109-6, DOI 10.1007/S42979-020-0109-6]; Sun XM, 2022, IEEE ACCESS, V10, P93845, DOI 10.1109/ACCESS.2022.3204683; Tran ST, 2021, IEEE ACCESS, V9, P3752, DOI 10.1109/ACCESS.2020.3047861; Wang JK, 2022, J DIGIT IMAGING, V35, P1479, DOI 10.1007/s10278-022-00668-x; Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-018-0932-7, 10.1007/s10916-017-0845-x]; Wang Y, 2021, NEURAL COMPUT APPL, V33, P9637, DOI 10.1007/s00521-021-05728-x; Xu Q, 2020, IEEE J BIOMED HEALTH, V24, P2481, DOI 10.1109/JBHI.2020.2986376; Xu RJ, 2021, FORESTS, V12, DOI 10.3390/f12020217; Yan J, 2020, NANO LETT, V20, P5844, DOI 10.1021/acs.nanolett.0c01757; Yang TX, 2019, ARTIF LIFE ROBOT, V24, P550, DOI 10.1007/s10015-019-00547-9; Yu H, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04234-0; Yuan WW, 2022, VIS COMPUT IND BIOME, V5, DOI 10.1186/s42492-022-00110-7; Zhang YT, 2019, BMC CANCER, V19, DOI 10.1186/s12885-019-6139-6; Zhang Z, 2020, IEEE ACCESS, V8, P44999, DOI 10.1109/ACCESS.2020.2977962; Zhang ZY, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103261; Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]; Zhu XF, 2023, INT J MACH LEARN CYB, V14, P2041, DOI 10.1007/s13042-022-01744-y	49	2	2	2	17	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0941-0643	1433-3058		NEURAL COMPUT APPL	Neural Comput. Appl.	JUL	2023	35	21					15805	15819		10.1007/s00521-023-08569-y	http://dx.doi.org/10.1007/s00521-023-08569-y		APR 2023	15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	H7JB4					2024-09-18	WOS:000974742600003
J	Xu, C; Zhang, Y; Fan, XJ; Lan, XJ; Ye, X; Wu, TN				Xu, Chao; Zhang, Yi; Fan, Xianjun; Lan, Xingjie; Ye, Xin; Wu, Tongning			An efficient fluorescence in situ hybridization (FISH)-based circulating genetically abnormal cells (CACs) identification method based on Multi-scale MobileNet-YOLO-V4	QUANTITATIVE IMAGING IN MEDICINE AND SURGERY			English	Article						Circulating genetically abnormal cell (CAC); fluorescence in situ hybridization (FISH); multi-scale; You Only Look Once-V4 (YOLO-V4); MobileNet-V3	TUMOR-CELLS; AUTOMATED DETECTION; CLASSIFICATION	Background: Circulating tumor cells (CTCs) acting as "liquid biopsy" of cancer arc cells that have been shed from the primary tumor, which cause the development of a secondary tumor in a distant organ site, leading to cancer metastasis. Recent research suggests that CTCs with abnormalities in gene copy numbers in mononuclear cell-enriched peripheral blood samples, namely circulating genetically abnormal cells (CACs), could be used as a non-invasive decision tool to detect patients with benign pulmonary nodules. Such cells are identified by counting the fluorescence signals of fluorescence in situ hybridization (FISH). However, owing to the rarity of CACs in the bkxxl, identification of CACs using this technique is time-consuming and is a drawback of this method. Methods: This study has proposed an efficient and automatic FISH-based CACs identification approach which is based on a combination of the high accuracy of You Only Look Once (YOLO)-V4 and the lightweight and rapidness of MobileNet-V3. The backbone of YOLO-V4 was replaced with MobileNet-V3 to improve the detection efficiency and prevent overfitting, and the architecture of YOLO-V4 was optimized by utilizing a new feature map with a larger scale to enable the enhanced detection ability for small targets. Results: We trained and tested the proposed model using a dataset containing more than 7,000 cells based on five-fold cross-validation. All the images in the dataset were 2,448x2,048 (pixels) in size. The number of cells in each image was >70. The accuracy of four-color fluorescence signals detection for our proposed model were all approximately 98%, and the mean average precision (mAP) were close to 100%. The final outcome of the developed method was the type of cells, i.e., normal cells, CACs, gaining cells or deletion cells. The method had a CACs identification accuracy of 93.86% (similar to an expert pathologist), and a detection speed that was about 500 times greater than that of a pathologist. Conclusions: The developed method could greatly increase the review accuracy, enhance the efficiency of reviewers, and reduce the review turnaround time during CACs identification.	[Xu, Chao; Zhang, Yi; Wu, Tongning] China Acad Informat & Commun Technol, China Telecommun Technol Labs, Beijing 100191, Peoples R China; [Fan, Xianjun; Ye, Xin] Zhuhai Sanmed Biotech Ltd, Dept Prod Dev, Zhuhai 519000, Peoples R China; [Lan, Xingjie] Zhuhai Sanmed Biotech Ltd, Dept Data Operat, Zhuhai, Peoples R China	China Academy of Information & Communication Technology	Wu, TN (corresponding author), China Acad Informat & Commun Technol, China Telecommun Technol Labs, Beijing 100191, Peoples R China.; Ye, X (corresponding author), Zhuhai Sanmed Biotech Ltd, Dept Prod Dev, Zhuhai 519000, Peoples R China.	ye.xin@sanmedbio.com; wutongning@caict.ac.cn	Wu, Tongning/J-7308-2019	Ye, Xin/0000-0002-7942-3596; Wu, Tongning/0000-0002-9894-9518	National Natural Science Foundation of China [61971445]; National Key R&D Program of China [2019YFF0216302]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China	This work was supported by the National Natural Science Foundation of China (grant No. 61971445) and National Key R&D Program of China (grant No. 2019YFF0216302).	Alix-Panabières C, 2014, NAT REV CANCER, V14, P623, DOI 10.1038/nrc3820; Bochkovskiy A, ARXIV200410934V1CSCV; Brock G, 2015, TRANSL CANCER RES, V4, P280, DOI 10.3978/j.issn.2218-676X.2015.06.05; Chen Q, 2020, J COMPUTER COMMUNICA, V8, P285, DOI [10.26914/ c.cnkihy.2021.000290, DOI 10.26914/C.CNKIHY.2021.000290]; Ciurte A, 2015, 2015 IEEE INT C INT; Ciurte A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208385; Dhieb N, 2019, INT C MICROELECTRON, P300, DOI [10.1109/ICM48031.2019.9021862, 10.1109/icm48031.2019.9021862]; Dürr O, 2016, J BIOMOL SCREEN, V21, P998, DOI 10.1177/1087057116631284; Esmaeilsabzali H, 2013, BIOTECHNOL ADV, V31, P1063, DOI 10.1016/j.biotechadv.2013.08.016; Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2; Guber A, 2010, CANCER CYTOPATHOL, V118, P269, DOI 10.1002/cncy.20094; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Hu XL, 2021, COMPUT ELECTRON AGR, V185, DOI 10.1016/j.compag.2021.106135; Johnson JW, 2020, ADV INTELL SYST COMP, V944, P399, DOI 10.1007/978-3-030-17798-0_32; Katz RL, 2020, MONOGR CLIN CYTOL, V25, P43, DOI 10.1159/000455780; Katz RL, 2020, CANCER CYTOPATHOL, V128, P553, DOI 10.1002/cncy.22278; Katz RL, 2010, CLIN CANCER RES, V16, P3976, DOI 10.1158/1078-0432.CCR-09-3358; Kumar A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03541-x; Liu WR, 2020, THORAC CANCER, V11, P3234, DOI 10.1111/1759-7714.13654; Liu Y, 2019, P 2 INT C BIG DAT TE; Lozar T, 2019, RADIOL ONCOL, V53, P131, DOI 10.2478/raon-2019-0024; Luo G, 2020, ARXIV201113096V2CSCV; Qiu XC, 2022, J CANCER RES CLIN, V148, P685, DOI 10.1007/s00432-021-03648-w; Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803; Svensson CM, 2014, CYTOM PART A, V85A, P501, DOI 10.1002/cyto.a.22471; Toratani M, 2018, CANCER RES, V78, P6703, DOI 10.1158/0008-5472.CAN-18-0653; Tsuji K, 2020, MOBILE NETW APPL, V25, P1042, DOI 10.1007/s11036-018-1121-0; Wang CY, ARXIV201108036V2CSCV; Wang QW, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218808; Wang S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69056-1; Wolf FA, 2018, GENOME BIOL, V19, DOI 10.1186/s13059-017-1382-0; Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009; Xie WD, 2018, COMP M BIO BIO E-IV, V6, P283, DOI 10.1080/21681163.2016.1149104; Xu Y, 2015, INT CONF ACOUST SPEE, P947, DOI 10.1109/ICASSP.2015.7178109; Ye X, 2021, PATHOLOGY CLASSICS I, DOI [10.5772/intechopen.97631, DOI 10.5772/INTECHOPEN.97631]; Yu JM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093263; Zhang AJ, 2019, J MED IMAG HEALTH IN, V9, P167, DOI 10.1166/jmihi.2019.2556; Zhang B, 2019, J THORAC ONCOL, V14, pS798, DOI 10.1016/j.jtho.2019.08.1715	39	7	8	3	61	AME PUBLISHING COMPANY	SHATIN	FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG 00000, PEOPLES R CHINA	2223-4292	2223-4306		QUANT IMAG MED SURG	Quant. Imaging Med. Surg.	MAY	2022	12	5					2961	+		10.21037/qims-21-909	http://dx.doi.org/10.21037/qims-21-909			19	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	ZX9GR	35502367	Green Published, gold			2024-09-18	WOS:000772201800003
J	Hwang, YJ; Kim, GH; Lee, H; Sung, ES; Nam, KW				Hwang, Young Jun; Kim, Gun Ho; Lee, Hongje; Sung, Eui-Suk; Nam, Kyoung Won			CONVOLUTIONAL NEURAL NETWORK-BASED MULTI-REGION SINGLE INSPECTION TECHNIQUE FOR AT-HOME, SELF-PRESCREENING OF ORAL/LARYNGEAL TUMORS	JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY			English	Article						Oral cancer; home diagnosis; early detection; deep learning; artificial intelligence	DEEP; CLASSIFICATION; HEAD	Late detection of oral/laryngeal cancers or squamous cell carcinoma results in high patient mortality. Therefore, the detection of early-stage disease symptoms and timely medical treatment are important for improving long-term survival rates. Here, three deep learning models (single-shot detector, Yolo V4 and Tiny Yolo) were developed for target detection and binary type classification (normal/suspicious) for four representative oral/laryngeal regions (tongue, epiglottis, vocal cords, and tonsils) with a single-inspection process. The model performance was evaluated quantitatively on desktop and embedded platforms. We collected 1,632 endoscopic still-images and 20 diagnostic videos from the hospital database to train, validate, and test the models. Experimental results demonstrated that implemented models showed F1-scores ranging between 0.74-0.86, 0.86-1.00, and 0.74-0.87, and average precision ranging between 0.60-0.82, 0.92-1.00, and 0.72-0.98 for the tongue, epiglottis, and vocal cords, respectively, on the desktop platform. In addition, the Yolo V4 model showed performances of 0.92, 0.82, and 2.00 frames per second for the F1-score, average precision, and inference speed, respectively, on the embedded platform. Based on these results, we conclude that the implemented deep-learning-based at-home self-prescreening technique may be a reliable tool for personal oral/laryngeal healthcare, which will be especially important in endemic situations.	[Hwang, Young Jun; Nam, Kyoung Won] Pusan Natl Univ, Sch Med, Dept Biomed Engn, Yangsan, South Korea; [Kim, Gun Ho] Pusan Natl Univ, Med Res Inst, Yangsan, South Korea; [Lee, Hongje] Dongnam Inst Radiol & Med Sci, Dept Nucl Med, Pusan, South Korea; [Sung, Eui-Suk] Pusan Natl Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Yangsan, South Korea; [Sung, Eui-Suk; Nam, Kyoung Won] Pusan Natl Univ, Yangsan Hosp, Res Inst Convergence Biomed Sci & Technol, Yangsan, South Korea	Pusan National University; Pusan National University Hospital; Pusan National University; Korea Institute of Radiological & Medical Sciences; Pusan National University; Pusan National University Hospital; Pusan National University; Pusan National University Hospital	Nam, KW (corresponding author), Pusan Natl Univ, Sch Med, Dept Biomed Engn, Yangsan, South Korea.; Sung, ES (corresponding author), Pusan Natl Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Yangsan, South Korea.; Sung, ES; Nam, KW (corresponding author), Pusan Natl Univ, Yangsan Hosp, Res Inst Convergence Biomed Sci & Technol, Yangsan, South Korea.	sunges77@gmail.com; marmera@gmail.com		Nam, Kyoung Won/0000-0002-8378-8758	National Research Foundation of Korea (NRF) - Korean Government (MSIT) [NRF-2021R1C1C1011799]; National Research Council of Science and Technology (NST) Grant by the Korean Government (MSIT) [CRC-19-01-KISTI]; Dongnam Institute of Radiological amp; Medical Sciences (DIRAMS) grant - Korean Government (MSIT) [50594-2022]	National Research Foundation of Korea (NRF) - Korean Government (MSIT)(National Research Foundation of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); National Research Council of Science and Technology (NST) Grant by the Korean Government (MSIT)(Ministry of Science & ICT (MSIT), Republic of KoreaNational Research Council of Science & Technology (NST), Republic of Korea); Dongnam Institute of Radiological amp; Medical Sciences (DIRAMS) grant - Korean Government (MSIT)	This research was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean Government (MSIT) (No. NRF-2021R1C1C1011799) and by the National Research Council of Science and Technology (NST) Grant by the Korean Government (MSIT) (No. CRC-19-01-KISTI).This work was also supported by the Dongnam Institute of Radiological & amp; Medical Sciences (DIRAMS) grant funded by the Korean Government (MSIT) (No. 50594-2022).	Askarian B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153307; Aubreville M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12320-8; Bengs Marcel, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P690, DOI 10.1007/978-3-030-59716-0_66; Bengs M., 2020, Proc. SPIE, V11314, P369; Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042; Byeon H, 2021, INT J ADV COMPUT SC, V12, P112; Camalan S, 2021, CANCERS, V13, DOI 10.3390/cancers13061291; Cho WK, 2021, LARYNGOSCOPE, V131, P2558, DOI 10.1002/lary.29595; Heo J, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10287-9; Ilhan B, 2020, J DENT RES, V99, P241, DOI 10.1177/0022034520902128; Jubair F, 2022, ORAL DIS, V28, P1123, DOI 10.1111/odi.13825; Kar A, 2020, J ORAL PATHOL MED, V49, P727, DOI 10.1111/jop.13013; Kim GH, 2021, BIOMED ENG ONLINE, V20, DOI 10.1186/s12938-021-00886-4; Kono M, 2021, DIGEST ENDOSC, V33, P569, DOI 10.1111/den.13800; Larsen CF, 2023, EUR ARCH OTO-RHINO-L, V280, P2365, DOI 10.1007/s00405-022-07736-6; MAIER H, 1992, CLIN INVESTIGATOR, V70, P320; Nanditha BR, 2021, INT J ONLINE BIOMED, V17, P121, DOI 10.3991/ijoe.v17i02.19207; Paderno A, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.626602; Ren JJ, 2020, LARYNGOSCOPE, V130, pE686, DOI 10.1002/lary.28539; Shamim MZM, 2022, COMPUT J, V65, P91, DOI 10.1093/comjnl/bxaa136; Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402; Song BF, 2018, BIOMED OPT EXPRESS, V9, P5318, DOI 10.1364/BOE.9.005318; Tanriver G, 2021, CANCERS, V13, DOI 10.3390/cancers13112766; Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037; VOKES EE, 1993, NEW ENGL J MED, V328, P184, DOI 10.1056/NEJM199301213280306; Warin K, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0273508; Welikala RA, 2020, IEEE ACCESS, V8, P132677, DOI 10.1109/ACCESS.2020.3010180; Wittekindt C, 2012, Laryngorhinootologie, V91 Suppl 1, pS1, DOI [10.3205/cto000091, 10.1055/s-0031-1297241]; Yan P, 2021, AUTOMATED DETECTION; Yoo TK, 2020, COMPUT BIOL MED, V125, DOI 10.1016/j.compbiomed.2020.103980; Yousef R, 2022, MULTIMEDIA SYST, V28, P881, DOI 10.1007/s00530-021-00884-5; Zhao Q, 2022, MED PHYS, V49, P432, DOI 10.1002/mp.15371	32	0	0	2	5	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-5194	1793-6810		J MECH MED BIOL	J. Mech. Med. Biol.	AUG 31	2023										10.1142/S0219519423500884	http://dx.doi.org/10.1142/S0219519423500884			15	Biophysics; Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Biophysics; Engineering	Q7DP8					2024-09-18	WOS:001059094800005
J	Wu, HT; Fu, QS				Wu, Haiting; Fu, Qingsong			An Innovative Deep Learning Approach to Spinal Fracture Detection in CT Images	ANNALI ITALIANI DI CHIRURGIA			English	Article						deep learning; spinal fracture; CT images; accuracy; YOLO V7; agency; TRF	CLASSIFICATION; SEGMENTATION; CANCER	AIM: Spinal fractures, particularly vertebral compression fractures, pose a significant challenge in medical imaging due to their smallscale nature and blurred boundaries in Computed Tomography (CT) scans. However, advanced deep learning models, such as the integration of the You Only Look Once (YOLO) V7 model with Efficient Layer Aggregation Networks (ELAN) and Max-Pooling Convolution (MPConv) architectures, can substantially reduce the loss of small-scale information during computational processing, thus improving detection accuracy. The purpose of this study is to develop an innovative deep learning approach for detecting spinal fractures, particularly vertebral compression fractures, in CT images. METHODS: We proposed a novel method to precisely identify spinal injury using the YOLO V7 model as a classifier. This model was enhanced by integrating ELAN and MPConv architectures, which were influenced by the Receptive Field Learning and Aggregation (RFLA) small object recognition framework. Standard normalization techniques were utilized to preprocess the CT images. The YOLO V7 model, integrated with ELAN and MPConv architectures, was trained using a dataset containing annotated spinal fractures. Additionally, to mitigate boundary ambiguities in compressive fractures, a Theoretical Receptive Field (TRF) based on Gaussian distribution and an Effective Receptive Field (ERF) were used to capture multi-scale features better. Furthermore, the Wasserstein distance was employed to optimize the model's learning process. A total of 240 CT images from patients diagnosed with spinal fractures were included in this study, sourced from Ningbo No.2 Hospital, ensuring a robust dataset for training the deep learning model. RESULTS: Our method demonstrated superior performance over conventional object detection networks like YOLO V7 and YOLO V3. Specifically, with a dataset of 200 pathological images and 40 normal spinal images, our method achieved a 3% increase in accuracy CONCLUSIONS: The proposed method offers an innovative and more effective approach for identifying vertebral compression fractures in CT scans. These promising findings suggest the method's potential for practical clinical applications, highlighting the significance of deep learning in enhancing patient care and treatment in medical imaging. Future research should incorporate cross-validation and independent validation and test sets to assess the model's robustness and generalizability. Additionally, exploring other deep learning models and methods could further enhance detection accuracy and reliability, contributing to the development of more effective diagnostic tools in medical imaging.	[Wu, Haiting] Ningbo No 2 Hosp, Dept Spinal Surg, Ningbo 315010, Zhejiang, Peoples R China; [Fu, Qingsong] Ningbo No 2 Hosp, Dept Orthopaed, Ningbo 315010, Zhejiang, Peoples R China		Fu, QS (corresponding author), Ningbo No 2 Hosp, Dept Orthopaed, Ningbo 315010, Zhejiang, Peoples R China.	fuqs2021@163.com			Medical Scientific Research Foundation of Zhejiang Province [2019KY597]; Ningbo Public Service Technology Foundation [2022S063]	Medical Scientific Research Foundation of Zhejiang Province; Ningbo Public Service Technology Foundation	This work was supported by Medical Scientific Research Foundation of Zhejiang Province (2019KY597) , Ningbo Public Service Technology Foundation (2022S063) ,	Acharya UR, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1428-9; Adler J, 2018, ADV NEUR IN, V31; Alam F, 2018, BIOCYBERN BIOMED ENG, V38, P71, DOI 10.1016/j.bbe.2017.10.001; Baskaran L, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232573; Baumgartner M, 2021, LECT NOTES COMPUT SC, V12905, P530, DOI 10.1007/978-3-030-87240-3_51; Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013; Biswas M, 2019, FRONT BIOSCI-LANDMRK, V24, P392, DOI 10.2741/4725; Boveiri HR, 2020, COMPUT ELECTR ENG, V87, DOI 10.1016/j.compeleceng.2020.106767; Brutti F, 2022, CARDIOVASC ENG TECHN, V13, P535, DOI 10.1007/s13239-021-00594-z; Cao X, 2020, Handbook of medical image computing and computer assisted intervention, P319; Chan HP, 2020, ADV EXP MED BIOL, V1213, P3, DOI 10.1007/978-3-030-33128-3_1; Chen G, 2023, IEEE INT CON MULTI, P1020, DOI 10.1109/ICME55011.2023.00179; Chen JW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144908; Cheng CT, 2019, EUR RADIOL, V29, P5469, DOI 10.1007/s00330-019-06167-y; Currie G, 2019, J MED IMAGING RADIAT, V50, P477, DOI 10.1016/j.jmir.2019.09.005; Derkatch S, 2019, RADIOLOGY, V293, P405, DOI 10.1148/radiol.2019190201; Dong Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P507, DOI 10.1007/978-3-319-66179-7_58; Ebsim R, 2019, LECT NOTES COMPUT SC, V11404, P114, DOI 10.1007/978-3-030-11166-3_10; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Jarrett D, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20190001; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Kulasingham JP, 2023, IEEE T BIO-MED ENG, V70, P88, DOI 10.1109/TBME.2022.3185005; Levine AB, 2019, TRENDS CANCER, V5, P157, DOI 10.1016/j.trecan.2019.02.002; Li W., 2015, Journal of Computer and Communications, V3, P146, DOI 10.4236/jcc.2015.311023; Li ZL, 2019, NEUROCOMPUTING, V350, P53, DOI 10.1016/j.neucom.2019.04.028; Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409; Lin L, 2019, RADIOLOGY, V291, P677, DOI 10.1148/radiol.2019182012; Litjens G, 2019, JACC-CARDIOVASC IMAG, V12, P1549, DOI 10.1016/j.jcmg.2019.06.009; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo WJ, 2016, ADV NEUR IN, V29; Perone CS, 2019, Journal of Medical Artificial Intelligence, P2; Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690]; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Samarasinghe G, 2021, J MED IMAG RADIAT ON, V65, P578, DOI 10.1111/1754-9485.13286; Shin HC, 2018, LECT NOTES COMPUT SC, V11037, P1, DOI 10.1007/978-3-030-00536-8_1; Sori WJ, 2019, MULTIDIM SYST SIGN P, V30, P1749, DOI 10.1007/s11045-018-0626-9; Sun CJ, 2017, ARTIF INTELL MED, V83, P58, DOI 10.1016/j.artmed.2017.03.008; Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007; Voulodimos A, 2021, SENSORS-BASEL, V21, DOI [10.3390/s21062215, 10.1145/3453892.3461322]; Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721; Ward TM, 2021, SURGERY, V169, P1253, DOI 10.1016/j.surg.2020.10.039; Yoon AP, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.6096	46	0	0	1	1	EDIZIONI LUIGI POZZI	ROME	VIA PANAMA 68, 00198 ROME, ITALY	0003-469X	2239-253X		ANN ITAL CHIR	Ann. Ital. Chir.	JUL-AUG	2024	95	4					657	668		10.62713/aic.3498	http://dx.doi.org/10.62713/aic.3498			12	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	E0V1R	39186337	Bronze			2024-09-18	WOS:001300260600026
