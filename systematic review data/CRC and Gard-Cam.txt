PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Wesp, P; Grosu, S; Graser, A; Maurus, S; Schulz, C; Knösel, T; Fabritius, MP; Schachtner, B; Yeh, BM; Cyran, CC; Ricke, J; Kazmierczak, PM; Ingrisch, M				Wesp, Philipp; Grosu, Sergio; Graser, Anno; Maurus, Stefan; Schulz, Christian; Knosel, Thomas; Fabritius, Matthias P.; Schachtner, Balthasar; Yeh, Benjamin M.; Cyran, Clemens C.; Ricke, Jens; Kazmierczak, Philipp M.; Ingrisch, Michael			Deep learning in CT colonography: differentiating premalignant from benign colorectal polyps	EUROPEAN RADIOLOGY			English	Article						Colonography; Computed tomographic; Colonic polyp; Deep learning; Early detection of cancer	CANCER; COLONOSCOPY; PARTICIPATION; PREVENTION; ADENOMA; SOCIETY; RATES	Objectives To investigate the differentiation of premalignant from benign colorectal polyps detected by CT colonography using deep learning. Methods In this retrospective analysis of an average risk colorectal cancer screening sample, polyps of all size categories and morphologies were manually segmented on supine and prone CT colonography images and classified as premalignant (adenoma) or benign (hyperplastic polyp or regular mucosa) according to histopathology. Two deep learning models SEG and noSEG were trained on 3D CT colonography image subvolumes to predict polyp class, and model SEG was additionally trained with polyp segmentation masks. Diagnostic performance was validated in an independent external multicentre test sample. Predictions were analysed with the visualisation technique Grad-CAM++. Results The training set consisted of 107 colorectal polyps in 63 patients (mean age: 63 +/- 8 years, 40 men) comprising 169 polyp segmentations. The external test set included 77 polyps in 59 patients comprising 118 polyp segmentations. Model SEG achieved a ROC-AUC of 0.83 and 80% sensitivity at 69% specificity for differentiating premalignant from benign polyps. Model noSEG yielded a ROC-AUC of 0.75, 80% sensitivity at 44% specificity, and an average Grad-CAM++ heatmap score of >= 0.25 in 90% of polyp tissue. Conclusions In this proof-of-concept study, deep learning enabled the differentiation of premalignant from benign colorectal polyps detected with CT colonography and the visualisation of image regions important for predictions. The approach did not require polyp segmentation and thus has the potential to facilitate the identification of high-risk polyps as an automated second reader.	[Wesp, Philipp; Grosu, Sergio; Maurus, Stefan; Fabritius, Matthias P.; Schachtner, Balthasar; Cyran, Clemens C.; Ricke, Jens; Kazmierczak, Philipp M.; Ingrisch, Michael] Ludwig Maximilians Univ Munchen, Dept Radiol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany; [Graser, Anno] Radiol Munchen, Burgstr 7, D-80331 Munich, Germany; [Schulz, Christian] Ludwig Maximilians Univ Munchen, Dept Med 2, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany; [Knosel, Thomas] Ludwig Maximilians Univ Munchen, Dept Pathol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany; [Schachtner, Balthasar] German Ctr Lung Res DZL, Comprehens Pneumol Ctr CPC M, Max Lebsche Pl 31, D-81377 Munich, Germany; [Yeh, Benjamin M.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave, San Francisco, CA 94117 USA	University of Munich; University of Munich; University of Munich; University of California System; University of California San Francisco	Wesp, P (corresponding author), Ludwig Maximilians Univ Munchen, Dept Radiol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany.	philipp.wesp@med.uni-muenchen.de	schulz, christian/HOA-7122-2023; Wesp, Philipp/HNO-9426-2023; Ingrisch, Michael/T-3408-2017	Grosu, Sergio/0000-0002-9093-6499; Wesp, Philipp/0000-0001-7356-3371	Projekt DEAL; FoFoLe, Medizinische Fakultat, Ludwig-Maximilians-Universitat Munchen, Germany	Projekt DEAL; FoFoLe, Medizinische Fakultat, Ludwig-Maximilians-Universitat Munchen, Germany	Open Access funding enabled and organized by Projekt DEAL. This study has received funding by FoFoLe, Medizinische Fakultat, Ludwig-Maximilians-Universitat Munchen, Germany (PI: Sergio Grosu).	Abadi M, 2015, **DATA OBJECT**, V21, DOI [10.5281/zenodo.4724125, DOI 10.5281/ZENODO.4724125]; [Anonymous], CA-CANCER J CLIN, DOI DOI 10.3322/caac.20115; [Anonymous], 2013, Robbins basic pathology; Atkin W, 2013, LANCET, V381, P1194, DOI 10.1016/S0140-6736(12)62186-2; Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7; Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012; Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467; Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097; Chollet Francois, 2015, Keras; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; Dachman AH, 2010, RADIOLOGY, V256, P827, DOI 10.1148/radiol.10091890; Graser A, 2009, GUT, V58, P241, DOI 10.1136/gut.2008.156448; Grosu S, 2021, RADIOLOGY, V299, P326, DOI 10.1148/radiol.2021202363; Halligan S, 2011, RADIOLOGY, V258, P469, DOI 10.1148/radiol.10100354; Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996; Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543; Kim DH, 2016, RADIOLOGY, V280, P455, DOI 10.1148/radiol.2016151608; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; MANDEL JS, 1993, NEW ENGL J MED, V328, P1365, DOI 10.1056/NEJM199305133281901; Nolden M, 2013, INT J COMPUT ASS RAD, V8, P607, DOI 10.1007/s11548-013-0840-8; Pickhardt PJ, 2008, AM J ROENTGENOL, V190, P136, DOI 10.2214/AJR.07.2646; Rex DK, 2017, GASTROENTEROLOGY, V153, P307, DOI 10.1053/j.gastro.2017.05.013; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]; Smith K., 2015, **DATA OBJECT**, DOI [10.7937/K9/TCIA.2015.NWTESAY1, DOI 10.7937/K9/TCIA.2015.NWTESAY1]; Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2; Spada C, 2021, EUR RADIOL, V31, P2967, DOI 10.1007/s00330-020-07413-4; Stoop EM, 2012, LANCET ONCOL, V13, P55, DOI 10.1016/S1470-2045(11)70283-2; Tan JX, 2020, IEEE T MED IMAGING, V39, P2013, DOI 10.1109/TMI.2019.2963177; van der Meulen MP, 2018, RADIOLOGY, V287, P901, DOI 10.1148/radiol.2017162359; WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701; Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370	31	8	8	1	22	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0938-7994	1432-1084		EUR RADIOL	Eur. Radiol.	JUL	2022	32	7					4749	4759		10.1007/s00330-021-08532-2	http://dx.doi.org/10.1007/s00330-021-08532-2		JAN 2022	11	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	2I3RK	35083528	Green Published, hybrid			2024-09-18	WOS:000747080500001
J	Zhou, PY; Cao, YZ; Li, M; Ma, YH; Chen, C; Gan, XJ; Wu, JY; Lv, XY; Chen, C				Zhou, Panyun; Cao, Yanzhen; Li, Min; Ma, Yuhua; Chen, Chen; Gan, Xiaojing; Wu, Jianying; Lv, Xiaoyi; Chen, Cheng			HCCANet: histopathological image grading of colorectal cancer using CNN based on multichannel fusion attention mechanism	SCIENTIFIC REPORTS			English	Article							RESIDUAL NETWORK; CLASSIFICATION	Histopathological image analysis is the gold standard for pathologists to grade colorectal cancers of different differentiation types. However, the diagnosis by pathologists is highly subjective and prone to misdiagnosis. In this study, we constructed a new attention mechanism named MCCBAM based on channel attention mechanism and spatial attention mechanism, and developed a computer-aided diagnosis (CAD) method based on CNN and MCCBAM, called HCCANet. In this study, 630 histopathology images processed with Gaussian filtering denoising were included and gradient-weighted class activation map (Grad-CAM) was used to visualize regions of interest in HCCANet to improve its interpretability. The experimental results show that the proposed HCCANet model outperforms four advanced deep learning (ResNet50, MobileNetV2, Xception, and DenseNet121) and four classical machine learning (KNN, NB, RF, and SVM) techniques, achieved 90.2%, 85%, and 86.7% classification accuracy for colorectal cancers with high, medium, and low differentiation levels, respectively, with an overall accuracy of 87.3% and an average AUC value of 0.9.In addition, the MCCBAM constructed in this study outperforms several commonly used attention mechanisms SAM, SENet, SKNet, Non_Local, CBAM, and BAM on the backbone network. In conclusion, the HCCANet model proposed in this study is feasible for postoperative adjuvant diagnosis and grading of colorectal cancer.	[Zhou, Panyun; Lv, Xiaoyi; Chen, Cheng] Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China; [Cao, Yanzhen; Gan, Xiaojing] Xinjiang Med Univ, Affiliated Tumor Hosp, Urumqi 830011, Peoples R China; [Li, Min; Chen, Chen; Lv, Xiaoyi] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China; [Li, Min; Lv, Xiaoyi] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China; [Ma, Yuhua] Tongji Univ, Shanghai East Hosp, Dept Oncol, Sch Med, Shanghai 200120, Peoples R China; [Ma, Yuhua] Karamay Cent Hosp Xinjiang Karamay, Dept Pathol, Karamay 834000, Xinjiang Uygur, Peoples R China; [Chen, Chen; Lv, Xiaoyi] Xinjiang Cloud Comp Applicat Lab, Karamay 834099, Peoples R China; [Wu, Jianying] Xinjiang Normal Univ, Coll Phys & Elect Engn, Urumqi 830054, Peoples R China; [Lv, Xiaoyi] Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830046, Peoples R China	Xinjiang University; Xinjiang Medical University; Xinjiang University; Xinjiang University; Tongji University; Xinjiang Normal University; Xinjiang University	Lv, XY; Chen, C (corresponding author), Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China.; Lv, XY (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.; Lv, XY (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.; Lv, XY (corresponding author), Xinjiang Cloud Comp Applicat Lab, Karamay 834099, Peoples R China.; Lv, XY (corresponding author), Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830046, Peoples R China.	xjuwawj01@163.com; chenchengoptics@gmail.com	xiao, ming/KHT-1774-2024		Key Laboratory of Clinical Gene Detection and Biomedical Information of Xinjiang; Xinjiang Uygur Autonomous Region Science Foundation for Distinguished Young Scholars [2022D01E11, 2022D01E27]; National Natural Science Foundation of China [81860430]; Xinjiang Autonomous Region Science and Technology Plan Project [2018D01C257]; Karamay Central Hospital Project: Research on Molecular Mechanism and Application of DNA Methylation Liquid Biopsy in the "Prevention, Diagnosis and Treatment" of Malignant Tumors	Key Laboratory of Clinical Gene Detection and Biomedical Information of Xinjiang; Xinjiang Uygur Autonomous Region Science Foundation for Distinguished Young Scholars; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Xinjiang Autonomous Region Science and Technology Plan Project; Karamay Central Hospital Project: Research on Molecular Mechanism and Application of DNA Methylation Liquid Biopsy in the "Prevention, Diagnosis and Treatment" of Malignant Tumors	This work was supported by the Key Laboratory of Clinical Gene Detection and Biomedical Information of Xinjiang; the Xinjiang Uygur Autonomous Region Science Foundation for Distinguished Young Scholars [grant number 2022D01E11& 2022D01E27]; the National Natural Science Foundation of China [grant number 81860430]; the Xinjiang Autonomous Region Science and Technology Plan Project [grant number 2018D01C257]; the Karamay Central Hospital Project: Research on Molecular Mechanism and Application of DNA Methylation Liquid Biopsy in the "Prevention, Diagnosis and Treatment" of Malignant Tumors.	Alzubaidi L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134523; Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544; Arvaniti E, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30535-1; Black-Schaffer WS, 2016, ACAD PATHOL, V3, DOI 10.1177/2374289516665393; Carion Johannes., 1550, The thre bokes of cronicles; Chen C, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164043; Chen C, 2020, PHOTODIAGN PHOTODYN, V30, DOI 10.1016/j.pdpdt.2020.101792; Chen HY, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105265; Chen L, P IEEE C COMP VIS PA, P5659; Chen SL, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.833978; Chu X., P IEEE C COMP VIS PA; Dai T., P IEEE CVF C COMP VI, P11065; Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350; Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20107, 10.3322/caac.21492, 10.3322/caac.20115]; Kim SH, 2021, MULTIMED TOOLS APPL, V80, P35941, DOI 10.1007/s11042-021-10551-6; Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001; Koohbanani NA, 2018, LECT NOTES COMPUT SC, V11039, P139, DOI 10.1007/978-3-030-00949-6_17; Lei HJ, 2018, PATTERN RECOGN, V79, P290, DOI 10.1016/j.patcog.2018.02.006; Li X., P IEEE CVF C COMP VI, P510; Lin HJ, 2019, IEEE T MED IMAGING, V38, P1948, DOI 10.1109/TMI.2019.2891305; Luo Y, 2017, IEEE INT SYMP ELEC; Mattiuzzi C, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.07.91; Nguyen H.-G., 2020 IEEE 17 INT S B, P1271; Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091; Pei Y, 2020, IEEE ACCESS, V8, P64131, DOI 10.1109/ACCESS.2020.2982543; Ponzio F., 5 INT C BIOIM; Ravishankar A, 2017 INT C EL COMM A, P385; Sarwinda D., 2020 4 INT C INF COM; Sarwinda D, 2021, PROCEDIA COMPUT SCI, V179, P423, DOI 10.1016/j.procs.2021.01.025; Shaban M, 2020, IEEE T MED IMAGING, V39, P2395, DOI 10.1109/TMI.2020.2971006; Shirazi AZ, 2021, BRIT J CANCER, V125, P337, DOI 10.1038/s41416-021-01394-x; Song TH, 2019, IEEE J BIOMED HEALTH, V23, P1469, DOI 10.1109/JBHI.2018.2878945; Sun H, 2020, IEEE J BIOMED HEALTH, V24, P1664, DOI 10.1109/JBHI.2019.2944977; Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302; Tang P, P EUR C COMP VIS ECC, P352; Vasuki P., 2017 IEEE INT C EL I, P1; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xu Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1685-x; Yoon H, 2019, J DIGIT IMAGING, V32, P131, DOI 10.1007/s10278-018-0112-9; Yue FL, 2020, PHOTODIAGN PHOTODYN, V32, DOI 10.1016/j.pdpdt.2020.101923; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zhou Y, 2020, CGC NET CELL GRAPH C	43	21	21	3	36	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	SEP 6	2022	12	1							15103	10.1038/s41598-022-18879-1	http://dx.doi.org/10.1038/s41598-022-18879-1			12	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	4K4GO	36068309	Green Published, gold			2024-09-18	WOS:000851910600007
J	Xu, R; Wang, ZZ; Liu, ZB; Han, C; Yan, LX; Lin, H; Xu, ZY; Feng, ZY; Liang, CH; Chen, X; Pan, XP; Liu, ZY				Xu, Rui; Wang, Zhizhen; Liu, Zhenbing; Han, Chu; Yan, Lixu; Lin, Huan; Xu, Zeyan; Feng, Zhengyun; Liang, Changhong; Chen, Xin; Pan, Xipeng; Liu, Zaiyi			Histopathological Tissue Segmentation of Lung Cancer with Bilinear CNN and Soft Attention	BIOMED RESEARCH INTERNATIONAL			English	Article							CLASSIFICATION	Automatic tissue segmentation in whole-slide images (WSIs) is a critical task in hematoxylin and eosin- (H&E-) stained histopathological images for accurate diagnosis and risk stratification of lung cancer. Patch classification and stitching the classification results can fast conduct tissue segmentation of WSIs. However, due to the tumour heterogeneity, large intraclass variability and small interclass variability make the classification task challenging. In this paper, we propose a novel bilinear convolutional neural network- (Bilinear-CNN-) based model with a bilinear convolutional module and a soft attention module to tackle this problem. This method investigates the intraclass semantic correspondence and focuses on the more distinguishable features that make feature output variations relatively large between interclass. The performance of the Bilinear-CNN-based model is compared with other state-of-the-art methods on the histopathological classification dataset, which consists of 107.7 k patches of lung cancer. We further evaluate our proposed algorithm on an additional dataset from colorectal cancer. Extensive experiments show that the performance of our proposed method is superior to that of previous state-of-the-art ones and the interpretability of our proposed method is demonstrated by Grad-CAM.	[Xu, Rui; Wang, Zhizhen; Liu, Zhenbing; Feng, Zhengyun; Pan, Xipeng] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin, Peoples R China; [Han, Chu; Lin, Huan; Xu, Zeyan; Liang, Changhong; Pan, Xipeng; Liu, Zaiyi] Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Radiol, Guangzhou, Peoples R China; [Han, Chu; Pan, Xipeng] Guangdong Cardiovasc Inst, Guangzhou, Peoples R China; [Han, Chu; Lin, Huan; Xu, Zeyan; Liang, Changhong; Pan, Xipeng; Liu, Zaiyi] Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Guangdong Prov Key Lab Artificial Intelligence Med, Guangzhou, Peoples R China; [Yan, Lixu] Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Pathol, Guangzhou, Peoples R China; [Chen, Xin] South China Univ Technol, Guangzhou Peoples Hosp 1, Dept Radiol, Affiliated Hosp 2, Guangzhou, Peoples R China	Guilin University of Electronic Technology; Guangdong Academy of Medical Sciences & Guangdong General Hospital; Southern Medical University - China; Guangdong Academy of Medical Sciences & Guangdong General Hospital; Southern Medical University - China; Guangdong Academy of Medical Sciences & Guangdong General Hospital; Southern Medical University - China; South China University of Technology	Pan, XP (corresponding author), Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin, Peoples R China.; Pan, XP; Liu, ZY (corresponding author), Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Radiol, Guangzhou, Peoples R China.; Pan, XP (corresponding author), Guangdong Cardiovasc Inst, Guangzhou, Peoples R China.; Pan, XP; Liu, ZY (corresponding author), Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Guangdong Prov Key Lab Artificial Intelligence Med, Guangzhou, Peoples R China.; Chen, X (corresponding author), South China Univ Technol, Guangzhou Peoples Hosp 1, Dept Radiol, Affiliated Hosp 2, Guangzhou, Peoples R China.	webrat@yeah.net; wangzhizhen0012021@163.com; zbliu@guet.edu.cn; zq1992@gmail.com; ylxyss@163.com; huanhuan260@hotmail.com; zeyx0708@163.com; 20032303022@mails.guet.edu.cn; liangchanghong@gdph.org.cn; wolfchenxin@163.com; pxp201@guet.edu.cn; liuzaiyi@gdph.org.cn	Han, Chu/GWM-9255-2022; Liu, Zaiyi/L-9212-2015; zhang, xiaowei/GQH-5387-2022; Li, Shiyu/KHE-1376-2024	Chen, Xin/0000-0002-3873-9041	Key R&D Program of Guangdong Province, China [2021B0101420006]; National Key R&D Program of China [2021YFF1201003]; National Science Fund for Distinguished Young Scholars, China [81925023]; National Natural Science Foundation of China [62002082, 82072090, 62102103, 81771912]; Natural Science Foundation of Guangxi Province [2020GXNSFBA238014]; China Postdoctoral Science Foundation [2021M690753]; Guangxi University Young and Middle Aged Teachers' Research Ability Improvement Project [2020KY05034]; Major Achievement Transformation Foundation of Guilin [20192013-1]; Guangxi Key Research and Development Program [GuikeAB21196063]; Innovation Project of Guangxi Graduate Education [YCSW2021172]; Innovation Project of GUET Graduate Education [2021YCXS060]; High-Level Hospital Construction Project [DFJHBF202105, DFJH201805]; Guangdong Provincial Key Laboratory of Artificial Intelligence in Medical Image Analysis and Application [2022B1212010011]	Key R&D Program of Guangdong Province, China; National Key R&D Program of China; National Science Fund for Distinguished Young Scholars, China(National Natural Science Foundation of China (NSFC)National Science Fund for Distinguished Young Scholars); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Guangxi Province(National Natural Science Foundation of Guangxi Province); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Guangxi University Young and Middle Aged Teachers' Research Ability Improvement Project; Major Achievement Transformation Foundation of Guilin; Guangxi Key Research and Development Program; Innovation Project of Guangxi Graduate Education; Innovation Project of GUET Graduate Education; High-Level Hospital Construction Project; Guangdong Provincial Key Laboratory of Artificial Intelligence in Medical Image Analysis and Application	This research was supported in part by the Key R&D Program of Guangdong Province, China (Grant No. 2021B0101420006), the National Key R&D Program of China (Grant No. 2021YFF1201003), the National Science Fund for Distinguished Young Scholars, China (Grant No. 81925023), the National Natural Science Foundation of China (Grant Nos. 62002082, 82072090, 62102103, and 81771912), the Natural Science Foundation of Guangxi Province (Grant No. 2020GXNSFBA238014), the China Postdoctoral Science Foundation (Grant No. 2021M690753), Guangxi University Young and Middle Aged Teachers' Research Ability Improvement Project (Grant No. 2020KY05034), the Major Achievement Transformation Foundation of Guilin (Grant No. 20192013-1), the Guangxi Key Research and Development Program (Grant No. GuikeAB21196063), the Innovation Project of Guangxi Graduate Education (Grant No. YCSW2021172), the Innovation Project of GUET Graduate Education (Grant No. 2021YCXS060), the High-Level Hospital Construction Project (Grant Nos. DFJHBF202105 and DFJH201805), and the Guangdong Provincial Key Laboratory of Artificial Intelligence in Medical Image Analysis and Application (Grant No. 2022B1212010011).	Anklin V., 2021, MEDICAL IMAGE COMPUT; Barta JA, 2019, ANN GLOB HEALTH, V85, DOI 10.5334/aogh.2419; Chan L, 2019, IEEE I CONF COMP VIS, P10661, DOI 10.1109/ICCV.2019.01076; Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516; Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266; Jun Xu, 2019, Digital Pathology. 15th European Congress, ECDP 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11435), P100, DOI 10.1007/978-3-030-23937-4_12; Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730; Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9; Li YH, 2017, IEEE I CONF COMP VIS, P2098, DOI 10.1109/ICCV.2017.229; Li Z, 2021, IEEE J BIOMED HEALTH, V25, P429, DOI 10.1109/JBHI.2020.3039741; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu WH, 2020, FRONT GENET, V11, DOI 10.3389/fgene.2020.547327; Lu C, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101903; Lu C, 2020, LANCET DIGIT HEALTH, V2, pE594, DOI 10.1016/s2589-7500(20)30225-9; Lu WQ, 2020, IEEE COMPUT SOC CONF, P1049, DOI 10.1109/CVPRW50498.2020.00138; Pan XP, 2017, NEUROCOMPUTING, V229, P88, DOI 10.1016/j.neucom.2016.08.103; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Tan MX, 2019, PR MACH LEARN RES, V97; Tang J, 2020, CANCERS, V12, DOI 10.3390/cancers12092644; Wang CF, 2017, IEEE ENG MED BIO, P4050, DOI 10.1109/EMBC.2017.8037745; Wang SD, 2019, CANCERS, V11, DOI 10.3390/cancers11111673; Wang YF, 2019, J VIS COMMUN IMAGE R, V59, P210, DOI 10.1016/j.jvcir.2018.12.049; Wei XS, 2019, Arxiv, DOI arXiv:1907.03069; Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034; Xu K., 2018, INT C LEARN REPR; Yan CY, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105528; Yang H, 2021, BMC MED, V19, DOI 10.1186/s12916-021-01953-2; Zhao K, 2020, EBIOMEDICINE, V61, DOI 10.1016/j.ebiom.2020.103054	31	3	3	1	24	HINDAWI LTD	LONDON	ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND	2314-6133	2314-6141		BIOMED RES INT-UK	Biomed Res. Int.	JUL 7	2022	2022								7966553	10.1155/2022/7966553	http://dx.doi.org/10.1155/2022/7966553			10	Biotechnology & Applied Microbiology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology; Research & Experimental Medicine	3G8MY	35845926	gold, Green Published			2024-09-18	WOS:000831603200002
J	Uddin, AH; Chen, YL; Akter, MR; Ku, CS; Yang, J; Por, LY				Uddin, A. Hasib; Chen, Yen-Lin; Akter, Miss Rokeya; Ku, Chin Soon; Yang, Jing; Por, Lip Yee			Colon and lung cancer classification from multi-modal images using resilient and efficient neural network architectures	HELIYON			English	Article						Dense neural networks (DNN); Cancer image classification; Multi-modal network; Histopathological imaging; CT-Scan imaging; Lung cancer; Colon cancer		Automatic classification of colon and lung cancer images is crucial for early detection and accurate diagnostics. However, there is room for improvement to enhance accuracy, ensuring better diagnostic precision. This study introduces two novel dense architectures (D1 and D2) and emphasizes their effectiveness in classifying colon and lung cancer from diverse images. It also highlights their resilience, efficiency, and superior performance across multiple datasets. These architectures were tested on various types of datasets, including NCT-CRC-HE-100K (set of 100,000 non -overlapping image patches from hematoxylin and eosin (H &E) stained histological images of human colorectal cancer (CRC) and normal tissue), CRC-VAL-HE-7K (set of 7180 image patches from N = 50 patients with colorectal adenocarcinoma, no overlap with patients in NCTCRC-HE-100K), LC25000 (Lung and Colon Cancer Histopathological Image), and IQ-OTHNCCD (Iraq -Oncology Teaching Hospital/National Center for Cancer Diseases), showcasing their effectiveness in classifying colon and lung cancers from histopathological and Computed Tomography (CT) scan images. This underscores the multi -modal image classification capability of the proposed models. Moreover, the study addresses imbalanced datasets, particularly in CRC-VAL-HE7K and IQ-OTHNCCD, with a specific focus on model resilience and robustness. To assess overall performance, the study conducted experiments in different scenarios. The D1 model achieved an impressive 99.80 % accuracy on the NCT-CRC-HE-100K dataset, with a Jaccard Index (J) of 0.8371, a Matthew ' s Correlation Coefficient (MCC) of 0.9073, a Cohen ' s Kappa (Kp) of 0.9057, and a Critical Success Index (CSI) of 0.8213. When subjected to 10 -fold cross -validation on LC25000, the D1 model averaged (avg) 99.96 % accuracy (avg J, MCC, Kp, and CSI of 0.9993, 0.9987, 0.9853, and 0.9990), surpassing recent reported performances. Furthermore, the ensemble of D1 and D2 reached 93 % accuracy (J, MCC, Kp, and CSI of 0.7556, 0.8839, 0.8796, and 0.7140) on the IQ-OTHNCCD dataset, exceeding recent benchmarks and aligning with other reported results. Efficiency evaluations were conducted in various scenarios. For instance, training on only 10 % of LC25000 resulted in high accuracy rates of 99.19 % (J, MCC, Kp, and CSI of 0.9840, 0.9898, 0.9898, and 0.9837) (D1) and 99.30 % (J, MCC, Kp, and CSI of 0.9863, 0.9913, 0.9913, and 0.9861) (D2). In NCT-CRC-HE-100K, D2 achieved an impressive 99.53 % accuracy (J, MCC, Kp, and CSI of 0.9906, 0.9946, 0.9946, and 0.9906) with training on only 30 % of the dataset and testing on the remaining 70 %. When tested on CRC-VAL-HE-7K, D1 and D2 achieved 95 % accuracy (J, MCC, Kp, and CSI of 0.8845, 0.9455, 0.9452, and 0.8745) and 96 % accuracy (J, MCC, Kp, and CSI of 0.8926, 0.9504, 0.9503, and 0.8798), respectively, outperforming previously reported results and aligning closely with others. Lastly, training D2 on just 10 % of NCT-CRC-HE-100K and testing on CRC-VAL-HE-7K resulted in significant outperformance of InceptionV3, Xception, and DenseNet201 benchmarks, achieving an accuracy rate of 82.98 % (J, MCC, Kp, and CSI of 0.7227, 0.8095, 0.8081, and 0.6671). Finally, using explainable AI algorithms such as Grad -CAM, Grad -CAM ++, Score -CAM, and Faster Score -CAM, along with their emphasized versions, we visualized the features from the last layer of DenseNet201 for histopathological as well as CT -scan image samples. The proposed dense models, with their multi -modality, robustness, and efficiency in cancer image classification, hold the promise of significant advancements in medical diagnostics. They have the potential to revolutionize early cancer detection and improve healthcare accessibility worldwide.	[Uddin, A. Hasib; Akter, Miss Rokeya] Khwaja Yunus Ali Univ, Dept Comp Sci & Engn, Chouhali 6751, Sirajganj, Bangladesh; [Chen, Yen-Lin] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106344, Taiwan; [Ku, Chin Soon] Univ Tunku Abdul Rahman, Dept Comp Sci, Kampar 31900, Malaysia; [Yang, Jing; Por, Lip Yee] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia	National Taipei University of Technology; Universiti Tunku Abdul Rahman (UTAR); Universiti Malaya	Uddin, AH (corresponding author), Khwaja Yunus Ali Univ, Dept Comp Sci & Engn, Chouhali 6751, Sirajganj, Bangladesh.; Chen, YL (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106344, Taiwan.; Ku, CS (corresponding author), Univ Tunku Abdul Rahman, Dept Comp Sci, Kampar 31900, Malaysia.; Por, LY (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.	abdulhasib.cse@kyau.edu.bd; ylchen@mail.ntut.edu.tw; kucs@utar.edu.my; porlip@um.edu.my	Akter, Rokeya/JHS-8896-2023; ku, chin soon/N-6119-2015; Uddin, Abdul/ABC-9991-2020	Chen, Yen-Lin/0000-0001-7717-9393	National Science and Technology Council in Taiwan [NSTC-112-2221-E-027-088-MY2, NSTC-112-2622-8-027-008]; Ministry of Education of Taiwan [1122302319]; UTAR	National Science and Technology Council in Taiwan; Ministry of Education of Taiwan(Ministry of Education, Taiwan); UTAR	This work was supported in part by the National Science and Technology Council in Taiwan under Grant NSTC-112-2221-E-027-088-MY2 and Grant NSTC-112-2622-8-027-008 in part by the Ministry of Education of Taiwan titled "The Study of Artificial Intelligence and Advanced Semiconductor Manufacturing for Female STEM Talent Education and Industry-University Value-Added Cooperation Promotion" under Grant 1122302319, and the UTAR Financial Support for Journal Paper Publication Scheme through Universiti Tunku Abdul Rahman (UTAR), Malaysia.	Borkowski AA, 2019, Arxiv, DOI [arXiv:1912.12142, 10.48550/arXiv.1912.12142, DOI 10.48550/ARXIV.1912.12142]; Aayush R., 2023, Applications of Artificial Intelligence in Medical Imaging, P51, DOI [10.1016/B978-0-443-18450-5.00008-6, DOI 10.1016/B978-0-443-18450-5.00008-6]; Adu K, 2021, INT J IMAG SYST TECH, V31, P2075, DOI 10.1002/ima.22569; Al-Yasriy Hamdalla F., 2020, IOP Conference Series: Materials Science and Engineering, V928, DOI 10.1088/1757-899X/928/2/022035; AlGhamdi R, 2023, CANCERS, V15, DOI 10.3390/cancers15133300; Alyasriy Hamdalla, 2020, Mendeley Data, V1, DOI 10.17632/BHMDR45BH2.1; Bangare S.L., 2022, Computer Vision and Internet of Things, P247, DOI [10.1201/9781003244165-19, DOI 10.1201/9781003244165-19]; Bishop C.M., 2006, Pattern Recognition and Machine Learning; Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097; Chehade AH, 2022, PHYS ENG SCI MED, DOI 10.1007/s13246-022-01139-x; Chen J., 2021, 2021 2 INT SEM ART I, P354, DOI [10.1109/AINIT54228.2021.00076, DOI 10.1109/AINIT54228.2021.00076]; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Diao SH, 2023, IEEE J BIOMED HEALTH, V27, P1535, DOI 10.1109/JBHI.2023.3237137; Ghosh S, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104202; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Hadiyoso S., 2023, International Journal of Applied Science and Engineering, V20, P1; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hossain M, 2022, ENV SCI POLLUT CONTR, P1; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ibrahim NY, 2022, INT J ADV COMPUT SC, V13, P276; Iqbal S, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8040370; Karim DZ, 2021, 2021 IEEE REGION 10 CONFERENCE (TENCON 2021), P626, DOI 10.1109/TENCON54134.2021.9707242; Kather J.N., 2018, 100,000 histological images of human colorectal cancer and healthy tissue; Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730; Kingma D. P., 2017, arXiv; Kumar A, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104172; Kumar N, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103596; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li GL, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104181; Li J, 2023, IET IMAGE PROCESS, V17, P761, DOI 10.1049/ipr2.12670; Liang MY, 2020, IEEE ACCESS, V8, P208969, DOI 10.1109/ACCESS.2020.3038764; Masud M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030748; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mehmood S, 2022, IEEE ACCESS, V10, P25657, DOI 10.1109/ACCESS.2022.3150924; Mohalder Rahul Deb, 2023, Machine Intelligence and Emerging Technologies: First International Conference, MIET 2022, Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (490), P201, DOI 10.1007/978-3-031-34619-4_17; Mohamed TIA, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0285796; Moyes A, 2023, MED IMAGE ANAL, V83, DOI 10.1016/j.media.2022.102640; Mridha Krishna, 2022, 2022 International Conference on Advances in Computing, Communication and Materials (ICACCM), P1, DOI 10.1109/ICACCM56405.2022.10009311; Pradhan M., 2022, Automatic Detection of Lung Cancer Using the Potential of Artificial Intelligence (AI), P106, DOI [10.4018/978-1-6684-4671-3.ch006, DOI 10.4018/978-1-6684-4671-3.CH006]; Provath M.A.-M., 2023, Communications in Computer and Information Science, P56, DOI [10.1007/978-981-99-4914_45, DOI 10.1007/978-981-99-4914_45]; Rajput A., 2023, Applications of Artificial Intelligence in Medical Imaging, P265; Raju MSN, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7361; Ram S, 2023, NEOPLASIA, V42, DOI 10.1016/j.neo.2023.100911; Reis HC, 2023, J DIGIT IMAGING, V36, P306, DOI 10.1007/s10278-022-00701-z; SCHAEFER JT, 1990, WEATHER FORECAST, V5, P570, DOI 10.1175/1520-0434(1990)005<0570:TCSIAA>2.0.CO;2; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Sethy PK, 2023, J X-RAY SCI TECHNOL, V31, P211, DOI 10.3233/XST-221301; Srivastava G, 2023, APPL SOFT COMPUT, V132, DOI 10.1016/j.asoc.2022.109872; Stephen Okeke, 2023, Journal of Healthcare Engineering, DOI 10.1155/2023/4597445; Sun K, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13071277; Talukder MA, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117695; Tsai PC, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-37179-4; Wadekar S., 2023, Healthc Anal, V4, P100224, DOI [10.1016/J.HEALTH.2023.100224, DOI 10.1016/J.HEALTH.2023.100224]; Wahid Radical Rakhman, 2023, AIP Conference Proceedings, DOI 10.1063/5.0114327; Wang HJ, 2020, Cambria Sinophone Wo, P111, DOI 10.1109/CVPRW50498.2020.00020; YERUSHALMY J, 1947, PUBLIC HEALTH REP, V62, P1432, DOI 10.2307/4586294	57	1	1	6	6	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA		2405-8440		HELIYON	Heliyon	MAY 15	2024	10	9							e30625	10.1016/j.heliyon.2024.e30625	http://dx.doi.org/10.1016/j.heliyon.2024.e30625			23	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	TD8Y9	38742084	gold, Green Published			2024-09-18	WOS:001239428200001
J	Chen, J; Wang, GH; Zhou, JJ; Zhang, ZH; Ding, Y; Xia, KJ; Xu, XD				Chen, Jian; Wang, Ganhong; Zhou, Jingjie; Zhang, Zihao; Ding, Yu; Xia, Kaijian; Xu, Xiaodan			AI support for colonoscopy quality control using CNN and transformer architectures	BMC GASTROENTEROLOGY			English	Article						Deep learning; Colonoscopy quality control; Colonoscopy; Artificial intelligence	BOWEL PREPARATION QUALITY; COLORECTAL-CANCER; ENDOSCOPY; INDICATORS; SOCIETY; SYSTEM; TIME	BackgroundConstruct deep learning models for colonoscopy quality control using different architectures and explore their decision-making mechanisms.MethodsA total of 4,189 colonoscopy images were collected from two medical centers, covering different levels of bowel cleanliness, the presence of polyps, and the cecum. Using these data, eight pre-trained models based on CNN and Transformer architectures underwent transfer learning and fine-tuning. The models' performance was evaluated using metrics such as AUC, Precision, and F1 score. Perceptual hash functions were employed to detect image changes, enabling real-time monitoring of colonoscopy withdrawal speed. Model interpretability was analyzed using techniques such as Grad-CAM and SHAP. Finally, the best-performing model was converted to ONNX format and deployed on device terminals.ResultsThe EfficientNetB2 model outperformed other architectures on the validation set, achieving an accuracy of 0.992. It surpassed models based on other CNN and Transformer architectures. The model's precision, recall, and F1 score were 0.991, 0.989, and 0.990, respectively. On the test set, the EfficientNetB2 model achieved an average AUC of 0.996, with a precision of 0.948 and a recall of 0.952. Interpretability analysis showed the specific image regions the model used for decision-making. The model was converted to ONNX format and deployed on device terminals, achieving an average inference speed of over 60 frames per second.ConclusionsThe AI-assisted quality system, based on the EfficientNetB2 model, integrates four key quality control indicators for colonoscopy. This integration enables medical institutions to comprehensively manage and enhance these indicators using a single model, showcasing promising potential for clinical applications.	[Chen, Jian; Zhou, Jingjie; Ding, Yu; Xu, Xiaodan] Soochow Univ, Dept Gastroenterol, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China; [Wang, Ganhong] Changshu Traditional Chinese Med Hosp, Dept Gastroenterol, Suzhou 215500, Peoples R China; [Zhang, Zihao] Shanghai Haoxiong Educ Technol Co Ltd, Shanghai 200434, Peoples R China; [Xia, Kaijian] Soochow Univ, Dept Informat Engn, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China	Soochow University - China; Soochow University - China	Xu, XD (corresponding author), Soochow Univ, Dept Gastroenterol, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China.; Xia, KJ (corresponding author), Soochow Univ, Dept Informat Engn, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China.	kjxia@suda.edu.cn; xxddocter@gmail.com			Changshu City Medical and Health Science and Technology Plan Project	Changshu City Medical and Health Science and Technology Plan Project	The authors thank the team behind the HyperKvasir dataset for providing the data used in this study.	Ahmad OF, 2021, Deep learning for automated bowel preparation assessment during colonoscopy: time to embrace a new approach?, V3, pe685; Aziz Muhammad, 2023, J Clin Gastroenterol, V57, P863, DOI 10.1097/MCG.0000000000001878; Belderbos TDG, 2015, ENDOSCOPY, V47, P703, DOI 10.1055/s-0034-1391968; Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y; Bretthauer M, 2016, ENDOSCOPY, V48, P75, DOI 10.1055/s-0034-1393094; Committee of Colorectal Cancer Quality Control National Cancer Center and National Clinical Research Center for Cancer, 2022, Chin J Oncol, V44, P623; Gomez-Reyes E, 2020, SURG ENDOSC, V34, P3037, DOI 10.1007/s00464-019-07100-6; Gong RR, 2023, CLIN TRANSL GASTROEN, V14, DOI 10.14309/ctg.0000000000000566; Gunter MJ, 2019, ANN ONCOL, V30, P510, DOI 10.1093/annonc/mdz044; Gupta S, 2020, AM J GASTROENTEROL, V115, P415, DOI 10.14309/ajg.0000000000000544; Karaman A, 2023, EXPERT SYST APPL, V221, DOI 10.1016/j.eswa.2023.119741; Kikutsuji T, 2022, J CHEM PHYS, V156, DOI 10.1063/5.0087310; Li PS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166097; Li Y, 2019, BIOMED OPT EXPRESS, V10, P2419, DOI 10.1364/BOE.10.002419; Liu ZS, 2023, COMPUT BIOL MED, V164, DOI 10.1016/j.compbiomed.2023.107268; Lui TKL, 2024, GASTROINTEST ENDOSC, V99, DOI 10.1016/j.gie.2023.10.035; Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031; Pop OL, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21197359; Rembacken B, 2012, ENDOSCOPY, V44, P957, DOI 10.1055/s-0032-1325686; Rex DK, 2015, AM J GASTROENTEROL, V110, P72, DOI 10.1038/ajg.2014.385; Su H, 2020, ANN PALLIAT MED, V9, P420, DOI 10.21037/apm.2020.03.24; Wang YP, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030613; Xu LY, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.04096; Yamaguchi H, 2020, INTERNAL MED, V59, P1481, DOI 10.2169/internalmedicine.4212-19; Yao LW, 2021, CLIN TRANSL GASTROEN, V12, DOI 10.14309/ctg.0000000000000366; Ye TY, 2021, COMPUT STRUCT BIOTEC, V19, P835, DOI [10.1016/j.csbj.2021.01.0102, 10.1016/j.csbj.2021.01.010]; Zhang QM, 2020, GASTROENT RES PRACT, V2020, DOI 10.1155/2020/3089094; Zhang YY, 2021, J NEUROSCI METH, V353, DOI 10.1016/j.jneumeth.2021.109098; Zhao SB, 2021, WORLD J GASTROENTERO, V27, P5232, DOI 10.3748/wjg.v27.i31.5232; Zhou W, 2021, LANCET DIGIT HEALTH, V3, pE697, DOI 10.1016/S2589-7500(21)00109-6	30	0	0	0	0	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1471-230X		BMC GASTROENTEROL	BMC Gastroenterol.	AUG 9	2024	24	1							257	10.1186/s12876-024-03354-0	http://dx.doi.org/10.1186/s12876-024-03354-0			13	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	C3B0L	39123140	Green Published, gold			2024-09-18	WOS:001288126700002
J	Dabass, M; Vashisth, S; Vig, R				Dabass, Manju; Vashisth, Sharda; Vig, Rekha			A convolution neural network with multi-level convolutional and attention learning for classification of cancer grades and tissue structures in colon histopathological images	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Colon histopathology images; Cancer classification; Attention mechanism; Deep convolutional neural network; Multi-level feature extraction		A clinically comparable Convolutional Neural Network framework-based technique for performing automated classification of cancer grades and tissue structures in hematoxylin and eosin-stained colon histopathological images is proposed in this paper. It comprised of Enhanced Convolutional Learning Modules (ECLMs), multi-level Attention Learning Module (ALM), and Transitional Modules (TMs). The ECLMs perform a dual mechanism to extract multi-level discriminative spatial features and model cross-channel correlations with fewer computations and effectual avoidance of vanishing gradient issues. The ALM performs focus-refinement through the channelwise elemental attention learning to accentuate the discriminative channels of the features maps specifically belonging to the important pathological regions and the scale-wise attention learning to facilitate recalibration of features maps at diverse scales. The TMs concatenate the output of these two modules, infuse deep multi-scalar features and eliminate resolution degradation issues. Varied pre-processing techniques are further employed to improvise the generalizability of the proposed network. For performance evaluation, four diverse publicly available datasets (Gland Segmentation challenge(GlaS), Lung Colon(LC)-25000, Kather_Colorectal_Cancer_Texture_Images (Kather-5k), and NCT_HE_CRC_100K(NCT-100k)) and a private dataset Hospital Colon(HosC) are used that further aids in building network invariance against digital variability that exists in real-clinical data. Also, multiple pathologists are involved at every stage of the proposed research and their verification and approval are taken for each step outcome. For the cancer grade classification, the proposed model achieves competitive results for GlaS (Accuracy(97.5%), Precision(97.67%), F1-Score(97.67%), and Recall(97.67%)), LC-25000 (Accuracy(100%), Precision(100%), F1-Score(100%), and Recall(100%)), and HosC (Accuracy(99.45%), Precision(100%), F1-Score(99.65%), and Recall(99.31%)), and while for the tissue structure classification, it achieves results for Kather-5k(Accuracy(98.83%), Precision(98.86%), F1-Score(98.85%), and Recall(98.85%)) and NCT-100k(Accuracy(97.7%), Precision(97.69%), F1-Score(97.71%), and Recall(97.73%)). Furthermore, the reported activation mappings of Gradient-Weighted Class Activation Mappings(Grad-CAM), Occlusion Sensitivity, and Local Interpretable Model-Agnostic Explanations (LIME) evidence that the proposed model can itself learn the similar patterns considered pertinent by the pathologists exclusive of any prerequisite for annotations. In addition, these visualization results are inspected by multiple expert pathologists and provided with a validation score as (GlaS(9.251), LC-25000(9.045), Kather-5k(9.248), NCT-100k(9.262), and HosC (9.853)). This model will provide a secondary referential diagnosis for the pathologists to ease their load and aid them in devising an accurate diagnosis and treatment plan.	[Dabass, Manju; Vashisth, Sharda; Vig, Rekha] NorthCap Univ, EECE Dept, Gurugram 122017, India	The Northcap University	Dabass, M (corresponding author), NorthCap Univ, EECE Dept, Gurugram 122017, India.	manjurashi87@gmail.com	Vashisth, Sharda/HHS-8370-2022; dabass, manju/GLN-3022-2022; Vig, Rekha/KIB-5038-2024	dabass, manju/0000-0002-9040-3158; Vashisth, Sharda/0000-0002-1730-4866; Vig, Rekha/0000-0002-0789-8840				Ali M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081485; Alinsaif S, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01327-3; Alqudah AM, 2022, MULTIMED TOOLS APPL, V81, P10839, DOI 10.1007/s11042-022-11946-9; [Anonymous], 2020, Cancer Discov, V10, pOF1, DOI 10.1158/2159-8290.CD-RW2020-012; Awan R, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16516-w; Babu T., 2020, Prediction of normal and grades of cancer on colon biopsy images at different magnifications using minimal robust texture and morphological features, V11, DOI [10.37506/v11/i1/2020/ijphrd/193905, DOI 10.37506/V11/I1/2020/IJPHRD/193905]; Banwari A, 2018, INT J E-HEALTH MED C, V9, P1, DOI 10.4018/IJEHMC.2018040101; Black-Schaffer WS, 2016, ACAD PATHOL, V3, DOI 10.1177/2374289516665393; Borkowski A.A., 2019, Lung and colon cancer histopathological image dataset (lc25000); Bukhari S.U.K., 2020, medRxiv; Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3; Chaddad A, 2017, ANAL CELL PATHOL, V2017, P1, DOI 10.1155/2017/8428102; Clevert D.-A., 2016, 4 INT C LEARN REPR I; Dabass, 2019, REV CLASSIFICATION T, DOI [10.1109/SPIN.2019.8711776, DOI 10.1109/SPIN.2019.8711776]; Dabass M., 2021, LECT NOTES ELECT ENG, V668, DOI [10.1007/978-981-15-5341-7_85, DOI 10.1007/978-981-15-5341-7_85]; Dabass M., 2020, COMMUN COMPUT PHYS, V1229, DOI [10.1007/978-981-15-5827-6_9, DOI 10.1007/978-981-15-5827-6_9]; Dabass M., 2019, 5 GRADE CANC CLASSIF, DOI [10.1201/9780429444272-3, DOI 10.1201/9780429444272-3]; Dabass M., 2021, Inf. Med. Unlocked, V27, DOI 10.1016/j.imu.2021.100784; Damkliang K, 2021, BIOMED ENG-APP BAS C, V33, DOI 10.4015/S1016237221500228; Ghosh S, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104202; Guan QJ, 2020, PATTERN RECOGN LETT, V130, P259, DOI 10.1016/j.patrec.2018.10.027; Haj-Hassan Hawraa, 2017, J Pathol Inform, V8, P1, DOI 10.4103/jpi.jpi_47_16; Haryanto T., 2021, Inform. Med. Unlocked, V23, DOI 10.1016/j.imu.2021.100565; He K., 2016, PROC IEEE C COMPUTER, DOI [DOI 10.1109/CVPR.2016.90, 10.1109/CVPR.2016.90]; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]; Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20107, 10.3322/caac.21492, 10.3322/caac.20115]; Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874; Kather J.N., 2018, 100,000 histological images of human colorectal cancer and healthy tissue; Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730; Kather JN, 2016, SCI REP-UK, V6, DOI 10.1038/srep27988; Khadilkar SP, 2022, INT J IMAGE GRAPH, V22, DOI 10.1142/S0219467822500243; Masud M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030748; Maung R, 2016, Diagn Histopathol, V22, DOI DOI 10.1016/J.MPDHP.2016.07.004; Ohata EF, 2021, J SUPERCOMPUT, V77, P9494, DOI 10.1007/s11227-020-03575-6; Paladini E, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030051; Rachapudi V, 2021, EVOL INTELL, V14, P1337, DOI 10.1007/s12065-020-00367-y; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Ribeiro MG, 2019, EXPERT SYST APPL, V120, P262, DOI 10.1016/j.eswa.2018.11.034; Roberto GF, 2019, COMPUT GRAPH-UK, V84, P134, DOI 10.1016/j.cag.2019.08.008; Salvi M, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105506; Saroja B., 2019, Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, V7, P1, DOI 10.1080/21681163.2017.1350603; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]; Shaban MT, 2019, I S BIOMED IMAGING, P953, DOI [10.1109/ISBI.2019.8759152, 10.1109/isbi.2019.8759152]; Shapcott M, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00052; Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008; Skrede OJ, 2020, LANCET, V395, P350, DOI 10.1016/S0140-6736(19)32998-8; Togaçar M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104827; Trivizakis E, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94781-6; Tsai MJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141662; Vidyun, 2021, HISTOPATHOLOGICAL IM, DOI [10.1007/978-981-16-0171-2_17, DOI 10.1007/978-981-16-0171-2_17]; Wang CF, 2017, IEEE ENG MED BIO, P4050, DOI 10.1109/EMBC.2017.8037745; Wang HY, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101846; Wang KS, 2021, BMC MED, V19, DOI 10.1186/s12916-021-01942-5; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xi Y, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101174; Yildirim M, 2022, INT J IMAG SYST TECH, V32, P155, DOI 10.1002/ima.22623; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang JP, 2019, IEEE T MED IMAGING, V38, P2092, DOI [10.1109/TKDE.2019.2891537, 10.1109/TMI.2019.2893944]; Zhu C, 2021, NEUROCOMPUTING, V438, P165, DOI 10.1016/j.neucom.2020.04.154	59	17	18	1	37	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825	1879-0534		COMPUT BIOL MED	Comput. Biol. Med.	AUG	2022	147								105680	10.1016/j.compbiomed.2022.105680	http://dx.doi.org/10.1016/j.compbiomed.2022.105680		JUN 2022	20	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	3J7AN	35671654				2024-09-18	WOS:000833546200006
