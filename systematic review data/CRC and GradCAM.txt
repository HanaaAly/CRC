Publication Type	Authors	Book Authors	Book Editors	Book Group Authors	Author Full Names	Book Author Full Names	Group Authors	Article Title	Source Title	Book Series Title	Book Series Subtitle	Language	Document Type	Conference Title	Conference Date	Conference Location	Conference Sponsor	Conference Host	Author Keywords	Keywords Plus	Abstract	Addresses	Affiliations	Reprint Addresses	Email Addresses	Researcher Ids	ORCIDs	Funding Orgs	Funding Name Preferred	Funding Text	Cited References	Cited Reference Count	"Times Cited, WoS Core"	"Times Cited, All Databases"	180 Day Usage Count	Since 2013 Usage Count	Publisher	Publisher City	Publisher Address	ISSN	eISSN	ISBN	Journal Abbreviation	Journal ISO Abbreviation	Publication Date	Publication Year	Volume	Issue	Part Number	Supplement	Special Issue	Meeting Abstract	Start Page	End Page	Article Number	DOI	DOI Link	Book DOI	Early Access Date	Number of Pages	WoS Categories	Web of Science Index	Research Areas	IDS Number	Pubmed Id	Open Access Designations	Highly Cited Status	Hot Paper Status	Date of Export	UT (Unique WOS ID)	Web of Science Record
J	"Wesp, P; Grosu, S; Graser, A; Maurus, S; Schulz, C; Knösel, T; Fabritius, MP; Schachtner, B; Yeh, BM; Cyran, CC; Ricke, J; Kazmierczak, PM; Ingrisch, M"				"Wesp, Philipp; Grosu, Sergio; Graser, Anno; Maurus, Stefan; Schulz, Christian; Knosel, Thomas; Fabritius, Matthias P.; Schachtner, Balthasar; Yeh, Benjamin M.; Cyran, Clemens C.; Ricke, Jens; Kazmierczak, Philipp M.; Ingrisch, Michael"			Deep learning in CT colonography: differentiating premalignant from benign colorectal polyps	EUROPEAN RADIOLOGY			English	Article						Colonography; Computed tomographic; Colonic polyp; Deep learning; Early detection of cancer	CANCER; COLONOSCOPY; PARTICIPATION; PREVENTION; ADENOMA; SOCIETY; RATES	"Objectives To investigate the differentiation of premalignant from benign colorectal polyps detected by CT colonography using deep learning. Methods In this retrospective analysis of an average risk colorectal cancer screening sample, polyps of all size categories and morphologies were manually segmented on supine and prone CT colonography images and classified as premalignant (adenoma) or benign (hyperplastic polyp or regular mucosa) according to histopathology. Two deep learning models SEG and noSEG were trained on 3D CT colonography image subvolumes to predict polyp class, and model SEG was additionally trained with polyp segmentation masks. Diagnostic performance was validated in an independent external multicentre test sample. Predictions were analysed with the visualisation technique Grad-CAM++. Results The training set consisted of 107 colorectal polyps in 63 patients (mean age: 63 +/- 8 years, 40 men) comprising 169 polyp segmentations. The external test set included 77 polyps in 59 patients comprising 118 polyp segmentations. Model SEG achieved a ROC-AUC of 0.83 and 80% sensitivity at 69% specificity for differentiating premalignant from benign polyps. Model noSEG yielded a ROC-AUC of 0.75, 80% sensitivity at 44% specificity, and an average Grad-CAM++ heatmap score of >= 0.25 in 90% of polyp tissue. Conclusions In this proof-of-concept study, deep learning enabled the differentiation of premalignant from benign colorectal polyps detected with CT colonography and the visualisation of image regions important for predictions. The approach did not require polyp segmentation and thus has the potential to facilitate the identification of high-risk polyps as an automated second reader."	"[Wesp, Philipp; Grosu, Sergio; Maurus, Stefan; Fabritius, Matthias P.; Schachtner, Balthasar; Cyran, Clemens C.; Ricke, Jens; Kazmierczak, Philipp M.; Ingrisch, Michael] Ludwig Maximilians Univ Munchen, Dept Radiol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany; [Graser, Anno] Radiol Munchen, Burgstr 7, D-80331 Munich, Germany; [Schulz, Christian] Ludwig Maximilians Univ Munchen, Dept Med 2, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany; [Knosel, Thomas] Ludwig Maximilians Univ Munchen, Dept Pathol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany; [Schachtner, Balthasar] German Ctr Lung Res DZL, Comprehens Pneumol Ctr CPC M, Max Lebsche Pl 31, D-81377 Munich, Germany; [Yeh, Benjamin M.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave, San Francisco, CA 94117 USA"	University of Munich; University of Munich; University of Munich; University of California System; University of California San Francisco	"Wesp, P (corresponding author), Ludwig Maximilians Univ Munchen, Dept Radiol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany."	philipp.wesp@med.uni-muenchen.de	"schulz, christian/HOA-7122-2023; Wesp, Philipp/HNO-9426-2023; Ingrisch, Michael/T-3408-2017"	"Grosu, Sergio/0000-0002-9093-6499; Wesp, Philipp/0000-0001-7356-3371"	"Projekt DEAL; FoFoLe, Medizinische Fakultat, Ludwig-Maximilians-Universitat Munchen, Germany"	"Projekt DEAL; FoFoLe, Medizinische Fakultat, Ludwig-Maximilians-Universitat Munchen, Germany"	"Open Access funding enabled and organized by Projekt DEAL. This study has received funding by FoFoLe, Medizinische Fakultat, Ludwig-Maximilians-Universitat Munchen, Germany (PI: Sergio Grosu)."		31	8	8	1	22	SPRINGER	NEW YORK	"ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES"	0938-7994	1432-1084		EUR RADIOL	Eur. Radiol.	JUL	2022	32	7					4749	4759		10.1007/s00330-021-08532-2	http://dx.doi.org/10.1007/s00330-021-08532-2		JAN 2022	11	"Radiology, Nuclear Medicine & Medical Imaging"	Science Citation Index Expanded (SCI-EXPANDED)	"Radiology, Nuclear Medicine & Medical Imaging"	2I3RK	35083528	"Green Published, hybrid"			2024-09-17	WOS:000747080500001	View Full Record in Web of Science
J	"Zhou, PY; Cao, YZ; Li, M; Ma, YH; Chen, C; Gan, XJ; Wu, JY; Lv, XY; Chen, C"				"Zhou, Panyun; Cao, Yanzhen; Li, Min; Ma, Yuhua; Chen, Chen; Gan, Xiaojing; Wu, Jianying; Lv, Xiaoyi; Chen, Cheng"			HCCANet: histopathological image grading of colorectal cancer using CNN based on multichannel fusion attention mechanism	SCIENTIFIC REPORTS			English	Article							RESIDUAL NETWORK; CLASSIFICATION	"Histopathological image analysis is the gold standard for pathologists to grade colorectal cancers of different differentiation types. However, the diagnosis by pathologists is highly subjective and prone to misdiagnosis. In this study, we constructed a new attention mechanism named MCCBAM based on channel attention mechanism and spatial attention mechanism, and developed a computer-aided diagnosis (CAD) method based on CNN and MCCBAM, called HCCANet. In this study, 630 histopathology images processed with Gaussian filtering denoising were included and gradient-weighted class activation map (Grad-CAM) was used to visualize regions of interest in HCCANet to improve its interpretability. The experimental results show that the proposed HCCANet model outperforms four advanced deep learning (ResNet50, MobileNetV2, Xception, and DenseNet121) and four classical machine learning (KNN, NB, RF, and SVM) techniques, achieved 90.2%, 85%, and 86.7% classification accuracy for colorectal cancers with high, medium, and low differentiation levels, respectively, with an overall accuracy of 87.3% and an average AUC value of 0.9.In addition, the MCCBAM constructed in this study outperforms several commonly used attention mechanisms SAM, SENet, SKNet, Non_Local, CBAM, and BAM on the backbone network. In conclusion, the HCCANet model proposed in this study is feasible for postoperative adjuvant diagnosis and grading of colorectal cancer."	"[Zhou, Panyun; Lv, Xiaoyi; Chen, Cheng] Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China; [Cao, Yanzhen; Gan, Xiaojing] Xinjiang Med Univ, Affiliated Tumor Hosp, Urumqi 830011, Peoples R China; [Li, Min; Chen, Chen; Lv, Xiaoyi] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China; [Li, Min; Lv, Xiaoyi] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China; [Ma, Yuhua] Tongji Univ, Shanghai East Hosp, Dept Oncol, Sch Med, Shanghai 200120, Peoples R China; [Ma, Yuhua] Karamay Cent Hosp Xinjiang Karamay, Dept Pathol, Karamay 834000, Xinjiang Uygur, Peoples R China; [Chen, Chen; Lv, Xiaoyi] Xinjiang Cloud Comp Applicat Lab, Karamay 834099, Peoples R China; [Wu, Jianying] Xinjiang Normal Univ, Coll Phys & Elect Engn, Urumqi 830054, Peoples R China; [Lv, Xiaoyi] Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830046, Peoples R China"	Xinjiang University; Xinjiang Medical University; Xinjiang University; Xinjiang University; Tongji University; Xinjiang Normal University; Xinjiang University	"Lv, XY; Chen, C (corresponding author), Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China.;Lv, XY (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.;Lv, XY (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.;Lv, XY (corresponding author), Xinjiang Cloud Comp Applicat Lab, Karamay 834099, Peoples R China.;Lv, XY (corresponding author), Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830046, Peoples R China."	xjuwawj01@163.com; chenchengoptics@gmail.com	"xiao, ming/KHT-1774-2024"		"Key Laboratory of Clinical Gene Detection and Biomedical Information of Xinjiang; Xinjiang Uygur Autonomous Region Science Foundation for Distinguished Young Scholars [2022D01E11, 2022D01E27]; National Natural Science Foundation of China [81860430]; Xinjiang Autonomous Region Science and Technology Plan Project [2018D01C257]; Karamay Central Hospital Project: Research on Molecular Mechanism and Application of DNA Methylation Liquid Biopsy in the Prevention, Diagnosis and Treatment of Malignant Tumors"	"Key Laboratory of Clinical Gene Detection and Biomedical Information of Xinjiang; Xinjiang Uygur Autonomous Region Science Foundation for Distinguished Young Scholars; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Xinjiang Autonomous Region Science and Technology Plan Project; Karamay Central Hospital Project: Research on Molecular Mechanism and Application of DNA Methylation Liquid Biopsy in the Prevention, Diagnosis and Treatment of Malignant Tumors"	"This work was supported by the Key Laboratory of Clinical Gene Detection and Biomedical Information of Xinjiang; the Xinjiang Uygur Autonomous Region Science Foundation for Distinguished Young Scholars [grant number 2022D01E11& 2022D01E27]; the National Natural Science Foundation of China [grant number 81860430]; the Xinjiang Autonomous Region Science and Technology Plan Project [grant number 2018D01C257]; the Karamay Central Hospital Project: Research on Molecular Mechanism and Application of DNA Methylation Liquid Biopsy in the Prevention, Diagnosis and Treatment of Malignant Tumors."		43	21	21	3	36	NATURE PORTFOLIO	BERLIN	"HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY"	2045-2322			SCI REP-UK	Sci Rep	SEP 6	2022	12	1							15103	10.1038/s41598-022-18879-1	http://dx.doi.org/10.1038/s41598-022-18879-1			12	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	4K4GO	36068309	"Green Published, gold"			2024-09-17	WOS:000851910600007	View Full Record in Web of Science
J	"Xu, R; Wang, ZZ; Liu, ZB; Han, C; Yan, LX; Lin, H; Xu, ZY; Feng, ZY; Liang, CH; Chen, X; Pan, XP; Liu, ZY"				"Xu, Rui; Wang, Zhizhen; Liu, Zhenbing; Han, Chu; Yan, Lixu; Lin, Huan; Xu, Zeyan; Feng, Zhengyun; Liang, Changhong; Chen, Xin; Pan, Xipeng; Liu, Zaiyi"			Histopathological Tissue Segmentation of Lung Cancer with Bilinear CNN and Soft Attention	BIOMED RESEARCH INTERNATIONAL			English	Article							CLASSIFICATION	"Automatic tissue segmentation in whole-slide images (WSIs) is a critical task in hematoxylin and eosin- (H&E-) stained histopathological images for accurate diagnosis and risk stratification of lung cancer. Patch classification and stitching the classification results can fast conduct tissue segmentation of WSIs. However, due to the tumour heterogeneity, large intraclass variability and small interclass variability make the classification task challenging. In this paper, we propose a novel bilinear convolutional neural network- (Bilinear-CNN-) based model with a bilinear convolutional module and a soft attention module to tackle this problem. This method investigates the intraclass semantic correspondence and focuses on the more distinguishable features that make feature output variations relatively large between interclass. The performance of the Bilinear-CNN-based model is compared with other state-of-the-art methods on the histopathological classification dataset, which consists of 107.7 k patches of lung cancer. We further evaluate our proposed algorithm on an additional dataset from colorectal cancer. Extensive experiments show that the performance of our proposed method is superior to that of previous state-of-the-art ones and the interpretability of our proposed method is demonstrated by Grad-CAM."	"[Xu, Rui; Wang, Zhizhen; Liu, Zhenbing; Feng, Zhengyun; Pan, Xipeng] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin, Peoples R China; [Han, Chu; Lin, Huan; Xu, Zeyan; Liang, Changhong; Pan, Xipeng; Liu, Zaiyi] Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Radiol, Guangzhou, Peoples R China; [Han, Chu; Pan, Xipeng] Guangdong Cardiovasc Inst, Guangzhou, Peoples R China; [Han, Chu; Lin, Huan; Xu, Zeyan; Liang, Changhong; Pan, Xipeng; Liu, Zaiyi] Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Guangdong Prov Key Lab Artificial Intelligence Med, Guangzhou, Peoples R China; [Yan, Lixu] Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Pathol, Guangzhou, Peoples R China; [Chen, Xin] South China Univ Technol, Guangzhou Peoples Hosp 1, Dept Radiol, Affiliated Hosp 2, Guangzhou, Peoples R China"	Guilin University of Electronic Technology; Guangdong Academy of Medical Sciences & Guangdong General Hospital; Southern Medical University - China; Guangdong Academy of Medical Sciences & Guangdong General Hospital; Southern Medical University - China; Guangdong Academy of Medical Sciences & Guangdong General Hospital; Southern Medical University - China; South China University of Technology	"Pan, XP (corresponding author), Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin, Peoples R China.;Pan, XP; Liu, ZY (corresponding author), Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Radiol, Guangzhou, Peoples R China.;Pan, XP (corresponding author), Guangdong Cardiovasc Inst, Guangzhou, Peoples R China.;Pan, XP; Liu, ZY (corresponding author), Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Guangdong Prov Key Lab Artificial Intelligence Med, Guangzhou, Peoples R China.;Chen, X (corresponding author), South China Univ Technol, Guangzhou Peoples Hosp 1, Dept Radiol, Affiliated Hosp 2, Guangzhou, Peoples R China."	webrat@yeah.net; wangzhizhen0012021@163.com; zbliu@guet.edu.cn; zq1992@gmail.com; ylxyss@163.com; huanhuan260@hotmail.com; zeyx0708@163.com; 20032303022@mails.guet.edu.cn; liangchanghong@gdph.org.cn; wolfchenxin@163.com; pxp201@guet.edu.cn; liuzaiyi@gdph.org.cn	"Han, Chu/GWM-9255-2022; Liu, Zaiyi/L-9212-2015; zhang, xiaowei/GQH-5387-2022; Li, Shiyu/KHE-1376-2024"	"Chen, Xin/0000-0002-3873-9041"	"Key R&D Program of Guangdong Province, China [2021B0101420006]; National Key R&D Program of China [2021YFF1201003]; National Science Fund for Distinguished Young Scholars, China [81925023]; National Natural Science Foundation of China [62002082, 82072090, 62102103, 81771912]; Natural Science Foundation of Guangxi Province [2020GXNSFBA238014]; China Postdoctoral Science Foundation [2021M690753]; Guangxi University Young and Middle Aged Teachers' Research Ability Improvement Project [2020KY05034]; Major Achievement Transformation Foundation of Guilin [20192013-1]; Guangxi Key Research and Development Program [GuikeAB21196063]; Innovation Project of Guangxi Graduate Education [YCSW2021172]; Innovation Project of GUET Graduate Education [2021YCXS060]; High-Level Hospital Construction Project [DFJHBF202105, DFJH201805]; Guangdong Provincial Key Laboratory of Artificial Intelligence in Medical Image Analysis and Application [2022B1212010011]"	"Key R&D Program of Guangdong Province, China; National Key R&D Program of China; National Science Fund for Distinguished Young Scholars, China(National Natural Science Foundation of China (NSFC)National Science Fund for Distinguished Young Scholars); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Guangxi Province(National Natural Science Foundation of Guangxi Province); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Guangxi University Young and Middle Aged Teachers' Research Ability Improvement Project; Major Achievement Transformation Foundation of Guilin; Guangxi Key Research and Development Program; Innovation Project of Guangxi Graduate Education; Innovation Project of GUET Graduate Education; High-Level Hospital Construction Project; Guangdong Provincial Key Laboratory of Artificial Intelligence in Medical Image Analysis and Application"	"This research was supported in part by the Key R&D Program of Guangdong Province, China (Grant No. 2021B0101420006), the National Key R&D Program of China (Grant No. 2021YFF1201003), the National Science Fund for Distinguished Young Scholars, China (Grant No. 81925023), the National Natural Science Foundation of China (Grant Nos. 62002082, 82072090, 62102103, and 81771912), the Natural Science Foundation of Guangxi Province (Grant No. 2020GXNSFBA238014), the China Postdoctoral Science Foundation (Grant No. 2021M690753), Guangxi University Young and Middle Aged Teachers' Research Ability Improvement Project (Grant No. 2020KY05034), the Major Achievement Transformation Foundation of Guilin (Grant No. 20192013-1), the Guangxi Key Research and Development Program (Grant No. GuikeAB21196063), the Innovation Project of Guangxi Graduate Education (Grant No. YCSW2021172), the Innovation Project of GUET Graduate Education (Grant No. 2021YCXS060), the High-Level Hospital Construction Project (Grant Nos. DFJHBF202105 and DFJH201805), and the Guangdong Provincial Key Laboratory of Artificial Intelligence in Medical Image Analysis and Application (Grant No. 2022B1212010011)."		31	3	3	1	24	HINDAWI LTD	LONDON	"ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND"	2314-6133	2314-6141		BIOMED RES INT-UK	Biomed Res. Int.	JUL 7	2022	2022								7966553	10.1155/2022/7966553	http://dx.doi.org/10.1155/2022/7966553			10	"Biotechnology & Applied Microbiology; Medicine, Research & Experimental"	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology; Research & Experimental Medicine	3G8MY	35845926	"gold, Green Published"			2024-09-17	WOS:000831603200002	View Full Record in Web of Science
J	"Uddin, AH; Chen, YL; Akter, MR; Ku, CS; Yang, J; Por, LY"				"Uddin, A. Hasib; Chen, Yen-Lin; Akter, Miss Rokeya; Ku, Chin Soon; Yang, Jing; Por, Lip Yee"			Colon and lung cancer classification from multi-modal images using resilient and efficient neural network architectures	HELIYON			English	Article						Dense neural networks (DNN); Cancer image classification; Multi-modal network; Histopathological imaging; CT-Scan imaging; Lung cancer; Colon cancer		"Automatic classification of colon and lung cancer images is crucial for early detection and accurate diagnostics. However, there is room for improvement to enhance accuracy, ensuring better diagnostic precision. This study introduces two novel dense architectures (D1 and D2) and emphasizes their effectiveness in classifying colon and lung cancer from diverse images. It also highlights their resilience, efficiency, and superior performance across multiple datasets. These architectures were tested on various types of datasets, including NCT-CRC-HE-100K (set of 100,000 non -overlapping image patches from hematoxylin and eosin (H &E) stained histological images of human colorectal cancer (CRC) and normal tissue), CRC-VAL-HE-7K (set of 7180 image patches from N = 50 patients with colorectal adenocarcinoma, no overlap with patients in NCTCRC-HE-100K), LC25000 (Lung and Colon Cancer Histopathological Image), and IQ-OTHNCCD (Iraq -Oncology Teaching Hospital/National Center for Cancer Diseases), showcasing their effectiveness in classifying colon and lung cancers from histopathological and Computed Tomography (CT) scan images. This underscores the multi -modal image classification capability of the proposed models. Moreover, the study addresses imbalanced datasets, particularly in CRC-VAL-HE7K and IQ-OTHNCCD, with a specific focus on model resilience and robustness. To assess overall performance, the study conducted experiments in different scenarios. The D1 model achieved an impressive 99.80 % accuracy on the NCT-CRC-HE-100K dataset, with a Jaccard Index (J) of 0.8371, a Matthew ' s Correlation Coefficient (MCC) of 0.9073, a Cohen ' s Kappa (Kp) of 0.9057, and a Critical Success Index (CSI) of 0.8213. When subjected to 10 -fold cross -validation on LC25000, the D1 model averaged (avg) 99.96 % accuracy (avg J, MCC, Kp, and CSI of 0.9993, 0.9987, 0.9853, and 0.9990), surpassing recent reported performances. Furthermore, the ensemble of D1 and D2 reached 93 % accuracy (J, MCC, Kp, and CSI of 0.7556, 0.8839, 0.8796, and 0.7140) on the IQ-OTHNCCD dataset, exceeding recent benchmarks and aligning with other reported results. Efficiency evaluations were conducted in various scenarios. For instance, training on only 10 % of LC25000 resulted in high accuracy rates of 99.19 % (J, MCC, Kp, and CSI of 0.9840, 0.9898, 0.9898, and 0.9837) (D1) and 99.30 % (J, MCC, Kp, and CSI of 0.9863, 0.9913, 0.9913, and 0.9861) (D2). In NCT-CRC-HE-100K, D2 achieved an impressive 99.53 % accuracy (J, MCC, Kp, and CSI of 0.9906, 0.9946, 0.9946, and 0.9906) with training on only 30 % of the dataset and testing on the remaining 70 %. When tested on CRC-VAL-HE-7K, D1 and D2 achieved 95 % accuracy (J, MCC, Kp, and CSI of 0.8845, 0.9455, 0.9452, and 0.8745) and 96 % accuracy (J, MCC, Kp, and CSI of 0.8926, 0.9504, 0.9503, and 0.8798), respectively, outperforming previously reported results and aligning closely with others. Lastly, training D2 on just 10 % of NCT-CRC-HE-100K and testing on CRC-VAL-HE-7K resulted in significant outperformance of InceptionV3, Xception, and DenseNet201 benchmarks, achieving an accuracy rate of 82.98 % (J, MCC, Kp, and CSI of 0.7227, 0.8095, 0.8081, and 0.6671). Finally, using explainable AI algorithms such as Grad -CAM, Grad -CAM ++, Score -CAM, and Faster Score -CAM, along with their emphasized versions, we visualized the features from the last layer of DenseNet201 for histopathological as well as CT -scan image samples. The proposed dense models, with their multi -modality, robustness, and efficiency in cancer image classification, hold the promise of significant advancements in medical diagnostics. They have the potential to revolutionize early cancer detection and improve healthcare accessibility worldwide."	"[Uddin, A. Hasib; Akter, Miss Rokeya] Khwaja Yunus Ali Univ, Dept Comp Sci & Engn, Chouhali 6751, Sirajganj, Bangladesh; [Chen, Yen-Lin] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106344, Taiwan; [Ku, Chin Soon] Univ Tunku Abdul Rahman, Dept Comp Sci, Kampar 31900, Malaysia; [Yang, Jing; Por, Lip Yee] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia"	National Taipei University of Technology; Universiti Tunku Abdul Rahman (UTAR); Universiti Malaya	"Uddin, AH (corresponding author), Khwaja Yunus Ali Univ, Dept Comp Sci & Engn, Chouhali 6751, Sirajganj, Bangladesh.;Chen, YL (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106344, Taiwan.;Ku, CS (corresponding author), Univ Tunku Abdul Rahman, Dept Comp Sci, Kampar 31900, Malaysia.;Por, LY (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia."	abdulhasib.cse@kyau.edu.bd; ylchen@mail.ntut.edu.tw; kucs@utar.edu.my; porlip@um.edu.my	"Akter, Rokeya/JHS-8896-2023; ku, chin soon/N-6119-2015; Uddin, Abdul/ABC-9991-2020"	"Chen, Yen-Lin/0000-0001-7717-9393"	"National Science and Technology Council in Taiwan [NSTC-112-2221-E-027-088-MY2, NSTC-112-2622-8-027-008]; Ministry of Education of Taiwan [1122302319]; UTAR"	"National Science and Technology Council in Taiwan; Ministry of Education of Taiwan(Ministry of Education, Taiwan); UTAR"	"This work was supported in part by the National Science and Technology Council in Taiwan under Grant NSTC-112-2221-E-027-088-MY2 and Grant NSTC-112-2622-8-027-008 in part by the Ministry of Education of Taiwan titled The Study of Artificial Intelligence and Advanced Semiconductor Manufacturing for Female STEM Talent Education and Industry-University Value-Added Cooperation Promotion under Grant 1122302319, and the UTAR Financial Support for Journal Paper Publication Scheme through Universiti Tunku Abdul Rahman (UTAR), Malaysia."		57	1	1	6	6	CELL PRESS	CAMBRIDGE	"50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA"		2405-8440		HELIYON	Heliyon	MAY 15	2024	10	9							e30625	10.1016/j.heliyon.2024.e30625	http://dx.doi.org/10.1016/j.heliyon.2024.e30625			23	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	TD8Y9	38742084	"gold, Green Published"			2024-09-17	WOS:001239428200001	View Full Record in Web of Science
J	"Chen, J; Wang, GH; Zhou, JJ; Zhang, ZH; Ding, Y; Xia, KJ; Xu, XD"				"Chen, Jian; Wang, Ganhong; Zhou, Jingjie; Zhang, Zihao; Ding, Yu; Xia, Kaijian; Xu, Xiaodan"			AI support for colonoscopy quality control using CNN and transformer architectures	BMC GASTROENTEROLOGY			English	Article						Deep learning; Colonoscopy quality control; Colonoscopy; Artificial intelligence	BOWEL PREPARATION QUALITY; COLORECTAL-CANCER; ENDOSCOPY; INDICATORS; SOCIETY; SYSTEM; TIME	"BackgroundConstruct deep learning models for colonoscopy quality control using different architectures and explore their decision-making mechanisms.MethodsA total of 4,189 colonoscopy images were collected from two medical centers, covering different levels of bowel cleanliness, the presence of polyps, and the cecum. Using these data, eight pre-trained models based on CNN and Transformer architectures underwent transfer learning and fine-tuning. The models' performance was evaluated using metrics such as AUC, Precision, and F1 score. Perceptual hash functions were employed to detect image changes, enabling real-time monitoring of colonoscopy withdrawal speed. Model interpretability was analyzed using techniques such as Grad-CAM and SHAP. Finally, the best-performing model was converted to ONNX format and deployed on device terminals.ResultsThe EfficientNetB2 model outperformed other architectures on the validation set, achieving an accuracy of 0.992. It surpassed models based on other CNN and Transformer architectures. The model's precision, recall, and F1 score were 0.991, 0.989, and 0.990, respectively. On the test set, the EfficientNetB2 model achieved an average AUC of 0.996, with a precision of 0.948 and a recall of 0.952. Interpretability analysis showed the specific image regions the model used for decision-making. The model was converted to ONNX format and deployed on device terminals, achieving an average inference speed of over 60 frames per second.ConclusionsThe AI-assisted quality system, based on the EfficientNetB2 model, integrates four key quality control indicators for colonoscopy. This integration enables medical institutions to comprehensively manage and enhance these indicators using a single model, showcasing promising potential for clinical applications."	"[Chen, Jian; Zhou, Jingjie; Ding, Yu; Xu, Xiaodan] Soochow Univ, Dept Gastroenterol, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China; [Wang, Ganhong] Changshu Traditional Chinese Med Hosp, Dept Gastroenterol, Suzhou 215500, Peoples R China; [Zhang, Zihao] Shanghai Haoxiong Educ Technol Co Ltd, Shanghai 200434, Peoples R China; [Xia, Kaijian] Soochow Univ, Dept Informat Engn, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China"	Soochow University - China; Soochow University - China	"Xu, XD (corresponding author), Soochow Univ, Dept Gastroenterol, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China.;Xia, KJ (corresponding author), Soochow Univ, Dept Informat Engn, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China."	kjxia@suda.edu.cn; xxddocter@gmail.com			Changshu City Medical and Health Science and Technology Plan Project	Changshu City Medical and Health Science and Technology Plan Project	The authors thank the team behind the HyperKvasir dataset for providing the data used in this study.		30	0	0	0	0	BMC	LONDON	"CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND"		1471-230X		BMC GASTROENTEROL	BMC Gastroenterol.	AUG 9	2024	24	1							257	10.1186/s12876-024-03354-0	http://dx.doi.org/10.1186/s12876-024-03354-0			13	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	C3B0L	39123140	"Green Published, gold"			2024-09-17	WOS:001288126700002	View Full Record in Web of Science
J	"Dabass, M; Vashisth, S; Vig, R"				"Dabass, Manju; Vashisth, Sharda; Vig, Rekha"			A convolution neural network with multi-level convolutional and attention learning for classification of cancer grades and tissue structures in colon histopathological images	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Colon histopathology images; Cancer classification; Attention mechanism; Deep convolutional neural network; Multi-level feature extraction		"A clinically comparable Convolutional Neural Network framework-based technique for performing automated classification of cancer grades and tissue structures in hematoxylin and eosin-stained colon histopathological images is proposed in this paper. It comprised of Enhanced Convolutional Learning Modules (ECLMs), multi-level Attention Learning Module (ALM), and Transitional Modules (TMs). The ECLMs perform a dual mechanism to extract multi-level discriminative spatial features and model cross-channel correlations with fewer computations and effectual avoidance of vanishing gradient issues. The ALM performs focus-refinement through the channelwise elemental attention learning to accentuate the discriminative channels of the features maps specifically belonging to the important pathological regions and the scale-wise attention learning to facilitate recalibration of features maps at diverse scales. The TMs concatenate the output of these two modules, infuse deep multi-scalar features and eliminate resolution degradation issues. Varied pre-processing techniques are further employed to improvise the generalizability of the proposed network. For performance evaluation, four diverse publicly available datasets (Gland Segmentation challenge(GlaS), Lung Colon(LC)-25000, Kather_Colorectal_Cancer_Texture_Images (Kather-5k), and NCT_HE_CRC_100K(NCT-100k)) and a private dataset Hospital Colon(HosC) are used that further aids in building network invariance against digital variability that exists in real-clinical data. Also, multiple pathologists are involved at every stage of the proposed research and their verification and approval are taken for each step outcome. For the cancer grade classification, the proposed model achieves competitive results for GlaS (Accuracy(97.5%), Precision(97.67%), F1-Score(97.67%), and Recall(97.67%)), LC-25000 (Accuracy(100%), Precision(100%), F1-Score(100%), and Recall(100%)), and HosC (Accuracy(99.45%), Precision(100%), F1-Score(99.65%), and Recall(99.31%)), and while for the tissue structure classification, it achieves results for Kather-5k(Accuracy(98.83%), Precision(98.86%), F1-Score(98.85%), and Recall(98.85%)) and NCT-100k(Accuracy(97.7%), Precision(97.69%), F1-Score(97.71%), and Recall(97.73%)). Furthermore, the reported activation mappings of Gradient-Weighted Class Activation Mappings(Grad-CAM), Occlusion Sensitivity, and Local Interpretable Model-Agnostic Explanations (LIME) evidence that the proposed model can itself learn the similar patterns considered pertinent by the pathologists exclusive of any prerequisite for annotations. In addition, these visualization results are inspected by multiple expert pathologists and provided with a validation score as (GlaS(9.251), LC-25000(9.045), Kather-5k(9.248), NCT-100k(9.262), and HosC (9.853)). This model will provide a secondary referential diagnosis for the pathologists to ease their load and aid them in devising an accurate diagnosis and treatment plan."	"[Dabass, Manju; Vashisth, Sharda; Vig, Rekha] NorthCap Univ, EECE Dept, Gurugram 122017, India"	The Northcap University	"Dabass, M (corresponding author), NorthCap Univ, EECE Dept, Gurugram 122017, India."	manjurashi87@gmail.com	"Vashisth, Sharda/HHS-8370-2022; dabass, manju/GLN-3022-2022; Vig, Rekha/KIB-5038-2024"	"dabass, manju/0000-0002-9040-3158; Vashisth, Sharda/0000-0002-1730-4866; Vig, Rekha/0000-0002-0789-8840"					59	17	18	1	37	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	"THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND"	0010-4825	1879-0534		COMPUT BIOL MED	Comput. Biol. Med.	AUG	2022	147								105680	10.1016/j.compbiomed.2022.105680	http://dx.doi.org/10.1016/j.compbiomed.2022.105680		JUN 2022	20	"Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology"	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	3J7AN	35671654				2024-09-17	WOS:000833546200006	View Full Record in Web of Science
